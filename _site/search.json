[
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "This take-home exercise will be done in reference to the VAST Challenge 2025 and provide solutions to the first question of Mini-Challenge 1.\n\n\nOne of music’s biggest superstars is Oceanus native Sailor Shift. From humble beginnings, Sailor has grown in popularity and now enjoys fans around the world. Sailor started her career on the island nation of Oceanus which can be clearly seen in her early work, she started in the genre of “Oceanus Folk”. While Sailor has moved away from the traditional Oceanus style, the Oceanus Folk has made a name for itself in the musical world. The popularity of this music is one of the factors driving an increase in tourism to a quiet island nation that used to be known for fishing.\nIn 2023, Sailor Shift joined the Ivy Echoes – an all-female Oceanus Folk band consisting of Sailor (vocalist), Maya Jensen (vocalist), Lila “Lilly” Hartman (guitarist), Jade Thompson (drummer), and Sophie Ramirez (bassist). They played together at venues throughout Oceanus but had broken up to pursue their individual careers by 2026. Sailor’s breakthrough came in 2028 when one of her singles went viral, launched to the top of the global charts (something no other Oceanus Folk song had ever done). Since then, she has only continued to grow in popularity worldwide.\nSailor has released a new album almost every year since her big break, and each has done better than the last. Although she has remained primarily a solo artist, she has also frequently collaborated with other established artists, especially in the Indie Pop and Indie Folk genres. She herself has branched out musically over the years but regularly returns to the Oceanus Folk genre — even as the genre’s influence on the rest of the music world has spread even more.\nSailor has always been passionate about two things: (1) spreading Oceanus Folk, and (2) helping lesser-known artists break into music. Because of those goals, she’s particularly famous for her frequent collaborations.\nAdditionally, because of Sailor’s success, more attention began to be paid over the years to her previous bandmates. All 4 have continued in the music industry—Maya as an independent vocalist, Lilly and Jade as instrumentalists in other bands, and Sophie as a music producer for a major record label. In various ways, all of them have contributed to the increased influence of Oceanus folk, resulting in a new generation of up-and-coming Oceanus Folk artists seeking to make a name for themselves in the music industry.\nNow, as Sailor returns to Oceanus in 2040, a local journalist – Silas Reed – is writing a piece titled Oceanus Folk: Then-and-Now that aims to trace the rise of Sailor and the influence of Oceanus Folk on the rest of the music world. He has collected a large dataset of musical artists, producers, albums, songs, and influences and organized it into a knowledge graph. Your task is to help Silas create beautiful and informative visualizations of this data and uncover new and interesting information about Sailor’s past, her rise to stardom, and her influence.\n\n\n\nThe objective of this take-home exercise is to address the following tasks and questions of VAST Challenge 2025’s Mini-Challenge 1.\n\nDesign and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career\n\nWho has she been most influenced by over time?\nWho has she collaborated with and directly or indirectly influenced?\nHow has she influenced collaborators of the broader Oceanus Folk community?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#background",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#background",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "One of music’s biggest superstars is Oceanus native Sailor Shift. From humble beginnings, Sailor has grown in popularity and now enjoys fans around the world. Sailor started her career on the island nation of Oceanus which can be clearly seen in her early work, she started in the genre of “Oceanus Folk”. While Sailor has moved away from the traditional Oceanus style, the Oceanus Folk has made a name for itself in the musical world. The popularity of this music is one of the factors driving an increase in tourism to a quiet island nation that used to be known for fishing.\nIn 2023, Sailor Shift joined the Ivy Echoes – an all-female Oceanus Folk band consisting of Sailor (vocalist), Maya Jensen (vocalist), Lila “Lilly” Hartman (guitarist), Jade Thompson (drummer), and Sophie Ramirez (bassist). They played together at venues throughout Oceanus but had broken up to pursue their individual careers by 2026. Sailor’s breakthrough came in 2028 when one of her singles went viral, launched to the top of the global charts (something no other Oceanus Folk song had ever done). Since then, she has only continued to grow in popularity worldwide.\nSailor has released a new album almost every year since her big break, and each has done better than the last. Although she has remained primarily a solo artist, she has also frequently collaborated with other established artists, especially in the Indie Pop and Indie Folk genres. She herself has branched out musically over the years but regularly returns to the Oceanus Folk genre — even as the genre’s influence on the rest of the music world has spread even more.\nSailor has always been passionate about two things: (1) spreading Oceanus Folk, and (2) helping lesser-known artists break into music. Because of those goals, she’s particularly famous for her frequent collaborations.\nAdditionally, because of Sailor’s success, more attention began to be paid over the years to her previous bandmates. All 4 have continued in the music industry—Maya as an independent vocalist, Lilly and Jade as instrumentalists in other bands, and Sophie as a music producer for a major record label. In various ways, all of them have contributed to the increased influence of Oceanus folk, resulting in a new generation of up-and-coming Oceanus Folk artists seeking to make a name for themselves in the music industry.\nNow, as Sailor returns to Oceanus in 2040, a local journalist – Silas Reed – is writing a piece titled Oceanus Folk: Then-and-Now that aims to trace the rise of Sailor and the influence of Oceanus Folk on the rest of the music world. He has collected a large dataset of musical artists, producers, albums, songs, and influences and organized it into a knowledge graph. Your task is to help Silas create beautiful and informative visualizations of this data and uncover new and interesting information about Sailor’s past, her rise to stardom, and her influence."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#tasks-and-questions",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#tasks-and-questions",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "The objective of this take-home exercise is to address the following tasks and questions of VAST Challenge 2025’s Mini-Challenge 1.\n\nDesign and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career\n\nWho has she been most influenced by over time?\nWho has she collaborated with and directly or indirectly influenced?\nHow has she influenced collaborators of the broader Oceanus Folk community?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#load-the-packages",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#load-the-packages",
    "title": "Take-home Exercise 2",
    "section": "2.1 Load the packages",
    "text": "2.1 Load the packages\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environemnt.\n\npacman::p_load(jsonlite, tidyverse, ggtext,\n                knitr, lubridate, patchwork,\n                ggraph, tidygraph, igraph, scales,\n                ggiraph, dplyr, stringr, ggnewscale)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#importing-knowledge-graph-data",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#importing-knowledge-graph-data",
    "title": "Take-home Exercise 2",
    "section": "2.2 Importing Knowledge Graph Data",
    "text": "2.2 Importing Knowledge Graph Data\nfromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object.\n\nmc1_data &lt;- fromJSON(\"MC1/data/MC1_graph.json\")\n\n\n2.2.1 Inspect structure\nHere, str() is used to reveal the structure of mc1_data object.\n\nstr(mc1_data, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "title": "Take-home Exercise 2",
    "section": "2.3 Extracting the edges and nodes tables",
    "text": "2.3 Extracting the edges and nodes tables\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from mc1_data object into two separate tibble data frames called mc1_nodes_raw and mc1_edges_raw respectively.\n\nmc1_nodes_raw &lt;- as_tibble(mc1_data$nodes)\nglimpse(mc1_nodes_raw)\n\nRows: 17,412\nColumns: 10\n$ `Node Type`    &lt;chr&gt; \"Song\", \"Person\", \"Person\", \"Person\", \"RecordLabel\", \"S…\n$ name           &lt;chr&gt; \"Breaking These Chains\", \"Carlos Duffy\", \"Min Qin\", \"Xi…\n$ single         &lt;lgl&gt; TRUE, NA, NA, NA, NA, FALSE, NA, NA, NA, NA, TRUE, NA, …\n$ release_date   &lt;chr&gt; \"2017\", NA, NA, NA, NA, \"2026\", NA, NA, NA, NA, \"2020\",…\n$ genre          &lt;chr&gt; \"Oceanus Folk\", NA, NA, NA, NA, \"Lo-Fi Electronica\", NA…\n$ notable        &lt;lgl&gt; TRUE, NA, NA, NA, NA, TRUE, NA, NA, NA, NA, TRUE, NA, N…\n$ id             &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ written_date   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020\", NA, NA,…\n$ stage_name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ notoriety_date &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\nkable(head(mc1_nodes_raw, 5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type\nname\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\n\n\n\n\nSong\nBreaking These Chains\nTRUE\n2017\nOceanus Folk\nTRUE\n0\nNA\nNA\nNA\n\n\nPerson\nCarlos Duffy\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\n\n\nPerson\nMin Qin\nNA\nNA\nNA\nNA\n2\nNA\nNA\nNA\n\n\nPerson\nXiuying Xie\nNA\nNA\nNA\nNA\n3\nNA\nNA\nNA\n\n\nRecordLabel\nNautical Mile Records\nNA\nNA\nNA\nNA\n4\nNA\nNA\nNA\n\n\n\n\n\n\nmc1_edges_raw &lt;- as_tibble(mc1_data$links)\n\nglimpse(mc1_edges_raw)\n\nRows: 37,857\nColumns: 4\n$ `Edge Type` &lt;chr&gt; \"InterpolatesFrom\", \"RecordedBy\", \"PerformerOf\", \"Composer…\n$ source      &lt;int&gt; 0, 0, 1, 1, 2, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ target      &lt;int&gt; 1841, 4, 0, 16180, 0, 16180, 0, 5088, 14332, 11677, 2479, …\n$ key         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\nkable(head(mc1_edges_raw, 5))\n\n\n\n\nEdge Type\nsource\ntarget\nkey\n\n\n\n\nInterpolatesFrom\n0\n1841\n0\n\n\nRecordedBy\n0\n4\n0\n\n\nPerformerOf\n1\n0\n0\n\n\nComposerOf\n1\n16180\n0\n\n\nPerformerOf\n2\n0\n0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#data-overview",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#data-overview",
    "title": "Take-home Exercise 2",
    "section": "2.4 Data Overview",
    "text": "2.4 Data Overview\nBefore proceeding to data pre-processing, we examine the data to gain a clearer understanding of the dataset and to verify the structural integrity of the imported graph.\nIn this code chunk below, ggplot2 functions are used the reveal the frequency distribution of Node Type field of mc1_nodes_raw.\n\nggplot(data = mc1_nodes_raw,\n       aes(y = `Node Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nOn the other hand, code chunk below uses ggplot2 functions to reveal the frequency distribution of Edge Type field of mc1_edges_raw.\n\nggplot(data = mc1_edges_raw,\n       aes(y = `Edge Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#adding-identifying-columns",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#adding-identifying-columns",
    "title": "Take-home Exercise 2",
    "section": "3.1 Adding identifying columns",
    "text": "3.1 Adding identifying columns\nAs a large part of this mini-challenge centers around Sailor Shift and the genre of “Oceanus Folk”, the following code will add columns to help with identification and filtering of Sailor Shift and the work in the genre of “Oceanus Folk”. This will help with analysis in addressing the questions and tasks.\n\nmc1_nodes_raw &lt;- mc1_nodes_raw %&gt;%\n  mutate(\n    is_sailor = (\n      str_detect(name, regex(\"sailor shift\", ignore_case = TRUE))\n    ) %&gt;% replace_na(FALSE),\n    \n    is_oceanus_folk = str_detect(genre, regex(\"oceanus folk\", ignore_case = TRUE)) %&gt;% #na/not oceanus folk = false\n      replace_na(FALSE)\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#converting-date-field",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#converting-date-field",
    "title": "Take-home Exercise 2",
    "section": "3.2 Converting date field",
    "text": "3.2 Converting date field\nDate fields will be converted from chr to int for later analysis. Note that dates only appear for Song and Album.\n\nmc1_nodes_raw &lt;- mc1_nodes_raw %&gt;%\n  mutate(across(c(release_date, notoriety_date, written_date),\n                ~as.integer(if_else(`Node Type` %in% c(\"Song\", \"Album\"), ., NA_character_))))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#check-for-duplicates",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#check-for-duplicates",
    "title": "Take-home Exercise 2",
    "section": "3.3 Check for duplicates",
    "text": "3.3 Check for duplicates\n\n3.3.1 Check for duplicates in mc1_nodes_raw\nThe following code chunk checks for id duplicates in mc1_nodes_raw.\n\nmc1_nodes_raw %&gt;%\n  count(id) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: id &lt;int&gt;, n &lt;int&gt;\n\n\nThere are no duplicated id in mc1_nodes_raw.\nThe following code checks for name duplicates in mc1_nodes_raw.\n\nduplicated_name &lt;- mc1_nodes_raw %&gt;%\n  count(name) %&gt;%\n  filter(n &gt; 1)\n\nduplicated_name\n\n# A tibble: 1,611 × 2\n   name                 n\n   &lt;chr&gt;            &lt;int&gt;\n 1 Agata Records        2\n 2 Ancestral Echoes     2\n 3 Angela Thompson      2\n 4 Anthony Davis        2\n 5 Anthony Smith        2\n 6 Asuka Takahashi      3\n 7 Brandon Wilson       2\n 8 Brian Gonzalez       2\n 9 Bryan Garcia         2\n10 Bryan Smith          3\n# ℹ 1,601 more rows\n\n\nThe following code chunk shows all rows from mc1_nodes_raw that have duplicated names, and sorting them alphabetically by the name column. There are a total of 4,953 records with duplicated names in mc1_nodes_raw.\n\nmc1_nodes_raw %&gt;%\n  filter(name %in% duplicated_name$name) %&gt;%\n  arrange(name)\n\n# A tibble: 4,953 × 12\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 RecordLabel Agata Recor… NA               NA &lt;NA&gt;  NA       1528           NA\n 2 RecordLabel Agata Recor… NA               NA &lt;NA&gt;  NA      17388           NA\n 3 Song        Ancestral E… TRUE           1991 Drea… FALSE   11793           NA\n 4 Song        Ancestral E… FALSE          2039 Avan… TRUE    17133           NA\n 5 Person      Angela Thom… NA               NA &lt;NA&gt;  NA       1150           NA\n 6 Person      Angela Thom… NA               NA &lt;NA&gt;  NA      13448           NA\n 7 Person      Anthony Dav… NA               NA &lt;NA&gt;  NA       8692           NA\n 8 Person      Anthony Dav… NA               NA &lt;NA&gt;  NA      12452           NA\n 9 Person      Anthony Smi… NA               NA &lt;NA&gt;  NA       5719           NA\n10 Person      Anthony Smi… NA               NA &lt;NA&gt;  NA       7694           NA\n# ℹ 4,943 more rows\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n\n3.3.2 Fixing duplicates in mc1_nodes_raw\nThe section will focus on fixing the duplicates found in mc1_nodes_raw as identified in section 3.3.1.\nThe following code chunk will tag each row with a unique key (group_key) based on its respective column values. This helps to identify unique records.\n\n# Step 1: Mark all node rows with a hash key for grouping\nmc1_nodes_tagged &lt;- mc1_nodes_raw %&gt;%\n  mutate(group_key = paste(`Node Type`, name, single, release_date, genre,\n                           notable, written_date, notoriety_date, is_sailor,\n                           is_oceanus_folk, sep = \"|\"))\n\nmc1_nodes_tagged\n\n# A tibble: 17,412 × 13\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 Song        Breaking Th… TRUE           2017 Ocea… TRUE        0           NA\n 2 Person      Carlos Duffy NA               NA &lt;NA&gt;  NA          1           NA\n 3 Person      Min Qin      NA               NA &lt;NA&gt;  NA          2           NA\n 4 Person      Xiuying Xie  NA               NA &lt;NA&gt;  NA          3           NA\n 5 RecordLabel Nautical Mi… NA               NA &lt;NA&gt;  NA          4           NA\n 6 Song        Unshackled … FALSE          2026 Lo-F… TRUE        5           NA\n 7 Person      Luke Payne   NA               NA &lt;NA&gt;  NA          6           NA\n 8 Person      Xiulan Zeng  NA               NA &lt;NA&gt;  NA          7           NA\n 9 Person      David Frank… NA               NA &lt;NA&gt;  NA          8           NA\n10 RecordLabel Colline-Cas… NA               NA &lt;NA&gt;  NA          9           NA\n# ℹ 17,402 more rows\n# ℹ 5 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;, group_key &lt;chr&gt;\n\n\nThe code below deduplicates the dataset using group_key, reducing the number of duplicated names from 4,953 to 14. The remaining 14 names appear more than once because their corresponding records differ in at least one column used to form group_key, so they are retained as distinct entries.\n\n# Step 2: Deduplicate and keep the preferred (with stage_name if available)\nmc1_nodes_dedup &lt;- mc1_nodes_tagged %&gt;%\n  group_by(group_key) %&gt;%\n  arrange(desc(!is.na(stage_name))) %&gt;%\n  slice(1) %&gt;%\n  ungroup()\n\nduplicated_name &lt;- mc1_nodes_dedup %&gt;%\n  count(name) %&gt;%\n  filter(n &gt; 1)\n\nmc1_nodes_raw %&gt;%\n  filter(name %in% duplicated_name$name) %&gt;%\n  arrange(name)\n\n# A tibble: 14 × 12\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 Song        Ancestral E… TRUE           1991 Drea… FALSE   11793           NA\n 2 Song        Ancestral E… FALSE          2039 Avan… TRUE    17133           NA\n 3 RecordLabel Coastal Ech… NA               NA &lt;NA&gt;  NA       4022           NA\n 4 Album       Coastal Ech… NA             2023 Psyc… TRUE    15065         2019\n 5 Song        Postcards f… TRUE           2023 Indi… TRUE    12852         2023\n 6 Song        Postcards f… FALSE          1984 Acou… FALSE   17214           NA\n 7 Album       Shattered R… NA             2013 Emo/… TRUE     3325         2013\n 8 Song        Shattered R… FALSE          2036 Dark… TRUE    17088           NA\n 9 Song        Unheard Fre… TRUE           2025 Alte… TRUE     7999           NA\n10 RecordLabel Unheard Fre… NA               NA &lt;NA&gt;  NA      10952           NA\n11 Song        Vanishing P… TRUE           2018 Avan… TRUE     9371         2018\n12 Song        Vanishing P… FALSE          2013 Ocea… FALSE   17338           NA\n13 RecordLabel Vertical Ho… NA               NA &lt;NA&gt;  NA       2453           NA\n14 Album       Vertical Ho… NA             2017 Doom… TRUE     9262           NA\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n\n3.3.3 Check for duplicates in mc1_edges_raw\nThe following code proceeds to check for duplicates in mc1_edges_raw.\n\n# Step 1: Identify duplicate combinations\nduplicate_summary &lt;- mc1_edges_raw %&gt;%\n  count(source, target, `Edge Type`) %&gt;%\n  filter(n &gt; 1)\n\n# Step 2: Join back to get all original duplicate rows\nmc1_edges_raw %&gt;%\n  inner_join(duplicate_summary, by = c(\"source\", \"target\", \"Edge Type\"))\n\n# A tibble: 6 × 5\n  `Edge Type` source target   key     n\n  &lt;chr&gt;        &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 PerformerOf  17057  17058     0     2\n2 PerformerOf  17057  17058     1     2\n3 PerformerOf  17349  17350     0     2\n4 PerformerOf  17349  17350     2     2\n5 PerformerOf  17355  17356     0     2\n6 PerformerOf  17355  17356     2     2\n\n\nThere are duplicates as seen above, with only differences in key. As key will not be used in subsequent data analysis, the duplicated edges will be removed with the following code.\n\nmc1_edges_raw &lt;- mc1_edges_raw %&gt;%\n  distinct(source, target, `Edge Type`, .keep_all = TRUE) %&gt;%\n  select(!key)\n\nmc1_edges_raw %&gt;%\n  count(source, target, `Edge Type`) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 4\n# ℹ 4 variables: source &lt;int&gt;, target &lt;int&gt;, Edge Type &lt;chr&gt;, n &lt;int&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#explore-and-inspect-nodes",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#explore-and-inspect-nodes",
    "title": "Take-home Exercise 2",
    "section": "4.1 Explore and inspect Nodes",
    "text": "4.1 Explore and inspect Nodes\n\nmc1_nodes_raw$release_date %&gt;% unique()\n\n [1] 2017   NA 2026 2020 2027 2022 2007 2010 2003 2023 1997 2013 2000 2025 2029\n[16] 2015 2018 2016 2014 2028 2021 2030 2011 1994 2004 1998 1991 1999 2024 2012\n[31] 2002 2006 2008 2019 1995 1989 2032 2009 2001 1996 1990 1984 2005 1993 1986\n[46] 1985 1981 1992 1987 1988 1983 2031 1975 2035 2033 2037 2036 2039 2038 2034\n[61] 1977 1979 1980 1982 2040\n\nmc1_nodes_raw %&gt;%\n  filter(grepl(\"Sailor Shift\", name)) #Sailor Shift is in name column and not in stage_name column\n\n# A tibble: 1 × 12\n  `Node Type` name         single release_date genre notable    id written_date\n  &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n1 Person      Sailor Shift NA               NA &lt;NA&gt;  NA      17255           NA\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n' will be removed from name to prevent issues with tooltip in tidygraph.\n\nmc1_nodes_clean &lt;- mc1_nodes_raw %&gt;%\n  mutate(\n    name = gsub(\"'\", \"\", name)) \n  \nkable(head(mc1_nodes_clean))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type\nname\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\nis_sailor\nis_oceanus_folk\n\n\n\n\nSong\nBreaking These Chains\nTRUE\n2017\nOceanus Folk\nTRUE\n0\nNA\nNA\nNA\nFALSE\nTRUE\n\n\nPerson\nCarlos Duffy\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nPerson\nMin Qin\nNA\nNA\nNA\nNA\n2\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nPerson\nXiuying Xie\nNA\nNA\nNA\nNA\n3\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nRecordLabel\nNautical Mile Records\nNA\nNA\nNA\nNA\n4\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nSong\nUnshackled Heart\nFALSE\n2026\nLo-Fi Electronica\nTRUE\n5\nNA\nNA\nNA\nFALSE\nFALSE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#explore-and-inspect-edges",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#explore-and-inspect-edges",
    "title": "Take-home Exercise 2",
    "section": "4.2 Explore and inspect Edges",
    "text": "4.2 Explore and inspect Edges\nThe following code chunk is used to ensure that id used in mc1_edges_raw matches the range range of id in mc1_nodes_clean.\n\nrange(mc1_nodes_clean$id)\n\n[1]     0 17411\n\nrange(mc1_edges_raw$source)\n\n[1]     0 17411\n\nrange(mc1_edges_raw$target)\n\n[1]     0 17411"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#mapping-node-name-to-edges-id",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#mapping-node-name-to-edges-id",
    "title": "Take-home Exercise 2",
    "section": "4.3 Mapping Node name to Edges id",
    "text": "4.3 Mapping Node name to Edges id\ntidygraph uses from and to columns to reference nodes. By default, tidygraph matches these edges reference against the first column in the nodes table, or against name column.\nCurrently, source and target columns in mc1_edges_raw contain id values that correspond to the id column in mc1_nodes_clean. To properly integrate with tidygraph’s conventions, the following will be done:\n\nRestructure mc1_nodes_clean\n\nRename the current name column to node_name - this is done to preserve the actual node names\nRename the id column to name so it becomes the primary identifier column that tidygraph will use for matching\n\nRename source and target columns in mc1_edges_raw, as required by tidygraph\nEnsure data type consistency: Convert the name column (formerly id) to character format to match the data type of the edge references\n\n\nmc1_nodes_clean &lt;- mc1_nodes_dedup %&gt;%\n  rename(node_name = name, name = id) %&gt;%\n  mutate(name = as.character(name)) %&gt;%\n  select(`Node Type`, node_name, release_date, genre, notable, name, single, written_date, stage_name, notoriety_date, is_sailor, is_oceanus_folk)\n\nmc1_nodes_clean\n\n# A tibble: 14,077 × 12\n   `Node Type` node_name    release_date genre notable name  single written_date\n   &lt;chr&gt;       &lt;chr&gt;               &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;chr&gt; &lt;lgl&gt;         &lt;int&gt;\n 1 Album       A Lush Dyst…         2031 Psyc… TRUE    17005 NA             2030\n 2 Album       Addicted to…         2004 Sout… TRUE    14658 NA             2000\n 3 Album       Adriatic Em…         2013 Post… TRUE    10412 NA               NA\n 4 Album       Aerial Echo…         2023 Indi… TRUE    7908  NA               NA\n 5 Album       Aftershock …         2028 Drea… TRUE    2030  NA             2021\n 6 Album       Allegretto …         2020 Indi… TRUE    6251  NA               NA\n 7 Album       Alleys and …         2029 Jazz… TRUE    1310  NA               NA\n 8 Album       Alloy Archi…         2017 Indi… TRUE    8428  NA             2017\n 9 Album       Almost (But…         2027 Alte… TRUE    14611 NA             2027\n10 Album       Altar of De…         2020 Ocea… TRUE    5883  NA               NA\n# ℹ 14,067 more rows\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n4.3.1 Creating edge mapping from old id to kept id\nIn section 3.3.2, duplicated nodes were deduplicated and removed, edges referring to the removed nodes will become invalid thus, edges will be remapped to the retained nodes. This ensures that all edges correctly point to existing nodes in the deduplicated graph.\n\n# Step 1: Create mapping of all group_key → kept id\nkey_to_id_map &lt;- mc1_nodes_dedup %&gt;%\n  select(group_key, kept_id = id)\n\n# Step 2: Map all original rows to the retained ID\nid_remap &lt;- mc1_nodes_tagged %&gt;%\n  left_join(key_to_id_map, by = \"group_key\") %&gt;%\n  select(original_id = id, kept_id)\n\nid_remap\n\n# A tibble: 17,412 × 2\n   original_id kept_id\n         &lt;int&gt;   &lt;int&gt;\n 1           0       0\n 2           1       1\n 3           2   14470\n 4           3       3\n 5           4       4\n 6           5       5\n 7           6       6\n 8           7       7\n 9           8       8\n10           9       9\n# ℹ 17,402 more rows\n\n\n\n# Step 3: Replace edges' source and target with mapped kept_id\nmc1_edges_mapped &lt;- mc1_edges_raw %&gt;%\n  left_join(id_remap, by = c(\"source\" = \"original_id\"))\n\nmc1_edges_mapped\n\n# A tibble: 37,854 × 4\n   `Edge Type`      source target kept_id\n   &lt;chr&gt;             &lt;int&gt;  &lt;int&gt;   &lt;int&gt;\n 1 InterpolatesFrom      0   1841       0\n 2 RecordedBy            0      4       0\n 3 PerformerOf           1      0       1\n 4 ComposerOf            1  16180       1\n 5 PerformerOf           2      0   14470\n 6 ProducerOf            2  16180   14470\n 7 PerformerOf           3      0       3\n 8 InterpolatesFrom      5   5088       5\n 9 InStyleOf             5  14332       5\n10 InterpolatesFrom      5  11677       5\n# ℹ 37,844 more rows\n\n\n\nmc1_edges_mapped &lt;- mc1_edges_mapped %&gt;%\n  mutate(source = kept_id) %&gt;%\n  select(-kept_id) %&gt;%\n  left_join(id_remap, by = c(\"target\" = \"original_id\")) %&gt;%\n  mutate(target = kept_id) %&gt;%\n  select(-kept_id) %&gt;%\n  rename(from = source, to = target) %&gt;%\n  mutate(from = as.character(from), to = as.character(to))\n\nmc1_edges_mapped\n\n# A tibble: 37,854 × 3\n   `Edge Type`      from  to   \n   &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;\n 1 InterpolatesFrom 0     1841 \n 2 RecordedBy       0     4    \n 3 PerformerOf      1     0    \n 4 ComposerOf       1     16180\n 5 PerformerOf      14470 0    \n 6 ProducerOf       14470 16180\n 7 PerformerOf      3     0    \n 8 InterpolatesFrom 5     5088 \n 9 InStyleOf        5     14332\n10 InterpolatesFrom 5     11677\n# ℹ 37,844 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#remove-unmatched-edges",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#remove-unmatched-edges",
    "title": "Take-home Exercise 2",
    "section": "4.4 Remove unmatched edges",
    "text": "4.4 Remove unmatched edges\nThe following code chunk removes edges that reference missing node id, ensuring that only valid edges are kept.\n\nmc1_edges_clean &lt;- mc1_edges_mapped %&gt;%\n  filter(!is.na(from), !is.na(to))\n\nThere are no unmatched edges."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#check-for-missing-nodes",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#check-for-missing-nodes",
    "title": "Take-home Exercise 2",
    "section": "4.5 Check for missing nodes",
    "text": "4.5 Check for missing nodes\nThe following code chunk checks for missing nodes being referenced in mc1_edges_clean that do not exist in mc1_nodes_clean.\n\nsetdiff(\n  unique(c(mc1_edges_clean$from, mc1_edges_clean$to)),\n  mc1_nodes_clean$name\n)\n\ncharacter(0)\n\n\nThere are no missing nodes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#validate-edges-schema",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#validate-edges-schema",
    "title": "Take-home Exercise 2",
    "section": "4.6 Validate Edges Schema",
    "text": "4.6 Validate Edges Schema\nThis section aims to ensure that each edge in the graph adheres to the schema specified in the VAST Challenge 2025 MC1 Data Description document. The following code checks whether the node types connect by each edge matches the valid source and target types for that edge’s type.\n\n# Define valid source and destination types for each edge type\nedge_rules &lt;- list(\n  PerformerOf = list(source = c(\"Person\", \"MusicalGroup\"), target = c(\"Song\", \"Album\")),\n  ComposerOf = list(source = c(\"Person\"), target = c(\"Song\", \"Album\")),\n  ProducerOf = list(source = c(\"Person\", \"RecordLabel\"), target = c(\"Song\", \"Album\", \"Person\", \"MusicalGroup\")),\n  LyricistOf = list(source = c(\"Person\"), target = c(\"Song\", \"Album\")),\n  RecordedBy = list(source = c(\"Song\", \"Album\"), target = c(\"RecordLabel\")),\n  DistributedBy = list(source = c(\"Song\", \"Album\"), target = c(\"RecordLabel\")),\n  InStyleOf = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\", \"Person\", \"MusicalGroup\")),\n  InterpolatesFrom = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  CoverOf = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  LyricalReferenceTo = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  DirectlySamples = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  MemberOf = list(source = c(\"Person\"), target = c(\"MusicalGroup\"))\n)\n\nThe following code chunk checks for any erroneous edge and node relationships defined in the code chunk above.\n\n# Create a lookup for node types\nnode_type_lookup &lt;- mc1_nodes_clean %&gt;%\n  select(name, `Node Type`) %&gt;%\n  deframe()\n\n# Add source and target node types to the edge table\nmc1_edges_checked &lt;- mc1_edges_clean %&gt;%\n  mutate(\n    source_type = node_type_lookup[from],\n    target_type = node_type_lookup[to]\n  )\n\nmc1_edges_tagged &lt;- mc1_edges_checked %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    valid = {\n      rule &lt;- edge_rules[[`Edge Type`]]\n      if (is.null(rule)) TRUE\n      else {\n        source_type %in% rule$source && target_type %in% rule$target\n      }\n    }\n  ) %&gt;%\n  ungroup()\n\n# Count and display invalid edge combinations\ninvalid_edge_summary &lt;- mc1_edges_tagged %&gt;%\n  filter(!valid) %&gt;%\n  count(`Edge Type`, source_type, target_type, sort = TRUE)\n\nprint(invalid_edge_summary)\n\n# A tibble: 24 × 4\n   `Edge Type`      source_type  target_type      n\n   &lt;chr&gt;            &lt;chr&gt;        &lt;chr&gt;        &lt;int&gt;\n 1 LyricistOf       MusicalGroup Song           106\n 2 RecordedBy       RecordLabel  Album          102\n 3 ProducerOf       MusicalGroup Song           100\n 4 ComposerOf       MusicalGroup Song            97\n 5 ProducerOf       MusicalGroup Album           31\n 6 LyricistOf       MusicalGroup Album           28\n 7 ComposerOf       MusicalGroup Album           17\n 8 InStyleOf        MusicalGroup MusicalGroup    12\n 9 InStyleOf        Person       MusicalGroup    11\n10 InterpolatesFrom MusicalGroup MusicalGroup    10\n# ℹ 14 more rows\n\n\n\n# Check total invalid edge count\ncat(\"Total invalid edges:\", sum(!mc1_edges_tagged$valid), \"\\n\")\n\nTotal invalid edges: 550 \n\n\nThere are 550 edges that do not adhere to the schema specified in the data description file provided. The following code will remove these edges.\n\n# Keep only valid edges\nmc1_edges_clean &lt;- mc1_edges_tagged %&gt;%\n  filter(valid) %&gt;%\n  select(from, to, `Edge Type`)  # drop helper columns"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#visualising-edge-and-node-types",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#visualising-edge-and-node-types",
    "title": "Take-home Exercise 2",
    "section": "4.7 Visualising Edge and Node types",
    "text": "4.7 Visualising Edge and Node types\n\nggplot(data = mc1_edges_clean,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = mc1_nodes_clean,\n       aes(y = `Node Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#creating-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#creating-knowledge-graph",
    "title": "Take-home Exercise 2",
    "section": "4.8 Creating knowledge graph",
    "text": "4.8 Creating knowledge graph\ntbl_graph() is used to create tidygraph’s graph object by using the following code chunk.\n\nmusic = tbl_graph(edges = mc1_edges_clean,\n                             nodes = mc1_nodes_clean,\n                             directed = TRUE)\n\nclass(music)\n\n[1] \"tbl_graph\" \"igraph\"   \n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1a---who-has-she-been-most-influenced-by-over-time",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1a---who-has-she-been-most-influenced-by-over-time",
    "title": "Take-home Exercise 2",
    "section": "5.1 Question 1a - Who has she been most influenced by over time?",
    "text": "5.1 Question 1a - Who has she been most influenced by over time?\nThe network structure below shows how Sailor Shift’s career has been influenced by others. PageRank is used to measure the overall influence of each person, musical group or work within the network. This captures both direct and indirect influences.\n\nNetwork VisualisationInfluence Summary\n\n\n\n\nCode\n# Step 0: Get name of 'Sailor Shift'\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;%\n  first()\n\n# Step 1: Find direct influence relationships from Sailor Shift\n# These are the artists/works that Sailor Shift has been influenced by\ndirect_influence_types &lt;- c(\"InStyleOf\", \"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\")\n\nsailor_direct_influences &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name, \n         `Edge Type` %in% direct_influence_types)\n\n# Step 2: Get immediate neighbors (people/groups Sailor Shift works with)\nsailor_out_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name)\n\nsailor_out_node_names &lt;- sailor_out_edges$to\n\n# Step 3: Split into people/groups vs songs/albums\nsailor_person_group &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_out_node_names, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\nsailor_songs_all &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_out_node_names, `Node Type` %in% c(\"Song\", \"Album\")) %&gt;%\n  pull(name)\n\n# Step 4: For songs/albums, find their direct influences too\nsong_influences &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs_all, \n         `Edge Type` %in% direct_influence_types)\n\n# Step 5: Get all influence targets (who influenced Sailor Shift or their works)\nall_influence_targets &lt;- unique(c(\n  sailor_direct_influences$to,\n  song_influences$to\n))\n\n# Step 6: Get creators of Sailor Shift's works (indirect influence indicators)\ncreator_edge_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\")\n\nsailor_songs &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs_all) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\nsailor_songs_out_nodes &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs) %&gt;%\n  pull(to)\n\ncreator_edges &lt;- mc1_edges_clean %&gt;%\n  filter(to %in% sailor_songs_out_nodes, `Edge Type` %in% creator_edge_types)\n\nsailor_people_group_neighbourhood_nodes &lt;- creator_edges %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 7: Combine all relevant nodes for subgraph\nsailor_all_node_names &lt;- unique(c(\n  sailor_vertex_name,\n  sailor_person_group,\n  sailor_songs,\n  sailor_songs_out_nodes,\n  sailor_people_group_neighbourhood_nodes,\n  all_influence_targets  \n))\n\n# Step 8: Create subgraph\nsub_music &lt;- music %&gt;%\n  filter(name %in% sailor_all_node_names)\n\n# Step 9: Calculate PageRank \nsub_music &lt;- sub_music %&gt;%\n  activate(nodes) %&gt;%\n  mutate(\n    pagerank = centrality_pagerank()\n  )\n\n# Step 10: Set node size based on PageRank for people/groups, fixed for others\nsub_music &lt;- sub_music %&gt;%\n  mutate(\n    is_sailor = name == sailor_vertex_name,\n    node_color = ifelse(is_sailor, \"red\", \"grey30\"),\n    tooltip_text = sprintf(\n      \"Name: %s\\nType: %s\\nPageRank: %.4f\",\n      node_name, `Node Type`, pagerank\n    ),\n    node_size = case_when(\n      `Node Type` %in% c(\"Person\", \"MusicalGroup\") ~ rescale(pagerank, to = c(4, 20)),\n      TRUE ~ 4  \n    )\n  )\n\n# Step 11: Create visualization\ng &lt;- sub_music %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(\n    aes(color = `Edge Type`), \n    alpha = 0.3,\n    arrow = arrow(length = unit(3, 'mm')),\n    end_cap = circle(3, 'mm')\n  ) +\n  geom_point_interactive(\n    aes(\n      x = x, y = y,\n      data_id = name,\n      tooltip = tooltip_text,\n      shape = `Node Type`,\n      colour = node_color,\n      size = node_size\n    )\n  ) +\n  scale_shape_discrete(name = \"Node Type\") +\n  scale_colour_identity() +\n  scale_size_identity() +\n  theme_graph(base_family = \"sans\") +\n  labs(\n    title = \"Network of Influences on Sailor Shift\"\n  )\n\ngirafe(ggobj = g, width_svg = 10, height_svg = 8)\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to people and groups only, exclude Sailor Shift node itself\ntop_influencers &lt;- sub_music %&gt;%\n  as_tibble() %&gt;%\n  filter(\n    `Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n    name != sailor_vertex_name\n  ) %&gt;%\n  arrange(desc(pagerank)) %&gt;%\n  slice_head(n = 5)\n\n# Plot\nggplot(top_influencers, aes(x = reorder(node_name, pagerank), y = pagerank, fill = `Node Type`)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    title = \"Top 5 Influences on Sailor Shift\",\n    x = \"Influencer\",\n    y = \"PageRank Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the PageRank score, it is noted that she is most influenced by musical groups as the top 3 most influences are musical groups. Phantom Roots have influenced her the most over time, this is followed by Ursus and the group she was a part of, Ivy Echos."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1b---who-has-she-collaborated-with-and-directly-or-indirectly-influenced",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1b---who-has-she-collaborated-with-and-directly-or-indirectly-influenced",
    "title": "Take-home Exercise 2",
    "section": "5.2 Question 1b - Who has she collaborated with and directly or indirectly influenced?",
    "text": "5.2 Question 1b - Who has she collaborated with and directly or indirectly influenced?\nThe network visualisation below explores Sailor Shift’s collaborations and influence. While the primary question centers on Sailor Shift, the analysis also incorporates Ivy Echos, the musical group that she was a member of. Including Ivy Echos is essential because Sailor Shift’s creative impact can extend beyond her solo work as her contributions as part of Ivy Echos could have influenced others. The visualisation therefore highlights not just individuals and groups who have collaborated with Sailor Shift on her works, but also those influenced by Ivy Echos, providing an extensive picture of her influence.\n\n\nCode\n# Step 1: Define all relevant edge types per schema\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\ninfluence_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\n# Step 2: Get Sailor Shift's node ID\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;% first()\n\n# Step 3: Find all Sailor Shift's works (songs/albums she performed or was lyricist of)\nsailor_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% c(\"PerformerOf\", \"LyricistOf\"), from == sailor_vertex_name) %&gt;%\n  pull(to)\n\n# Step 4: Find all Person/MusicalGroup collaborated on Sailor Shift's works (excluding herself)\nsailor_collab_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, to %in% sailor_works, from != sailor_vertex_name)\nsailor_collab_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_collab_edges$from, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\n# Step 5: Get Ivy Echos's node ID and works\nivy_echos_name &lt;- mc1_nodes_clean %&gt;%\n  filter(str_detect(node_name, regex(\"Ivy Echos\", ignore_case = TRUE))) %&gt;%\n  pull(name) %&gt;% first()\nivy_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` == \"PerformerOf\", from == ivy_echos_name) %&gt;%\n  pull(to)\nivy_works &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% ivy_works, `Node Type` %in% c(\"Song\", \"Album\")) %&gt;%\n  pull(name)\n\n# Step 6: Find all works influenced by Ivy Echos's works (Ivy Echos's works as destination of influence edges)\nivy_influenced_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_types, to %in% ivy_works)\nivy_influenced_works &lt;- ivy_influenced_edges$from\n\n# Step 7: For each influenced work, get the people/groups involved (collaborators on those works)\nivy_influenced_collab_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, to %in% ivy_influenced_works)\nivy_influenced_collab_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% ivy_influenced_collab_edges$from, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\n# Step 8: Collect all relevant nodes and edges for the network\nall_relevant_nodes &lt;- unique(c(\n  sailor_vertex_name,\n  sailor_collab_nodes,\n  sailor_works,\n  ivy_echos_name,\n  ivy_works,\n  ivy_influenced_works,\n  ivy_influenced_collab_nodes\n))\n\nall_relevant_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% all_relevant_nodes & to %in% all_relevant_nodes)\n\n# Step 9: Annotate node roles for plotting\nsub_nodes_df &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% all_relevant_nodes) %&gt;%\n  mutate(\n    node_role = case_when(\n      name == sailor_vertex_name ~ \"Sailor Shift\",\n      name == ivy_echos_name ~ \"Ivy Echos\",\n      name %in% sailor_collab_nodes ~ \"Sailor Shift Collaborator\",\n      name %in% sailor_works ~ \"Sailor Shift Work\",\n      name %in% ivy_works ~ \"Ivy Echos Work\",\n      name %in% ivy_influenced_works ~ \"Work Influenced by Ivy Echos\",\n      name %in% ivy_influenced_collab_nodes ~ \"Person/Group in Influenced Work\",\n      TRUE ~ \"Other\"\n    ),\n    node_color = case_when(\n      node_role == \"Sailor Shift\" ~ \"red\",\n      node_role == \"Ivy Echos\" ~ \"purple\",\n      node_role == \"Sailor Shift Collaborator\" ~ \"blue\",\n      node_role == \"Sailor Shift Work\" ~ \"grey30\",\n      node_role == \"Ivy Echos Work\" ~ \"green\",\n      node_role == \"Work Influenced by Ivy Echos\" ~ \"orange\",\n      node_role == \"Person/Group in Influenced Work\" ~ \"pink\",\n      TRUE ~ \"steelblue\"\n    ),\n    tooltip_text = paste0(\n      \"Name: \", node_name, \"\\n\",\n      \"Type: \", `Node Type`, \"\\n\",\n      \"Role: \", node_role, \"\\n\",\n      ifelse(!is.na(genre), paste0(\"Genre: \", genre, \"\\n\"), \"\"),\n      ifelse(!is.na(release_date), paste0(\"Release: \", release_date, \"\\n\"), \"\")\n    )\n  )\n\n# Step 10: Create tidygraph object and layout\ncareer_graph &lt;- tbl_graph(nodes = sub_nodes_df, edges = all_relevant_edges, directed = TRUE) %&gt;%\n  activate(nodes)\n\nlayout_df &lt;- create_layout(career_graph, layout = \"fr\") %&gt;%\n  as_tibble() %&gt;%\n  select(name, x, y)\n\nnodes_plot &lt;- as_tibble(career_graph) %&gt;%\n  left_join(layout_df, by = \"name\")\n\nedges_plot &lt;- all_relevant_edges %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n  rename(x_from = x, y_from = y) %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n  rename(x_to = x, y_to = y)\n\n# Step 11: Get coordinates for annotation\nsailor_coords &lt;- nodes_plot %&gt;%\n  filter(name == sailor_vertex_name) %&gt;%\n  select(x, y)\nivy_coords &lt;- nodes_plot %&gt;%\n  filter(name == ivy_echos_name) %&gt;%\n  select(x, y)\n\n# Step 12: Plot with ggplot2 + ggiraph, with annotation and legend\np &lt;- ggplot() +\n  geom_segment(\n    data = edges_plot,\n    aes(\n      x = x_from, y = y_from, xend = x_to, yend = y_to,\n      color = `Edge Type`\n    ),\n    alpha = 0.4, arrow = arrow(length = unit(3, 'mm'))\n  ) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Edge Type\") +\n  ggnewscale::new_scale_color() +\n  geom_point_interactive(\n    data = nodes_plot,\n    aes(\n      x = x, y = y,\n      tooltip = tooltip_text,\n      data_id = name,\n      color = node_role,  \n      shape = `Node Type`\n    ),\n    size = 4\n  ) +\n  scale_color_manual(\n    name = \"Node Role\",\n    values = c(\n      \"Sailor Shift\" = \"red\",\n      \"Ivy Echos\" = \"purple\", \n      \"Sailor Shift Collaborator\" = \"blue\",\n      \"Sailor Shift Work\" = \"grey30\",\n      \"Ivy Echos Work\" = \"green\",\n      \"Work Influenced by Ivy Echos\" = \"orange\",\n      \"Person/Group in Influenced Work\" = \"pink\",\n      \"Other\" = \"steelblue\"\n    ),\n    breaks = c(\n      \"Sailor Shift\",\n      \"Ivy Echos\", \n      \"Sailor Shift Collaborator\",\n      \"Sailor Shift Work\",\n      \"Ivy Echos Work\",\n      \"Work Influenced by Ivy Echos\",\n      \"Person/Group in Influenced Work\"\n    )\n  ) +\n  theme_void() +\n  labs(title = \"Sailor Shift's Collaborators and Influence\") +\n  guides(\n    color = guide_legend(\n      title = \"Node Role\",\n      override.aes = list(size = 4),\n      title.position = \"top\"\n    ),\n    shape = guide_legend(\n      title = \"Node Type\",\n      title.position = \"top\"\n    )\n  ) +\n  theme(\n    legend.position = \"right\",\n    legend.box = \"vertical\",\n    plot.title = element_text(size = 20, face = \"bold\") \n  )\n\ngirafe(ggobj = p, width_svg = 12, height_svg = 8)\n\n\n\n\n\n\nThe visualisation shows a wide array of individuals and musical groups who have collaborated with Sailor Shift on various works, this reflects her active engagement within the industry. While there are no instances of Sailor Shift directly influencing other artists, the visualisation reveals that her group, Ivy Echos, has influenced a group and four individuals through a song (Deepsea Fireflies, released in 2025). This demonstrates that Sailor Shift’s reach extends beyond her personal collaborations, contributing to a broader legacy through her involvement with Ivy Echos."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1c---how-has-she-influenced-collaborators-of-the-broader-oceanus-folk-community",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1c---how-has-she-influenced-collaborators-of-the-broader-oceanus-folk-community",
    "title": "Take-home Exercise 2",
    "section": "5.3 Question 1c - How has she influenced collaborators of the broader Oceanus Folk community?",
    "text": "5.3 Question 1c - How has she influenced collaborators of the broader Oceanus Folk community?\nThe network visualisation aims to analyse how Sailor Shift influenced collaborators of the broader Oceanus Folk community.\nSailor Shift and her group (Ivy Echos) were primary entities of interest, all works associated to them are compiled to form the foundation of Sailor Shift’s musical output. Based on this, several types of influence were analysed:\n\nDirect influence - This includes Oceanus Folk collaborators’ works that were explicity influenced by Sailor Shift or Ivy Echos through relationships such as CoverOf, InterpolatesFrom, LyricalReferenceTo, DirectlySamples, and InStyleOf.\nIndirect (two-step influence) - This occurs when a work by Sailor Shift or Ivy Echos influences an intermediate piece, which then goes on to influence a work by an Oceanus Folk collaborator. These two-step chains shows how Sailor Shift’s influence can propagate through the network.\nCross-collaborator influence - This captures intra-community influence where Oceanus Folk works that were initially influenced by Sailor Shift/Ivy Echos proceeded to influence other Oceanus Folk creations.\nCollaboration-mediated influence - This is transmitted through shared or bridge collaborators.\n\nShared collaborators are individuals or groups who worked with both Sailor Shift/Ivy Echos and the Oceanus Folk community\nBridge Collaborators are those who first worked with Sailor Shift/Ivy Echos and later collaborated with Ocean Folk Contributors.\n\n\nBased on the influences above, it reveals the full extent of Sailor Shift’s reach within the Oceanus Folk Community.\n\n\nCode\n# Step 1: Define edge types\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\ninfluence_edge_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\n# Step 2: Identify all nodes with genre == \"Oceanus Folk\"\noceanus_folk_works &lt;- mc1_nodes_clean %&gt;%\n  filter(genre == \"Oceanus Folk\") %&gt;%\n  pull(name)\n\n# Step 3: Identify all Person and MusicalGroup who are collaborators on Oceanus Folk works\noceanus_folk_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         to %in% oceanus_folk_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 4: Get Sailor Shift and Ivy Echos\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;% \n  first()\n\nivy_echos_name &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` == \"MemberOf\", from == sailor_vertex_name) %&gt;%\n  pull(to) %&gt;%\n  first()\n\n# Step 5: Find all works that Sailor Shift and Ivy Echos have created/performed\nsailor_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, from == sailor_vertex_name) %&gt;%\n  pull(to)\n\nivy_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, from == ivy_echos_name) %&gt;%\n  pull(to)\n\nsailor_ivy_works &lt;- unique(c(sailor_works, ivy_works))\n\n# Step 6: Find all works that the Oceanus Folk collaborators have worked on\noceanus_collaborator_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         from %in% oceanus_folk_collaborators) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\n# Step 7: Direct influence - Sailor Shift/Ivy Echos works influencing Oceanus collaborator works\ndirect_influence &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works,\n         to %in% oceanus_collaborator_works) %&gt;%\n  mutate(influence_direction = \"Sailor/Ivy → Oceanus\",\n         pathway_type = \"Direct\")\n\n# Step 8: Indirect influence - Multi-step pathways\n\n# 8a: Find intermediate works that could bridge Sailor Shift/Ivy Echos to Oceanus\n# Works influenced BY Sailor/Ivy\nsailor_influenced_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\n# Works that influence Sailor/Ivy  \nsailor_influencing_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         to %in% sailor_ivy_works) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# All intermediate works in potential pathways\nintermediate_works &lt;- unique(c(sailor_influenced_works, sailor_influencing_works))\n\n# 8b: Two-step influence: Sailor/Ivy → Intermediate → Oceanus collaborators\nindirect_influence_step1 &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works,\n         to %in% intermediate_works) %&gt;%\n  select(sailor_work = from, intermediate_work = to, step1_edge_type = `Edge Type`)\n\nindirect_influence_step2 &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% intermediate_works,\n         to %in% oceanus_collaborator_works) %&gt;%\n  select(intermediate_work = from, oceanus_work = to, step2_edge_type = `Edge Type`)\n\n# Join to find complete 2-step pathways\ntwo_step_pathways &lt;- indirect_influence_step1 %&gt;%\n  inner_join(indirect_influence_step2, by = \"intermediate_work\") %&gt;%\n  mutate(pathway_type = \"Indirect (2-step)\",\n         influence_direction = \"Sailor/Ivy → Intermediate → Oceanus\")\n\n# 8c: Cross-collaborator influence within Oceanus community\n# Find Oceanus works that were influenced by Sailor and then influenced other Oceanus works\ndirectly_influenced_oceanus_works &lt;- unique(c(direct_influence$to, two_step_pathways$oceanus_work))\n\ncross_collab_influence &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% directly_influenced_oceanus_works,\n         to %in% oceanus_collaborator_works,\n         from != to) %&gt;%\n  mutate(pathway_type = \"Cross-collaborator\",\n         influence_direction = \"Sailor-influenced Oceanus work → Other Oceanus work\")\n\n# Step 9: Collaboration-mediated influence \n\n# 9a: People who worked with both Sailor/Ivy AND Oceanus Folk collaborators\nsailor_ivy_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         to %in% sailor_ivy_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\nshared_collaborators &lt;- intersect(sailor_ivy_collaborators, oceanus_folk_collaborators)\n\n# 9b. Bridge collaborators - worked with Sailor/Ivy, then later with other Oceanus Folk collaborators\nbridge_collaborators &lt;- setdiff(sailor_ivy_collaborators, oceanus_folk_collaborators)\nbridge_to_oceanus &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         from %in% bridge_collaborators) %&gt;%\n  inner_join(\n    mc1_edges_clean %&gt;%\n      filter(`Edge Type` %in% collab_credit_types,\n             from %in% oceanus_folk_collaborators) %&gt;%\n      select(shared_work = to),\n    by = c(\"to\" = \"shared_work\")\n  ) %&gt;%\n  select(bridge_person = from, shared_work = to) %&gt;%\n  distinct()\n\n# Step 10: Identify influenced Oceanus Folk Collaborators \n\n# Get all works that show influence from Sailor/Ivy\nall_influenced_oceanus_works &lt;- unique(c(\n  direct_influence$to,\n  two_step_pathways$oceanus_work,\n  cross_collab_influence$to\n))\n\n# Find which Oceanus Folk collaborators worked on these influenced works\ndirectly_influenced_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         to %in% all_influenced_oceanus_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n         from %in% oceanus_folk_collaborators) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Add collaborators connected through shared/bridge relationships\ncollaboration_influenced &lt;- unique(c(shared_collaborators, bridge_to_oceanus$bridge_person))\ncollaboration_influenced &lt;- intersect(collaboration_influenced, oceanus_folk_collaborators)\n\ntotal_influenced_collaborators &lt;- unique(c(directly_influenced_collaborators, collaboration_influenced))\n\n# Prepare variables for tabset (initialize as NULL)\np &lt;- NULL\nsummary_stats &lt;- NULL\n\n# Step 11: Enhanced network visualisation and summary statistics \nif(length(total_influenced_collaborators) &gt; 0) {\n  \n  # Collect all relevant nodes for visualization\n  all_pathway_works &lt;- unique(c(\n    sailor_ivy_works,\n    direct_influence$from, direct_influence$to,\n    two_step_pathways$sailor_work, two_step_pathways$intermediate_work, two_step_pathways$oceanus_work,\n    cross_collab_influence$from, cross_collab_influence$to\n  ))\n  \n  all_relevant_people &lt;- unique(c(\n    sailor_vertex_name,\n    ivy_echos_name,\n    total_influenced_collaborators,\n    shared_collaborators,\n    bridge_to_oceanus$bridge_person\n  ))\n  \n  all_viz_nodes &lt;- unique(c(all_pathway_works, all_relevant_people))\n  \n  # Enhanced node classification\n  viz_nodes &lt;- mc1_nodes_clean %&gt;%\n    filter(name %in% all_viz_nodes) %&gt;%\n    mutate(\n      influence_strength = case_when(\n        name %in% direct_influence$to ~ \"Direct Target\",\n        name %in% two_step_pathways$oceanus_work ~ \"Indirect Target\", \n        name %in% cross_collab_influence$to ~ \"Secondary Target\",\n        name %in% shared_collaborators ~ \"Shared Collaborator\",\n        name %in% bridge_to_oceanus$bridge_person ~ \"Bridge Collaborator\",\n        TRUE ~ \"Network Node\"\n      ),\n      node_role = case_when(\n        name == sailor_vertex_name ~ \"Sailor Shift\",\n        name == ivy_echos_name ~ \"Ivy Echos\",\n        name %in% sailor_ivy_works ~ \"Sailor/Ivy Work\",\n        name %in% oceanus_folk_works ~ \"Oceanus Folk Work\",\n        name %in% total_influenced_collaborators ~ \"Influenced Oceanus Collaborator\",\n        name %in% oceanus_folk_collaborators ~ \"Other Oceanus Collaborator\",\n        name %in% intermediate_works ~ \"Intermediate Work\",\n        TRUE ~ \"Other\"\n      ),\n      node_color = case_when(\n        node_role == \"Sailor Shift\" ~ \"red\",\n        node_role == \"Ivy Echos\" ~ \"purple\", \n        node_role == \"Sailor/Ivy Work\" ~ \"gray30\",\n        influence_strength == \"Direct Target\" ~ \"darkred\",\n        influence_strength == \"Indirect Target\" ~ \"orange\",\n        influence_strength == \"Secondary Target\" ~ \"yellow\",\n        influence_strength == \"Shared Collaborator\" ~ \"blue\",\n        influence_strength == \"Bridge Collaborator\" ~ \"cyan\",\n        node_role == \"Influenced Oceanus Collaborator\" ~ \"darkgreen\",\n        node_role == \"Other Oceanus Collaborator\" ~ \"lightgreen\",\n        node_role == \"Intermediate Work\" ~ \"pink\",\n        TRUE ~ \"lightgray\"\n      ),\n      node_size = case_when(\n        node_role %in% c(\"Sailor Shift\", \"Ivy Echos\") ~ 8,\n        influence_strength %in% c(\"Direct Target\", \"Shared Collaborator\") ~ 6,\n        influence_strength %in% c(\"Indirect Target\", \"Bridge Collaborator\") ~ 5,\n        influence_strength == \"Secondary Target\" ~ 4,\n        TRUE ~ 3\n      ),\n      tooltip_text = paste0(\n        \"Name: \", node_name, \"\\n\",\n        \"Role: \", node_role, \"\\n\", \n        \"Influence: \", influence_strength, \"\\n\",\n        \"Type: \", `Node Type`, \"\\n\",\n        ifelse(!is.na(genre), paste0(\"Genre: \", genre), \"\")\n      )\n    )\n  \n  # Collect all relevant edges preserving original Edge Types\n  all_influence_edges &lt;- bind_rows(\n    direct_influence %&gt;% mutate(pathway_category = \"Direct\"),\n    two_step_pathways %&gt;% \n      select(from = sailor_work, to = intermediate_work, `Edge Type` = step1_edge_type) %&gt;%\n      mutate(pathway_category = \"Indirect Step 1\"),\n    two_step_pathways %&gt;% \n      select(from = intermediate_work, to = oceanus_work, `Edge Type` = step2_edge_type) %&gt;%\n      mutate(pathway_category = \"Indirect Step 2\"),\n    cross_collab_influence %&gt;% \n      select(from, to, `Edge Type`) %&gt;%\n      mutate(pathway_category = \"Cross-Collaborator\")\n  )\n  \n  viz_edges &lt;- mc1_edges_clean %&gt;%\n    filter(from %in% all_viz_nodes, to %in% all_viz_nodes) %&gt;%\n    left_join(\n      all_influence_edges %&gt;% select(from, to, pathway_category),\n      by = c(\"from\", \"to\")\n    ) %&gt;%\n    mutate(\n      # Categorize edges for visual emphasis while keeping original Edge Type\n      edge_category = case_when(\n        !is.na(pathway_category) ~ \"Influence Pathway\",\n        `Edge Type` == \"MemberOf\" & from == sailor_vertex_name ~ \"Key Membership\", \n        `Edge Type` %in% collab_credit_types ~ \"Collaboration\",\n        `Edge Type` %in% influence_edge_types ~ \"Other Influence\",\n        TRUE ~ \"Other\"\n      ),\n      edge_alpha = case_when(\n        edge_category == \"Influence Pathway\" ~ 0.9,\n        edge_category == \"Key Membership\" ~ 0.8,\n        edge_category == \"Collaboration\" ~ 0.4,\n        edge_category == \"Other Influence\" ~ 0.6,\n        TRUE ~ 0.2\n      )\n    )\n  \n  # Create network plot\n  influence_graph &lt;- tbl_graph(nodes = viz_nodes, edges = viz_edges, directed = TRUE)\n\n  layout_df &lt;- create_layout(influence_graph, layout = \"fr\") %&gt;%\n    as_tibble() %&gt;%\n    select(name, x, y)\n  \n  nodes_plot &lt;- as_tibble(influence_graph) %&gt;%\n    left_join(layout_df, by = \"name\")\n  \n  edges_plot &lt;- viz_edges %&gt;%\n    left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n    rename(x_from = x, y_from = y) %&gt;%\n    left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n    rename(x_to = x, y_to = y)\n  \n  # Create legend data frame for node colors\n  legend_data &lt;- data.frame(\n    node_color = c(\"red\", \"purple\", \"gray30\", \"darkred\", \"orange\", \"yellow\", \n                   \"blue\", \"cyan\", \"darkgreen\", \"lightgreen\", \"pink\", \"lightgray\"),\n    node_role = c(\"Sailor Shift\", \"Ivy Echos\", \"Sailor/Ivy Work\", \"Direct Target\", \n                  \"Indirect Target\", \"Secondary Target\", \"Shared Collaborator\", \n                  \"Bridge Collaborator\", \"Influenced Oceanus Collaborator\", \n                  \"Other Oceanus Collaborator\", \"Intermediate Work\", \"Other\"),\n    stringsAsFactors = FALSE\n  )\n  \n  p &lt;- ggplot() +\n    geom_segment(\n      data = edges_plot,\n      aes(x = x_from, y = y_from, xend = x_to, yend = y_to,\n          color = `Edge Type`, alpha = edge_alpha),\n      arrow = arrow(length = unit(1.5, 'mm'))\n    ) +\n    scale_alpha_identity() +\n    scale_color_discrete(name = \"Edge Type\") +\n    ggnewscale::new_scale_color() +\n    geom_point_interactive(\n      data = nodes_plot,\n      aes(x = x, y = y, tooltip = tooltip_text, data_id = name,\n          color = node_color, shape = `Node Type`, size = node_size)\n    ) +\n    scale_size_identity() +  \n    scale_color_manual(\n      name = \"Node Role\",\n      values = c(\"red\" = \"red\", \"purple\" = \"purple\", \"pink\" = \"pink\", \"darkred\" = \"darkred\",\n                 \"orange\" = \"orange\", \"yellow\" = \"yellow\", \"blue\" = \"blue\", \"cyan\" = \"cyan\", \n                 \"darkgreen\" = \"darkgreen\", \"lightgreen\" = \"lightgreen\",\n                 \"gray30\" = \"gray30\", \"lightgray\" = \"lightgray\"),\n      labels = setNames(legend_data$node_role, legend_data$node_color),\n      breaks = legend_data$node_color,\n      guide = guide_legend(override.aes = list(size = 4, shape = 16))\n    ) +\n    geom_text(\n      data = nodes_plot %&gt;% filter(node_role == \"Sailor Shift\"),\n      aes(x = x, y = y, label = \"Sailor Shift\"),\n      size = 4, fontface = \"bold\", color = \"red\", vjust = -2\n    ) +\n    theme_void() +\n    theme(\n      legend.position = \"right\",\n      legend.box = \"vertical\",\n      legend.text = element_text(size = 11),\n      legend.title = element_text(size = 16),\n      plot.title = element_text(size = 20, face = \"bold\"), \n      plot.subtitle = element_text(size = 16, face = \"plain\")    \n    ) +\n    labs(\n      title = \"Sailor Shift's Influence on Oceanus Folk Community\",\n      subtitle = str_to_title(\"Influence pathways: Direct (work-to-work), Indirect (via intermediary), Secondary (cross-collaborator), Shared/Bridge (collaboration networks)\")\n    )\n  \n  # Create summary statistics data frame\nsummary_stats &lt;- data.frame(\n  Metric = c(\n    \"Total Oceanus Folk collaborators\",\n    \"Total influenced collaborators\",\n    \"Percentage influenced (%)\",\n    \"\",\n    \"Direct influences\",\n    \"Two-step pathways\", \n    \"Cross-collaborator influences\",\n    \"Shared collaborators\",\n    \"Bridge collaborators\"\n  ),\n  Value = c(\n    length(oceanus_folk_collaborators),\n    length(total_influenced_collaborators),\n    round(100 * length(total_influenced_collaborators) / length(oceanus_folk_collaborators), 1),\n    \"\",\n    nrow(direct_influence),\n    nrow(two_step_pathways),\n    nrow(cross_collab_influence),\n    length(shared_collaborators),\n    length(unique(bridge_to_oceanus$bridge_person))\n  ),\n  stringsAsFactors = FALSE\n)\n}\n\n\n\nNetwork VisualisationSummary Statistics\n\n\n\n\nCode\ngirafe(ggobj = p, width_svg = 16, height_svg = 12)\n\n\n\n\n\n\n\n\n\n\nCode\nknitr::kable(\n  summary_stats,\n  col.names = c(\"Metric\", \"Count\"),\n  caption = \"Sailor Shift's Influence Analysis Summary\"\n)\n\n\n\nSailor Shift’s Influence Analysis Summary\n\n\nMetric\nCount\n\n\n\n\nTotal Oceanus Folk collaborators\n720\n\n\nTotal influenced collaborators\n81\n\n\nPercentage influenced (%)\n11.2\n\n\n\n\n\n\nDirect influences\n9\n\n\nTwo-step pathways\n11\n\n\nCross-collaborator influences\n10\n\n\nShared collaborators\n42\n\n\nBridge collaborators\n7\n\n\n\n\n\n\n\n\nThe above visualisation focus on the network of influence that Sailor Shift had in the Oceanus Folk community. Out of 720 Oceanus Folk collaborators, she has interacted with 81 collaborators, which is a notable influence as it is more than 10% of the community.\nWhile only 9 collaborators have been directly influenced by working closely with her/Ivy Echos, the majority of her impact is indirect. More than half of the influenced collaborators have been shaped indirectly through shared and bridged collaborators. These network-mediated pathways, including two-step and cross-collaborator connections, illustrates how her influence extends beyond those that she worked directly with.\nOverall, this showcases how Sailor Shift’s influence diffuses dynamically throughout the community where her impact in the community is not only driven by direct collaborations, but also by the broader web of relationships and interactions that connect the Oceanus Folk community."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "",
    "text": "This exercise aims to enhance a visualisation originally created by a fellow course-mate as a graphic editor of a media company that publishes daily content on digital platforms. The critique will be made with reference to the following principles extracted from Ben Jones’ article (“Data Visualization: Clarity or Aesthetics?”)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#objective",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#objective",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "",
    "text": "This exercise aims to enhance a visualisation originally created by a fellow course-mate as a graphic editor of a media company that publishes daily content on digital platforms. The critique will be made with reference to the following principles extracted from Ben Jones’ article (“Data Visualization: Clarity or Aesthetics?”)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#load-packages",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "2.1 Load packages",
    "text": "2.1 Load packages\nThe following R packages will be loaded using the pacman::p_load() function.\n\npacman::p_load(ggrepel, patchwork, \n               tidyverse, scales,\n               ggridges)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#import-data",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "2.2 Import data",
    "text": "2.2 Import data\nThis exercise will be using the same dataset as Phase 1 of Take-Home Exercise 1. Thus, proceed to import data with the following code.\n\ndata &lt;- read_csv(\"data/respopagesex2024.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#data-preprocessing",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#data-preprocessing",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "2.3 Data preprocessing",
    "text": "2.3 Data preprocessing\nSince the goal of this exercise is to provide critiques on the original visualisation, the data pre-processing will follow the process of the original visualisation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#original-work",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#original-work",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "3.1 Original Work",
    "text": "3.1 Original Work\nThe chosen submission had the following visualisation for Top 10 Planning Areas by Total Population.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntop_pa &lt;- data %&gt;%\n  group_by(PA) %&gt;%\n  summarise(Total_Pop = sum(Pop)) %&gt;%\n  arrange(desc(Total_Pop)) %&gt;%\n  slice_head(n = 10)\n\nggplot(top_pa, aes(x = reorder(PA, Total_Pop), y = Total_Pop)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Top 10 Most Populous Planning Areas (2024)\",\n       x = \"Planning Area\", y = \"Total Population\") +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#critique",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#critique",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "3.2 Critique",
    "text": "3.2 Critique\nClarity\nWhy it is clear:\n\nClear and purposeful layout: Bar chart is a good choice for communicating ranked categorical data. It is simple, direct and allows readers to immediately grasp the key message of the data visualisation.\nLogical ordering: The planning areas are arranged in descending order based on population size. This allows readers to quickly identify which areas are the most densely populated at the first glance and easily understand relative magnitude.\n\nWhy it can be confusing:\n\nScientific notation undermines readability: Displaying population values in scientific notations will require readers to engage in additional cognitive effort and may be difficult for non-technical readers. This introduces friction into the reading experience. On fast-scrolling digital platforms, accessible by general public of all ages and abilities, reducing interpretation barriers is critical.\nTitle and labels lack specificity: The title does not specify the scope of population (whether non-residents are included). Similarly, the x-axis label “Total Population” which is vague in a demographic context where definitions matter. To enhance the clarity, “Total Population” can be defined as “Resident Population” and source can be added to the data visualisation for readers to have further reference on the definition of “Resident Population” and the year of reference.\n\nAesthetic\nWhy it is beautiful:\n\nSimple and clean theme with faint gridlines: There are no unnecessary details, thus successfully avoiding distractions that do not contribute to understanding.\nOrientation of bar chart: Horizontal orientation is able to accommodate long planning area names without truncation or overlapping, which enhances readability.\n\nWhy it can be ugly:\n\nDull visualisation: While using a single blue shade avoids unnecessary noise, it fails to enhance visual interest or guide the reader’s attention. As Ben Jones mentioned, aesthetics and clarity can come hand-in-hand where aesthetics can aid clarity when used meaningfully. Applying a colour gradient, dark to light based on population size, or selectively highlighting the most populous area, would create visual contrast that draws attention and support the ranking narrative, without adding clutter."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#remake",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#remake",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "3.3 Remake",
    "text": "3.3 Remake\nBased on the critique in section 3.2, a revised version of the original visualisation has been created. It retains the strengths of the original visualisation while refining the areas identified for improvement.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Summarise top 10 planning areas by resident population\ntop_pa &lt;- data %&gt;%\n  group_by(PA) %&gt;%\n  summarise(Total_Pop = sum(Pop)) %&gt;%\n  arrange(desc(Total_Pop)) %&gt;%\n  slice_head(n = 10)\n\n# Prepare data for plotting\ntop_pa &lt;- top_pa %&gt;%\n  arrange(desc(Total_Pop)) %&gt;%\n  mutate(PA = factor(PA, levels = rev(PA)),\n         Fill = Total_Pop)\n\n# Create the plot\nggplot(top_pa, aes(x = PA, y = Total_Pop, fill = Fill)) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_gradient(low = \"#bdd7e7\", high = \"#08519c\", guide = \"none\") +\n  scale_y_continuous(labels = comma) +\n  labs(\n    title = \"Top 10 Planning Areas by Resident Population\",\n    x = \"Planning Area\",\n    y = \"Number of Residents\",\n    caption = \"Source: Department of Statistics Singapore (2024)\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title.x = element_text(margin = margin(t = 10)),\n    axis.title.y = element_text(margin = margin(r = 10)),\n    plot.caption = element_text(hjust = 1, size = 8, color = \"gray30\")\n  )"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 — Visual Analytics and Applications",
    "section": "",
    "text": "Welcome to my website for ISSS608: Visual Analytics and Applications. Here, you’ll find a collection of my learnings and coursework from the course, reflecting the skills and knowledge I’ve gained throughout this journey.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n \n\n\n \n\n\n\n\nJun 10, 2025\n\n\nHands-on Exercise 8a\n\n\n\n\nJun 10, 2025\n\n\nHands-on Exercise 8b\n\n\n\n\nJun 10, 2025\n\n\nHands-on Exercise 8c\n\n\n\n\nMay 28, 2025\n\n\nTake-home Exercise 2\n\n\n\n\nMay 28, 2025\n\n\nTake-home Exercise 2\n\n\n\n\nMay 20, 2025\n\n\nHands-on Exercise 6\n\n\n\n\nMay 17, 2025\n\n\nIn-class Exercise 5 Mini Challenge 1\n\n\n\n\nMay 13, 2025\n\n\nHands-on Exercise 5\n\n\n\n\nMay 6, 2025\n\n\nHands-on Exercise 4a\n\n\n\n\nMay 6, 2025\n\n\nHands-on Exercise 4b\n\n\n\n\nMay 6, 2025\n\n\nHands-on Exercise 4c\n\n\n\n\nMay 6, 2025\n\n\nHands-on Exercise 4d\n\n\n\n\nMay 6, 2025\n\n\nTake-home Exercise 1 Phase 2\n\n\n\n\nApr 30, 2025\n\n\nTake-home Exercise 1\n\n\n\n\nApr 29, 2025\n\n\nHands-on Exercise 3a\n\n\n\n\nApr 29, 2025\n\n\nHands-on Exercise 3b\n\n\n\n\nApr 22, 2025\n\n\nHands-on Exercise 2\n\n\n\n\nApr 18, 2025\n\n\nHands-on Exercise 1\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html",
    "title": "Hands-on Exercise 8a",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter will be covering how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable to read the functional description of each function before using them.\n\n\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually.\n\n\n\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\yfgoh\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed.\n\n\n\nNext, import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore performing the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(c(PA, SZ), toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, tmap functions that used to plot these elements will be shared.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\") +\n  tm_borders(lwd = 0.01,  \n             fill_alpha = 0.1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"kmeans\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"fisher\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"kmeans\",\n        n = 20)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"fisher\",\n        n = 10)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore getting started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7867  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, break point will be set at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, assign the preferred colour to values argument of tm_scale_intervals() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several tm_legend() options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5,\n        values = \"brewer.greens\"),\n      fill.legend = tm_legend(\n        title = \"Dependency ratio\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\")\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, selection funtion can also map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#overview",
    "title": "Hands-on Exercise 8a",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter will be covering how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#getting-started",
    "title": "Hands-on Exercise 8a",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#importing-data-into-r",
    "title": "Hands-on Exercise 8a",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\yfgoh\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed.\n\n\n\nNext, import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore performing the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(c(PA, SZ), toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 8a",
    "section": "",
    "text": "Two approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, tmap functions that used to plot these elements will be shared.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\") +\n  tm_borders(lwd = 0.01,  \n             fill_alpha = 0.1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"kmeans\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"fisher\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"kmeans\",\n        n = 20)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"fisher\",\n        n = 10)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore getting started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7867  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, break point will be set at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, assign the preferred colour to values argument of tm_scale_intervals() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several tm_legend() options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5,\n        values = \"brewer.greens\"),\n      fill.legend = tm_legend(\n        title = \"Dependency ratio\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\")\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, selection funtion can also map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#reference",
    "title": "Hands-on Exercise 8a",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "This hands-on exercise will allow one to create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\nLoad the following packages for this exercise.\n\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nIn this section, a calendar heatmap will be created programmatically by using ggplot2 package.\n\nBy end of this section, one will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore plotting the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\n\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, these are the steps:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\nThis section will be going through how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis section will be covering how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Countries\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "This hands-on exercise will allow one to create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Load the following packages for this exercise.\n\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, a calendar heatmap will be created programmatically by using ggplot2 package.\n\nBy end of this section, one will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore plotting the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\n\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, these are the steps:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "This section will be going through how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "This section will be covering how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Countries\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. This hands-on exercise will be covering the following:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. This hands-on exercise will compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  x_range = c(0, 6500),  #&lt;&lt;\n  y_range = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ndata_type argument is used to change from default “SR” to “PR” (i.e. proportions).\nxrange and yrange are used to set the range of x-axis and y-axis\n\n\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\n\n\nThis section will provide hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhances working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, cumulative death rate and standard error of cumulative death rate needs to be derived.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly\n\n\n\n\n\n\n\n\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#overview",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. This hands-on exercise will be covering the following:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#importing-data",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "In this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. This hands-on exercise will compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "FunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  x_range = c(0, 6500),  #&lt;&lt;\n  y_range = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ndata_type argument is used to change from default “SR” to “PR” (i.e. proportions).\nxrange and yrange are used to set the range of x-axis and y-axis\n\n\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "This section will provide hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhances working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, cumulative death rate and standard error of cumulative death rate needs to be derived.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#references",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "funnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "This hands-on exercise will be covering the following:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n-   To provide alternative statistical inference methods by default. \n-   To follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nUsing the following code, import exam_data.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information:\n\nstatistical details\nBayes Factor\nsample sizes\ndistribution summary\n\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information:\n\nstatistical details\nBayes Factor\nsample sizes\ndistribution summary\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nCodePlot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "This hands-on exercise will be covering the following:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n-   To provide alternative statistical inference methods by default. \n-   To follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#importing-data",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "Using the following code, import exam_data.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information:\n\nstatistical details\nBayes Factor\nsample sizes\ndistribution summary\n\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information:\n\nstatistical details\nBayes Factor\nsample sizes\ndistribution summary\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nCodePlot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, one will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore starting on animated graphs, it will be important to ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts.\n\n\n\n\n\n\n\n\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nAs mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nThe basic ggplot2 functions are used to create a static bubble plot as shown below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\nAs shown in the following plot,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')          \n\n\n\n\n\n\n\n\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, one will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object. :::\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\nIn this sub-section, one will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp\n\n\n\n\n\n\n\n\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#overview",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, one will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore starting on animated graphs, it will be important to ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#getting-started",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "First, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nAs mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "gganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nThe basic ggplot2 functions are used to create a static bubble plot as shown below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\nAs shown in the following plot,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "In Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, one will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object. :::\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\nIn this sub-section, one will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#reference",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "Getting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "This chapter will introduce several ggplot2 extensions for creating a more elegant and effective statistical graphics. By the end of this exercise, one should be able to:\n\ncontrol the placement of annontation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in the ggthemes and hrbrthemes packages, and\nplot composite figure by combining ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\nBesides tidyverse, the following R packages will be used in this exercise.\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe code chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\nThe following code chunk loads the extrafont package and imports system fonts so that they can be used in plots, which is instrumental in packages such as hrbrthemes.\n\npacman::p_load(extrafont)\nfont_import()\n\nImporting fonts may take a few minutes, depending on the number of fonts and the speed of the system.\nContinue? [y/n] \n\nloadfonts(device = \"win\")\n\n\n\n\nThis exercise will be using a data file called Exam_data. It consists of year-end examination grades of a cohort of primary 3 students from a local school. It is in a csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\nOne of the challenges in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in the examples on below.  \nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "This chapter will introduce several ggplot2 extensions for creating a more elegant and effective statistical graphics. By the end of this exercise, one should be able to:\n\ncontrol the placement of annontation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in the ggthemes and hrbrthemes packages, and\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Besides tidyverse, the following R packages will be used in this exercise.\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe code chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\nThe following code chunk loads the extrafont package and imports system fonts so that they can be used in plots, which is instrumental in packages such as hrbrthemes.\n\npacman::p_load(extrafont)\nfont_import()\n\nImporting fonts may take a few minutes, depending on the number of fonts and the speed of the system.\nContinue? [y/n] \n\nloadfonts(device = \"win\")\n\n\n\n\nThis exercise will be using a data file called Exam_data. It consists of year-end examination grades of a cohort of primary 3 students from a local school. It is in a csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annontation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annontation-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "One of the challenges in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in the examples on below.  \nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "The plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2",
    "section": "2.5 Beyond Single Graph",
    "text": "2.5 Beyond Single Graph\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, one will learn how to create composite plot by combining multiple graphs. First, the three statistical graphics will be created by using the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\nNext\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\nLastly, a scatterplot for English score versus Maths score will be created as shown below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n2.5.1 Creating Composite Graphics: pathwork methods\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, a ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure will be further explored.\nPatchwork package has a very simple syntax where one can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n2.5.2 Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Notice the simplicity of the syntax.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\n2.5.3 Combining three ggplot2 graphs\nMore complex composite can be plotted using appropriate operators. For example, the composite figure below is plotted by using:\n\n/ operator to stack two ggplot2 graphs,\n| operator to place the plots beside each other,\n() operator the define the sequence of the plotting.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n2.5.4 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n2.5.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, one or several plots or graphic elements can be freely placed on top or below another plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n2.5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#additional-work-for-exploration",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#additional-work-for-exploration",
    "title": "Hands-on Exercise 2",
    "section": "2.6 Additional work for exploration",
    "text": "2.6 Additional work for exploration\nThis section is reserved for further exploration."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 2",
    "section": "2.7 Reference",
    "text": "2.7 Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello! I’m Yi Fang, a postgraduate student with a passion for uncovering insights through analytics.\nThis site is my space to explore and refine my skills in visual analytics, while sharing my learning journey along the way. I’m also currently learning RStudio to broaden my analytical toolkit and deepen my understanding of data storytelling. I’m excited to grow, experiment, and hopefully connect with others who are just as excited about the power of analytics!\n\n\n\n Back to top"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcomes",
    "title": "Hands-on Exercise 1",
    "section": "1.1 Learning outcomes",
    "text": "1.1 Learning outcomes\nKey objectives of the following sections:\n\nlearn basic principles and essential components of ggplot2,\ngain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics, and\napply essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started-1",
    "title": "Hands-on Exercise 1",
    "section": "1.2 Getting started",
    "text": "1.2 Getting started\nBefore we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk on the below assumes that you already have pacman package installed. If not, please go ahead install pacman first."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "1.3 Introducing ggplot",
    "text": "1.3 Introducing ggplot\nggplot2 is a R package for declaratively creating data-driven graphics based on The Grammar of Graphics. It is also part of the tidyverse family specially designed for visual exploration and communication. For more detail, visit ggplot2 link.\n\n1.3.1 R Graphics VS ggplot\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR Graphicsggplots2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nggplot2 encourages deeper thinking about visualisation by connecting variables to visual elements."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\nBefore we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n1.4.1 A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1",
    "section": "1.5 Essential Grammatical Elements in ggplot2: data",
    "text": "1.5 Essential Grammatical Elements in ggplot2: data\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1",
    "section": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call.\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nggplot includes the x-axis and the axis’s label."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 1",
    "section": "1.7 Essential Grammatical Elements in ggplot2: geom",
    "text": "1.7 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nA plot must have at least one geom; there is no upper limit. geom can be added to a plot using the + operator. For complete list of geometric objects, please refer to here.\n\n1.7.1 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n1.7.2 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\nThe following code chunk performs the following steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n1.7.3 Geometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\n1.7.4 Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n1.7.5 Modifying a geometric object by changing aes()\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic(). This approach can be used to colour, fill and alpha of the geometric.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n1.7.6 Geometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram. It is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using color or fill arguments of aes().\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n1.7.7 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n1.7.8 Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n1.7.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n1.7.10 geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "1.8 Essential Grammatical Elements in ggplot2: stat",
    "text": "1.8 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n1.8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n1.8.3 Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n1.8.4 Adding a best fit curve on a scatterplot\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\n\n\n\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default method used is loess.\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "1.9 Essential Grammatical Elements in ggplot2: Facets",
    "text": "1.9 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n1.9.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n1.9.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "1.10 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "1.10 Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n- [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out). - [`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped. - [`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot). - [`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n1.10.1 Working with Coordinates\nBy default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe following code chunk flips the horizontal bar chart into a vertical bar chart by adding coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n1.10.2 Changing the y- and x-axis range\nNotice that the y- and x-axis range are not the same.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, linewidth=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below standardised both y- and x-axis to the range of 0 to 100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "1.11 Essential Grammatical Elements in ggplot2: themes",
    "text": "1.11 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n1.11.1 Working with themes\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 1",
    "section": "1.12 Reference",
    "text": "1.12 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "In this hands-on exercise, one will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages.\n\n\n\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\n\n\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\nCode chunk in the second tab below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\nCode chunk in the second tab shows the second interactive feature of ggiraph, namely data_id.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. Note: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.\n\n\n\n\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nKey learning points here:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,\n\n\n\n\n\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!.\n\n\n\n\n\n\n\n\n\n\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "In this hands-on exercise, one will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "First, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "In this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "ggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\nCode chunk in the second tab below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\nCode chunk in the second tab shows the second interactive feature of ggiraph, namely data_id.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. Note: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "Plotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nKey learning points here:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "Crosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "This link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. Some of the popular statistical graphics methods for visualising distribution were covered in Hands-on Exercise 1. These includes histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, two relatively new statistical graphic methods for visualising distribution will be covered, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. This section will cover how to plot ridgeline plot using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nTo fill the area under the ridgeline with varying colors instead of a single solid color, one can use either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nThe ridgeline plot can be colored based on quantile by using geom_density_ridges_gradient(). This is calculated using stat(quantile) aesthetic as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quantiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, one will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\nNext, add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, dd the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. Select side = “left” to place it on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\n\n\n\n\nReference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. Some of the popular statistical graphics methods for visualising distribution were covered in Hands-on Exercise 1. These includes histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, two relatively new statistical graphic methods for visualising distribution will be covered, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Ridgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. This section will cover how to plot ridgeline plot using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nTo fill the area under the ridgeline with varying colors instead of a single solid color, one can use either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nThe ridgeline plot can be colored based on quantile by using geom_density_ridges_gradient(). This is calculated using stat(quantile) aesthetic as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quantiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-using-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-using-raincloud-plot",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Raincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, one will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\nNext, add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, dd the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. Select side = “left” to place it on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#references",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Reference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. To create statistical graphics for visualising uncertainty, the following will be covered in this hands-on exercise.\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\nstringr for automatically wrapping text\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse, stringr)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\nThis section will go through how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nTableCode\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\nStandard error bars of means maths score by race will be plotted as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, the confidence intervals of mean maths score by race can also be plotted.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nThis section will cover how to plot interactive error bars for the 99% confidence interval of mean math score by race as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(6,6),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average &lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, it is best to read the syntax reference for more details.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nTo show 99% and 95% confidence, refer to the following code.\n\nPlot for 99% CIPlot for 95% CICodes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# For 99% CI\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.99,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n# For 95% CI\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, it is advisable to read the syntax reference for more details.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, it is advisable to read the syntax reference for more details.\n\n\n\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\nNext, the code chunk below will be used to build the HOPs.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. To create statistical graphics for visualising uncertainty, the following will be covered in this hands-on exercise.\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\nstringr for automatically wrapping text\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse, stringr)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "A point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\nThis section will go through how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nTableCode\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\nStandard error bars of means maths score by race will be plotted as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, the confidence intervals of mean maths score by race can also be plotted.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nThis section will cover how to plot interactive error bars for the 99% confidence interval of mean math score by race as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(6,6),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average &lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "ggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, it is best to read the syntax reference for more details.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nTo show 99% and 95% confidence, refer to the following code.\n\nPlot for 99% CIPlot for 95% CICodes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# For 99% CI\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.99,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n# For 95% CI\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, it is advisable to read the syntax reference for more details.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, it is advisable to read the syntax reference for more details."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcomes-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcomes-plots-hops",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\nNext, the code chunk below will be used to build the HOPs.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "This hands-on exercise will be going through how to model, analyse and visualise network data using R, this includes the following.\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\n\n\n\n\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)\n\n\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 54 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 54 employees.\n\n\n\n\n\nIn this step, import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nShow the code\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nNext, examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, proceed to aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\n\n\n\nIn this section, one will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, it is advisable to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, it is recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\nShow the code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 1372 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before getting started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\nIn this section, theme_graph() will be used to remove the x and y axes. Before getting started, it is advisable to read it’s reference guide at least once.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nlayout argument is used to define the layout to be used.\n\n\n\n\n\nIn this section, each node will be coloured by referring to their respective departments.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is best to read its reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\n\nShow the code\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable to read its reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nNodes can be moved and the graph will use an algorithm to keep the nodes properly spaced.\nIt can also be zoom in and out on the plot and moved around to re-center.\n\n\n\n\nBefore plotting the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "This hands-on exercise will be going through how to model, analyse and visualise network data using R, this includes the following.\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 54 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 54 employees.\n\n\n\n\n\nIn this step, import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nShow the code\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nNext, examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, proceed to aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this section, one will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, it is advisable to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, it is recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\nShow the code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 1372 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "ggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before getting started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\nIn this section, theme_graph() will be used to remove the x and y axes. Before getting started, it is advisable to read it’s reference guide at least once.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nlayout argument is used to define the layout to be used.\n\n\n\n\n\nIn this section, each node will be coloured by referring to their respective departments.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Another very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is best to read its reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\n\nShow the code\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable to read its reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Centrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "visNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nNodes can be moved and the graph will use an algorithm to keep the nodes properly spaced.\nIt can also be zoom in and out on the plot and moved around to re-center.\n\n\n\n\nBefore plotting the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "title": "<img src='/images/shibainu.png' alt='ISSS608' style='height: 48px; width: 48px;'>",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false    \n\n\n\n Back to top"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\npacman::p_load(jsonlite, tidyverse, SmartEDA, tidygraph, ggraph)\n\n\n\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object.\n\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\nstr(kg, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tbl &lt;- as_tibble(kg$links)\n\n\n\n\n\n\nggplot(data = edges_tbl,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid_map &lt;- tibble(id = nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)))\n\nThis ensures each id from node list is mapped to the correct number.\n\n\n\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\nThe number of observations in edges_tbl should be the same as before running this code chunk.\nBefore doing leftjoin, there are only 4 variables. AFter doing the leftjoin, there is two additional variables.\n\n\n\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from),!is.na(to))\n\nThis will get rid of any missing values.\n\n\n\nLastly, tbl_graph() is used to create tidygraph’s graph object by using the code chunk below.\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl,\n                   edges = edges_tbl,\n                   directed = kg$directed)\n\nDirected will be plugged from kg table’s directed column.\n\n\n\n\n\nset.seed(1234)\n\nThis is to ensure reproducibility. ### Visualising the Whole Graph\n\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3,               # line, alpha is transparency \n                 colour = \"gray\") + \n  geom_node_point(aes(color = `Node Type`), # point (plot after line so that it doesn't get covered by line)\n                  size = 4) +               # size of point  \n  geom_node_text(aes(label = name),         # label using name\n                 repel = TRUE,              # prevent overlapping names, force words apart\n                 size = 2.5) +\n  theme_void()\n\n\n\nIn this section, we are interested to create a sub-graph base on MemberOf vaue in Edge Type column of the edges data frame.\n\n\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%                     # Focus on edges table\n  filter(`Edge Type` == \"MemberOf\")       # Filter to Memberof\n\n\n\n\n\nused_nodes_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from,to) %&gt;%            # Only selected variables\n  unlist() %&gt;%                  # beCause it is a graph model, not a list\n  unique()\n\nThis is to eliminate orphan nodes.\n\n\n\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;% \n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_nodes_indices) %&gt;%\n  select(-row_id)  # optional clean up\n\n\n\n\n\nggraph(graph_memberof,\n       layout = \"fr\") + \n  geom_edge_link(alpha = 0.5,\n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`),\n                  size = 1) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#importing-knowledge-graph-data",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#importing-knowledge-graph-data",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "In the code chunk below, fromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object.\n\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\nstr(kg, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tbl &lt;- as_tibble(kg$links)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#initial-eda",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#initial-eda",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "ggplot(data = edges_tbl,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#creating-knowledge-graph",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#creating-knowledge-graph",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "id_map &lt;- tibble(id = nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)))\n\nThis ensures each id from node list is mapped to the correct number.\n\n\n\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\nThe number of observations in edges_tbl should be the same as before running this code chunk.\nBefore doing leftjoin, there are only 4 variables. AFter doing the leftjoin, there is two additional variables.\n\n\n\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from),!is.na(to))\n\nThis will get rid of any missing values.\n\n\n\nLastly, tbl_graph() is used to create tidygraph’s graph object by using the code chunk below.\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl,\n                   edges = edges_tbl,\n                   directed = kg$directed)\n\nDirected will be plugged from kg table’s directed column."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#visualising-the-knowledge-graph",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#visualising-the-knowledge-graph",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "set.seed(1234)\n\nThis is to ensure reproducibility. ### Visualising the Whole Graph\n\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3,               # line, alpha is transparency \n                 colour = \"gray\") + \n  geom_node_point(aes(color = `Node Type`), # point (plot after line so that it doesn't get covered by line)\n                  size = 4) +               # size of point  \n  geom_node_text(aes(label = name),         # label using name\n                 repel = TRUE,              # prevent overlapping names, force words apart\n                 size = 2.5) +\n  theme_void()\n\n\n\nIn this section, we are interested to create a sub-graph base on MemberOf vaue in Edge Type column of the edges data frame.\n\n\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%                     # Focus on edges table\n  filter(`Edge Type` == \"MemberOf\")       # Filter to Memberof\n\n\n\n\n\nused_nodes_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from,to) %&gt;%            # Only selected variables\n  unlist() %&gt;%                  # beCause it is a graph model, not a list\n  unique()\n\nThis is to eliminate orphan nodes.\n\n\n\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;% \n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_nodes_indices) %&gt;%\n  select(-row_id)  # optional clean up\n\n\n\n\n\nggraph(graph_memberof,\n       layout = \"fr\") + \n  geom_edge_link(alpha = 0.5,\n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`),\n                  size = 1) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "With reference to Singstat, Singapore’s resident population, consisting of citizens and permanent residents, stands at 4.18 million in 2024, with close to 20% of residents aged 65 and above. The population is distributed across 55 planning areas and 332 subzones.\n\n\n\nThis exercise will assume the role of a graphical editor of a media company planning to release an article on demographic structures and distribution of Singapore in 2024. The focus will be on presenting key demographics insights through visualisations.\nThe data will be processed by using appropriate tidyverse family of packages and the data visualisation will be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#overview",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#overview",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "With reference to Singstat, Singapore’s resident population, consisting of citizens and permanent residents, stands at 4.18 million in 2024, with close to 20% of residents aged 65 and above. The population is distributed across 55 planning areas and 332 subzones.\n\n\n\nThis exercise will assume the role of a graphical editor of a media company planning to release an article on demographic structures and distribution of Singapore in 2024. The focus will be on presenting key demographics insights through visualisations.\nThe data will be processed by using appropriate tidyverse family of packages and the data visualisation will be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#getting-started",
    "title": "Take-home Exercise 1",
    "section": "2 Getting started",
    "text": "2 Getting started\n\n2.1 Load packages\nThe following R packages will be loaded using the pacman::p_load() function.\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\npatchwork: an R package for preparing composite figure created using ggplot2.\nscales: an R package used for scaling and formatting data in visualisation.\nggridges: an R package for creating the density ridge plot.\n\n\npacman::p_load(ggrepel, patchwork, \n               tidyverse, scales,\n               ggridges) \n\n\n\n2.2 Import data\nThis exercise will be using Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore (DOS) \nProceed to load the dataset with the following code.\n\nrespop_data &lt;- read_csv(\"data/respopagesex2024.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1",
    "section": "3 Data Wrangling",
    "text": "3 Data Wrangling\nUsing glimpse() function, we get an overview of the dataset.\n\nglimpse(respop_data)\n\nRows: 60,424\nColumns: 6\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ Age  &lt;chr&gt; \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", …\n$ Sex  &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Females\", \"Male…\n$ Pop  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, 30, 10, 3…\n$ Time &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024,…\n\n\nThe dataset has 60,424 rows with 6 columns. This also shows the data type for each column.\n\n3.1 Check for duplicates\nA check for duplicates will be conducted with the duplicated function.\n\nrespop_data[duplicated(respop_data),]\n\n# A tibble: 0 × 6\n# ℹ 6 variables: PA &lt;chr&gt;, SZ &lt;chr&gt;, Age &lt;chr&gt;, Sex &lt;chr&gt;, Pop &lt;dbl&gt;,\n#   Time &lt;dbl&gt;\n\n\nAs indicated in the results, there are no duplicates.\n\n\n3.2 Check for missing values\nUsing the code below, proceed to check for missing values.\n\nfor(column_name in names(respop_data)) {\n  na_count &lt;- sum(is.na(respop_data[[column_name]]))\n\n  if (na_count &gt; 0) {\n    message(\"Column '\", column_name, \"' has \", na_count, \" NA values.\")\n  }\n}\n\n\n\n3.3 Recoding\nFor Age column, it is categorical due to the inclusion of an open-ended group, 90_and_Over. For this exercise, 90_and_Over was recoded to 90 so that Age could be treated as a numeric variable while still including this group in the analysis. This ensures that the completeness of the data. The following code will recode 90_and_Over to 90 and cast Age as numeric.\n\nrespop_data_clean &lt;- respop_data %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"90\", Age)) %&gt;%\n  mutate(Age = as.numeric(Age))\n\n\n\n3.4 Creating new column\nWith reference to URA Master Plan 2025, the 55 planning areas are classified into their respective regions with the following code.\n\nregion_mapping &lt;- c(\n  \"Ang Mo Kio\" = \"North-East\", \"Bedok\" = \"East\", \"Bishan\" = \"Central\", \n  \"Boon Lay\" = \"West\", \"Bukit Batok\" = \"West\", \"Bukit Merah\" = \"Central\", \n  \"Bukit Panjang\" = \"West\", \"Bukit Timah\" = \"Central\", \"Central Water Catchment\" = \"North\", \n  \"Changi\" = \"East\", \"Changi Bay\" = \"East\", \"Choa Chu Kang\" = \"West\", \n  \"Clementi\" = \"West\", \"Downtown Core\" = \"Central\", \"Geylang\" = \"Central\", \n  \"Hougang\" = \"North-East\", \"Jurong East\" = \"West\", \"Jurong West\" = \"West\", \n  \"Kallang\" = \"Central\", \"Lim Chu Kang\" = \"North\", \"Mandai\" = \"North\", \n  \"Marina East\" = \"Central\", \"Marina South\" = \"Central\", \"Marine Parade\" = \"Central\", \n  \"Museum\" = \"Central\", \"Newton\" = \"Central\", \"North-Eastern Islands\" = \"North-East\", \n  \"Novena\" = \"Central\", \"Orchard\" = \"Central\", \"Outram\" = \"Central\", \n  \"Pasir Ris\" = \"East\", \"Paya Lebar\" = \"East\", \"Pioneer\" = \"West\", \n  \"Punggol\" = \"North-East\", \"Queenstown\" = \"Central\", \"River Valley\" = \"Central\", \n  \"Rochor\" = \"Central\", \"Seletar\" = \"North-East\", \"Sembawang\" = \"North\", \n  \"Sengkang\" = \"North-East\", \"Serangoon\" = \"North-East\", \"Simpang\" = \"North\", \n  \"Singapore River\" = \"Central\", \"Southern Islands\" = \"Central\", \"Straits View\" = \"Central\", \n  \"Sungei Kadut\" = \"North\", \"Tampines\" = \"East\", \"Tanglin\" = \"Central\", \n  \"Tengah\" = \"West\", \"Toa Payoh\" = \"Central\", \"Tuas\" = \"West\", \n  \"Western Islands\" = \"West\", \"Western Water Catchment\" = \"West\", \"Woodlands\" = \"North\", \n  \"Yishun\" = \"North\"\n)\n\nrespop_data_clean &lt;- respop_data_clean %&gt;%\n  mutate(Region = region_mapping[PA])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-visualisation",
    "title": "Take-home Exercise 1",
    "section": "4 Data visualisation",
    "text": "4 Data visualisation\n\n4.1 National Distribution of Age and Sex Demographics\nTo gain an overview of the national age and sex demographics, we use a population pyramid that highlights the age distribution by sex. The stacked bar chart further illustrates the sex distribution within each age group.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create 5-year age bands\nnational_data &lt;- respop_data_clean %&gt;%\n  mutate(Age = as.integer(Age)) %&gt;%\n  mutate(\n    AgeBand = case_when(\n      Age &gt;= 90 ~ \"90+\",\n      TRUE ~ paste0(floor(Age / 5) * 5, \"-\", floor(Age / 5) * 5 + 4)\n    )\n  ) %&gt;%\n  group_by(AgeBand, Sex) %&gt;%\n  summarise(Total = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(\n    Total = ifelse(Sex == \"Males\", -Total, Total),\n    AgeBand = factor(AgeBand, levels = c(\n      paste0(seq(0, 85, 5), \"-\", seq(4, 89, 5)), \"90+\"\n    ))\n  )\n\n# Determine max population size for label positioning\nmax_pop &lt;- max(abs(national_data$Total))\ntop_age_band &lt;- tail(levels(national_data$AgeBand), 1)  \n\n# Population Pyramid plot with 90+ and top annotations\npyramid_plot &lt;- ggplot(national_data, aes(x = AgeBand, y = Total, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  coord_flip() +\n  scale_y_continuous(\n    labels = function(x) comma(abs(x)),\n    breaks = pretty_breaks()\n  ) +\n  labs(\n    title = \"Population Pyramid\",\n    x = \"Age Group\",\n    y = \"Population\"\n  ) +\n  scale_fill_manual(values = c(\"Males\" = \"#A1B8E0\", \"Females\" = \"#F8C1C1\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"none\"\n  ) +\n  annotate(\"text\", x = top_age_band, y = -max_pop * 0.5, label = \"Males\", color = \"#4A4A4A\", fontface = \"bold\", size = 3) +\n  annotate(\"text\", x = top_age_band, y = max_pop * 0.5, label = \"Females\", color = \"#4A4A4A\", fontface = \"bold\", size = 3)\n\nstacked_data &lt;- respop_data_clean %&gt;%\n  mutate(Age = as.integer(Age)) %&gt;%\n  mutate(\n    AgeBand = case_when(\n      Age &gt;= 90 ~ \"90+\",\n      TRUE ~ paste0(floor(Age / 5) * 5, \"-\", floor(Age / 5) * 5 + 4)\n    ),\n    AgeBand = factor(AgeBand, levels = c(\n      paste0(seq(0, 85, 5), \"-\", seq(4, 89, 5)), \"90+\"\n    ))\n  ) %&gt;%\n  group_by(AgeBand, Sex) %&gt;%\n  summarise(Pop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  group_by(AgeBand) %&gt;%\n  mutate(Proportion = Pop / sum(Pop)) %&gt;%\n  ungroup()\n\n# 100% Stacked Bar Chart using categorical age bands\nstacked_bar_plot &lt;- ggplot(stacked_data, aes(x = AgeBand, y = Proportion, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    title = \"Age-Sex Distribution\",\n    x = \"Age Group\",\n    y = \"Proportion within Age Group\"\n  ) +\n  scale_fill_manual(values = c(\"Males\" = \"#A1B8E0\", \"Females\" = \"#F8C1C1\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"  \n  ) +\n  # Annotate \"Males\" label\n  annotate(\"text\", x = 2, y = 0.3, label = \"Males\", color = \"#4A4A4A\", fontface = \"bold\", size = 3) +\n  # Annotate \"Females\" label\n  annotate(\"text\", x = 2, y = 0.9, label = \"Females\", color = \"#4A4A4A\", fontface = \"bold\", size = 3)\n\n\n# Arrange both plots side by side\npyramid_plot + stacked_bar_plot\n\n\n\n\nInsights\n\nThe national population pyramid highlights an ageing demographic with a significant concentration of the population observed between the age bands of 30-34 and 65-69, reflecting a large middle-aged and older working population.\nOn the other hand, the base of the pyramid is distinctively narrow, indicating persistently low birth rates and a declining proportion of younger residents.\nThe overall shape of the pyramid is generally symmetrical, suggesting a relatively balanced distribution between males and females across most age bands. However, the disparities become evident in the older age band. From the 75-79 band onwards, the females increasingly outnumber the males as seen in the 100% stacked bar chart.\n\n\n\n4.2 Population Size and Age Group Concentrations by Region\nThis section explores how the population is spread across different age groups in each region. The stacked bar chart shows the breakdown across five age groups for each region. Additionally, a slope chart shows the proportion of the youth against the senior populations, providing a simple visual of how each region’s population skews younger or older.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage_group_plot &lt;- respop_data_clean %&gt;%\n  mutate(Age_Group = cut(Age, breaks = c(0, 14, 24, 44, 64, Inf),\n                         labels = c(\"0-14\", \"15-24\", \"25-44\", \"45-64\", \"65+\"))) %&gt;%\n  filter(!is.na(Age_Group)) %&gt;%  \n  group_by(Region, Age_Group) %&gt;%\n  summarise(Total_Pop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(Region = fct_reorder(Region, Total_Pop, .fun = sum, .desc = TRUE)) %&gt;%\n  ggplot(aes(x = Region, y = Total_Pop, fill = Age_Group)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Age Group Distribution by Region\",\n       x = \"Region\", y = \"Population\", fill = \"Age Group\") +\n  scale_fill_manual(values = c(\"0-14\" = \"#FFB6C1\",\n                               \"15-24\" = \"#B3D9FF\", \n                               \"25-44\" = \"#A7D8C7\", \n                               \"45-64\" = \"#FFD1A9\",  \n                               \"65+\" = \"#E0B0FF\")) +  \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5))\n\n# Second plot (Slope Chart for Youth vs Senior Population)\nyouth_senior_data &lt;- respop_data_clean %&gt;%\n  mutate(Age_Group = case_when(\n    Age &lt;= 24 ~ \"Youth (0–24)\",\n    Age &gt;= 65 ~ \"Senior (65+)\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(Age_Group)) %&gt;%\n  group_by(Region, Age_Group) %&gt;%\n  summarise(Total_Pop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = Age_Group, values_from = Total_Pop) %&gt;%\n  mutate(\n    `Youth-to-Senior Ratio` = `Youth (0–24)` / `Senior (65+)`\n  ) %&gt;%\n  pivot_longer(\n    cols = c(`Youth (0–24)`, `Senior (65+)`),\n    names_to = \"Group\",\n    values_to = \"Population\"\n  )\n\n# Slope chart plot\nslope_chart_plot &lt;- ggplot(youth_senior_data, aes(x = Group, y = Population, group = Region)) +\n  geom_line(aes(color = Region), linewidth = 1) +\n  geom_point(aes(color = Region), size = 3) +\n  labs(title = \"Youth vs Senior Population by Region\",\n       x = \"\", y = \"Population\") +\n  theme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5))\n\n# Combine both plots side by side\nage_group_plot + slope_chart_plot\n\n\n\n\nInsights\n\nThe North-East region is the most populous, followed closely by the Central and West regions. In contrast, the East and North regions have significantly smaller populations.\nThe North-East also has the highest proportion of children aged 0–14, reinforcing its reputation as a family-oriented region popular with young households.\nThe Central region has the highest concentration of senior citizens (aged 65 and above), followed by the North-East and West regions, while the North region has the smallest senior population.\nAge groups of 0-14 and 15-24 remain relatively small across all regions, reflecting a broader national trend of declining birth rates.\nThe Central region stands out with a near-equal number of youths (aged 0–24) and seniors (65+). Despite signs of ageing, each region still has more youths than seniors, highlighting the continued presence of younger populations alongside an ageing demographic.\n\n\n\n4.3 Regional Age Profiles and Distribution Patterns\nTo get a better understanding of the age distribution and variation across the regions, we plot the following boxplot and density ridge plot.\n\nThe boxplot provides an overview of the age distribution within each region while highlighting the median, mean, interquartiles and range. This allows for easy comparison of the central tendency and spread of ages across regions.\nMeanwhile, the density ridge plot offers a more nuanced view by visualising the probability density of the age distribution. This reveals the relative density of different age groups across regions, emphasising the shapes and variations in distribution.\n\nTogether, these two visualisation provides a more comprehensive view of the population’s age structure, addressing the regional differences.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Boxplot\nrespop_expanded &lt;- respop_data_clean %&gt;%\n  uncount(weights = Pop)\nboxplot_plot &lt;- ggplot(respop_expanded, aes(y = Region, x = Age, fill = Region)) + \n  geom_boxplot() + \n  labs(title = \"Age Distribution Across Regions\",\n       x = \"Age\",\n       y = \"Region\") +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour = \"#9B2D20\",       \n               size = 4)   +\n  scale_fill_manual(values = c(\n    \"Central\" = \"#F9E29D\",   \n    \"East\" = \"#D6AEDD\",      \n    \"North\" = \"#F6B6A1\",   \n    \"North-East\" = \"#A9D8C9\",\n    \"West\" = \"#F7A1A0\"      \n  )) +\n  theme_minimal() +\n  theme(axis.title = element_text(size = 10),\n        plot.title = element_text(hjust = 0.5),\n        legend.position = \"none\",\n        )\n\n# Density Ridge Plot\ndensity_ridge_plot &lt;- respop_data_clean %&gt;%\n  ggplot(aes(x = Age, y = Region, \n             height = after_stat(density), \n             fill = Region, weight = Pop)) +\n  geom_density_ridges(stat = \"density\", scale = 3, alpha = 0.7, color = \"white\") +\n  labs(title = \"Weighted Age Density Distribution by Region\",\n       x = \"Age\", y = \"Region\") +\n  scale_fill_manual(values = c(\n    \"Central\" = \"#F9E29D\",  \n    \"East\" = \"#D6AEDD\",    \n    \"North\" = \"#F6B6A1\",     \n    \"North-East\" = \"#A9D8C9\",\n    \"West\" = \"#F7A1A0\"       \n  )) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5))\n\n\ndensity_ridge_plot / boxplot_plot\n\n\n\n\nInsights\n\nAll regions show signs of an ageing population, with noticeable age densities continuing into the 60s to 70s.\nAmong the regions, the North stands out with the youngest age profile, with lowest mean and median. Meanwhile, the Central region has the oldest demographic profile, with the highest mean and median, and a wider spread towards older age groups.\nBoth the North and North-East regions have their mean nearly identical to its own median, indicating a relatively balanced age distribution. Additionally, these two regions have a younger skew compared to the other regions.\nThe East and Central regions exhibit broader age distributions into the older age range. Their mean and median are also higher than that of the other regions, suggesting a more mature population."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#summary-and-conclusion",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#summary-and-conclusion",
    "title": "Take-home Exercise 1",
    "section": "5 Summary and conclusion",
    "text": "5 Summary and conclusion\nThese data visualisation serves as a foundation for telling the story of Singapore’s population in 2024. It strives to help readers better understand Singapore’s demographic landscape and its regional age patterns.\nSingapore’s demographic structure in 2024 indicates an ageing population, with most residents aged between 30 to 69 and a shrinking base of younger residents. While the overall gender distribution is relatively well-balanced, females increasingly outnumber males in the older age groups from age 75 onwards.\nAcross regions, ageing is evident as well. Notably, the Central region has the oldest demographic, while the North has the youngest demographic. Additionally, the North-East is the most populous with the largest proportion of children aged below 14 and below, cementing its reputation as a place of residence for young families."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#reference",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#reference",
    "title": "Take-home Exercise 1",
    "section": "6 Reference",
    "text": "6 Reference\n\nSingstat\nURA Master Plan 2025"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "This take-home exercise will be done in reference to the VAST Challenge 2025 and provide solutions to the first question of Mini-Challenge 1.\n\n\nOne of music’s biggest superstars is Oceanus native Sailor Shift. From humble beginnings, Sailor has grown in popularity and now enjoys fans around the world. Sailor started her career on the island nation of Oceanus which can be clearly seen in her early work, she started in the genre of “Oceanus Folk”. While Sailor has moved away from the traditional Oceanus style, the Oceanus Folk has made a name for itself in the musical world. The popularity of this music is one of the factors driving an increase in tourism to a quiet island nation that used to be known for fishing.\nIn 2023, Sailor Shift joined the Ivy Echoes – an all-female Oceanus Folk band consisting of Sailor (vocalist), Maya Jensen (vocalist), Lila “Lilly” Hartman (guitarist), Jade Thompson (drummer), and Sophie Ramirez (bassist). They played together at venues throughout Oceanus but had broken up to pursue their individual careers by 2026. Sailor’s breakthrough came in 2028 when one of her singles went viral, launched to the top of the global charts (something no other Oceanus Folk song had ever done). Since then, she has only continued to grow in popularity worldwide.\nSailor has released a new album almost every year since her big break, and each has done better than the last. Although she has remained primarily a solo artist, she has also frequently collaborated with other established artists, especially in the Indie Pop and Indie Folk genres. She herself has branched out musically over the years but regularly returns to the Oceanus Folk genre — even as the genre’s influence on the rest of the music world has spread even more.\nSailor has always been passionate about two things: (1) spreading Oceanus Folk, and (2) helping lesser-known artists break into music. Because of those goals, she’s particularly famous for her frequent collaborations.\nAdditionally, because of Sailor’s success, more attention began to be paid over the years to her previous bandmates. All 4 have continued in the music industry—Maya as an independent vocalist, Lilly and Jade as instrumentalists in other bands, and Sophie as a music producer for a major record label. In various ways, all of them have contributed to the increased influence of Oceanus folk, resulting in a new generation of up-and-coming Oceanus Folk artists seeking to make a name for themselves in the music industry.\nNow, as Sailor returns to Oceanus in 2040, a local journalist – Silas Reed – is writing a piece titled Oceanus Folk: Then-and-Now that aims to trace the rise of Sailor and the influence of Oceanus Folk on the rest of the music world. He has collected a large dataset of musical artists, producers, albums, songs, and influences and organized it into a knowledge graph. Your task is to help Silas create beautiful and informative visualizations of this data and uncover new and interesting information about Sailor’s past, her rise to stardom, and her influence.\n\n\n\nThe objective of this take-home exercise is to address the following tasks and questions of VAST Challenge 2025’s Mini-Challenge 1.\n\nDesign and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career\n\nWho has she been most influenced by over time?\nWho has she collaborated with and directly or indirectly influenced?\nHow has she influenced collaborators of the broader Oceanus Folk community?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#background",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#background",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "One of music’s biggest superstars is Oceanus native Sailor Shift. From humble beginnings, Sailor has grown in popularity and now enjoys fans around the world. Sailor started her career on the island nation of Oceanus which can be clearly seen in her early work, she started in the genre of “Oceanus Folk”. While Sailor has moved away from the traditional Oceanus style, the Oceanus Folk has made a name for itself in the musical world. The popularity of this music is one of the factors driving an increase in tourism to a quiet island nation that used to be known for fishing.\nIn 2023, Sailor Shift joined the Ivy Echoes – an all-female Oceanus Folk band consisting of Sailor (vocalist), Maya Jensen (vocalist), Lila “Lilly” Hartman (guitarist), Jade Thompson (drummer), and Sophie Ramirez (bassist). They played together at venues throughout Oceanus but had broken up to pursue their individual careers by 2026. Sailor’s breakthrough came in 2028 when one of her singles went viral, launched to the top of the global charts (something no other Oceanus Folk song had ever done). Since then, she has only continued to grow in popularity worldwide.\nSailor has released a new album almost every year since her big break, and each has done better than the last. Although she has remained primarily a solo artist, she has also frequently collaborated with other established artists, especially in the Indie Pop and Indie Folk genres. She herself has branched out musically over the years but regularly returns to the Oceanus Folk genre — even as the genre’s influence on the rest of the music world has spread even more.\nSailor has always been passionate about two things: (1) spreading Oceanus Folk, and (2) helping lesser-known artists break into music. Because of those goals, she’s particularly famous for her frequent collaborations.\nAdditionally, because of Sailor’s success, more attention began to be paid over the years to her previous bandmates. All 4 have continued in the music industry—Maya as an independent vocalist, Lilly and Jade as instrumentalists in other bands, and Sophie as a music producer for a major record label. In various ways, all of them have contributed to the increased influence of Oceanus folk, resulting in a new generation of up-and-coming Oceanus Folk artists seeking to make a name for themselves in the music industry.\nNow, as Sailor returns to Oceanus in 2040, a local journalist – Silas Reed – is writing a piece titled Oceanus Folk: Then-and-Now that aims to trace the rise of Sailor and the influence of Oceanus Folk on the rest of the music world. He has collected a large dataset of musical artists, producers, albums, songs, and influences and organized it into a knowledge graph. Your task is to help Silas create beautiful and informative visualizations of this data and uncover new and interesting information about Sailor’s past, her rise to stardom, and her influence."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#tasks-and-questions",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#tasks-and-questions",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "The objective of this take-home exercise is to address the following tasks and questions of VAST Challenge 2025’s Mini-Challenge 1.\n\nDesign and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career\n\nWho has she been most influenced by over time?\nWho has she collaborated with and directly or indirectly influenced?\nHow has she influenced collaborators of the broader Oceanus Folk community?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#load-the-packages",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#load-the-packages",
    "title": "Take-home Exercise 2",
    "section": "2.1 Load the packages",
    "text": "2.1 Load the packages\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environemnt.\n\npacman::p_load(jsonlite, tidyverse, ggtext,\n                knitr, lubridate, patchwork,\n                ggraph, tidygraph, igraph, scales,\n                ggiraph, dplyr, stringr, ggnewscale)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#importing-knowledge-graph-data",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#importing-knowledge-graph-data",
    "title": "Take-home Exercise 2",
    "section": "2.2 Importing Knowledge Graph Data",
    "text": "2.2 Importing Knowledge Graph Data\nfromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object.\n\nmc1_data &lt;- fromJSON(\"MC1/data/MC1_graph.json\")\n\n\n2.2.1 Inspect structure\nHere, str() is used to reveal the structure of mc1_data object.\n\nstr(mc1_data, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#extracting-the-edges-and-nodes-tables",
    "title": "Take-home Exercise 2",
    "section": "2.3 Extracting the edges and nodes tables",
    "text": "2.3 Extracting the edges and nodes tables\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from mc1_data object into two separate tibble data frames called mc1_nodes_raw and mc1_edges_raw respectively.\n\nmc1_nodes_raw &lt;- as_tibble(mc1_data$nodes)\nglimpse(mc1_nodes_raw)\n\nRows: 17,412\nColumns: 10\n$ `Node Type`    &lt;chr&gt; \"Song\", \"Person\", \"Person\", \"Person\", \"RecordLabel\", \"S…\n$ name           &lt;chr&gt; \"Breaking These Chains\", \"Carlos Duffy\", \"Min Qin\", \"Xi…\n$ single         &lt;lgl&gt; TRUE, NA, NA, NA, NA, FALSE, NA, NA, NA, NA, TRUE, NA, …\n$ release_date   &lt;chr&gt; \"2017\", NA, NA, NA, NA, \"2026\", NA, NA, NA, NA, \"2020\",…\n$ genre          &lt;chr&gt; \"Oceanus Folk\", NA, NA, NA, NA, \"Lo-Fi Electronica\", NA…\n$ notable        &lt;lgl&gt; TRUE, NA, NA, NA, NA, TRUE, NA, NA, NA, NA, TRUE, NA, N…\n$ id             &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ written_date   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020\", NA, NA,…\n$ stage_name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ notoriety_date &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\nkable(head(mc1_nodes_raw, 5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type\nname\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\n\n\n\n\nSong\nBreaking These Chains\nTRUE\n2017\nOceanus Folk\nTRUE\n0\nNA\nNA\nNA\n\n\nPerson\nCarlos Duffy\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\n\n\nPerson\nMin Qin\nNA\nNA\nNA\nNA\n2\nNA\nNA\nNA\n\n\nPerson\nXiuying Xie\nNA\nNA\nNA\nNA\n3\nNA\nNA\nNA\n\n\nRecordLabel\nNautical Mile Records\nNA\nNA\nNA\nNA\n4\nNA\nNA\nNA\n\n\n\n\n\n\nmc1_edges_raw &lt;- as_tibble(mc1_data$links)\n\nglimpse(mc1_edges_raw)\n\nRows: 37,857\nColumns: 4\n$ `Edge Type` &lt;chr&gt; \"InterpolatesFrom\", \"RecordedBy\", \"PerformerOf\", \"Composer…\n$ source      &lt;int&gt; 0, 0, 1, 1, 2, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ target      &lt;int&gt; 1841, 4, 0, 16180, 0, 16180, 0, 5088, 14332, 11677, 2479, …\n$ key         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\nkable(head(mc1_edges_raw, 5))\n\n\n\n\nEdge Type\nsource\ntarget\nkey\n\n\n\n\nInterpolatesFrom\n0\n1841\n0\n\n\nRecordedBy\n0\n4\n0\n\n\nPerformerOf\n1\n0\n0\n\n\nComposerOf\n1\n16180\n0\n\n\nPerformerOf\n2\n0\n0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#data-overview",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#data-overview",
    "title": "Take-home Exercise 2",
    "section": "2.4 Data Overview",
    "text": "2.4 Data Overview\nBefore proceeding to data pre-processing, we examine the data to gain a clearer understanding of the dataset and to verify the structural integrity of the imported graph.\nIn this code chunk below, ggplot2 functions are used the reveal the frequency distribution of Node Type field of mc1_nodes_raw.\n\nggplot(data = mc1_nodes_raw,\n       aes(y = `Node Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nOn the other hand, code chunk below uses ggplot2 functions to reveal the frequency distribution of Edge Type field of mc1_edges_raw.\n\nggplot(data = mc1_edges_raw,\n       aes(y = `Edge Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#adding-identifying-columns",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#adding-identifying-columns",
    "title": "Take-home Exercise 2",
    "section": "3.1 Adding identifying columns",
    "text": "3.1 Adding identifying columns\nAs a large part of this mini-challenge centers around Sailor Shift and the genre of “Oceanus Folk”, the following code will add columns to help with identification and filtering of Sailor Shift and the work in the genre of “Oceanus Folk”. This will help with analysis in addressing the questions and tasks.\n\nmc1_nodes_raw &lt;- mc1_nodes_raw %&gt;%\n  mutate(\n    is_sailor = (\n      str_detect(name, regex(\"sailor shift\", ignore_case = TRUE))\n    ) %&gt;% replace_na(FALSE),\n    \n    is_oceanus_folk = str_detect(genre, regex(\"oceanus folk\", ignore_case = TRUE)) %&gt;% #na/not oceanus folk = false\n      replace_na(FALSE)\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#converting-date-field",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#converting-date-field",
    "title": "Take-home Exercise 2",
    "section": "3.2 Converting date field",
    "text": "3.2 Converting date field\nDate fields will be converted from chr to int for later analysis. Note that dates only appear for Song and Album.\n\nmc1_nodes_raw &lt;- mc1_nodes_raw %&gt;%\n  mutate(across(c(release_date, notoriety_date, written_date),\n                ~as.integer(if_else(`Node Type` %in% c(\"Song\", \"Album\"), ., NA_character_))))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#check-for-duplicates",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#check-for-duplicates",
    "title": "Take-home Exercise 2",
    "section": "3.3 Check for duplicates",
    "text": "3.3 Check for duplicates\n\n3.3.1 Check for duplicates in mc1_nodes_raw\nThe following code chunk checks for id duplicates in mc1_nodes_raw.\n\nmc1_nodes_raw %&gt;%\n  count(id) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: id &lt;int&gt;, n &lt;int&gt;\n\n\nThere are no duplicated id in mc1_nodes_raw.\nThe following code checks for name duplicates in mc1_nodes_raw.\n\nduplicated_name &lt;- mc1_nodes_raw %&gt;%\n  count(name) %&gt;%\n  filter(n &gt; 1)\n\nduplicated_name\n\n# A tibble: 1,611 × 2\n   name                 n\n   &lt;chr&gt;            &lt;int&gt;\n 1 Agata Records        2\n 2 Ancestral Echoes     2\n 3 Angela Thompson      2\n 4 Anthony Davis        2\n 5 Anthony Smith        2\n 6 Asuka Takahashi      3\n 7 Brandon Wilson       2\n 8 Brian Gonzalez       2\n 9 Bryan Garcia         2\n10 Bryan Smith          3\n# ℹ 1,601 more rows\n\n\nThe following code chunk shows all rows from mc1_nodes_raw that have duplicated names, and sorting them alphabetically by the name column. There are a total of 4,953 records with duplicated names in mc1_nodes_raw.\n\nmc1_nodes_raw %&gt;%\n  filter(name %in% duplicated_name$name) %&gt;%\n  arrange(name)\n\n# A tibble: 4,953 × 12\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 RecordLabel Agata Recor… NA               NA &lt;NA&gt;  NA       1528           NA\n 2 RecordLabel Agata Recor… NA               NA &lt;NA&gt;  NA      17388           NA\n 3 Song        Ancestral E… TRUE           1991 Drea… FALSE   11793           NA\n 4 Song        Ancestral E… FALSE          2039 Avan… TRUE    17133           NA\n 5 Person      Angela Thom… NA               NA &lt;NA&gt;  NA       1150           NA\n 6 Person      Angela Thom… NA               NA &lt;NA&gt;  NA      13448           NA\n 7 Person      Anthony Dav… NA               NA &lt;NA&gt;  NA       8692           NA\n 8 Person      Anthony Dav… NA               NA &lt;NA&gt;  NA      12452           NA\n 9 Person      Anthony Smi… NA               NA &lt;NA&gt;  NA       5719           NA\n10 Person      Anthony Smi… NA               NA &lt;NA&gt;  NA       7694           NA\n# ℹ 4,943 more rows\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n\n3.3.2 Fixing duplicates in mc1_nodes_raw\nThe section will focus on fixing the duplicates found in mc1_nodes_raw as identified in section 3.3.1.\nThe following code chunk will tag each row with a unique key (group_key) based on its respective column values. This helps to identify unique records.\n\n# Step 1: Mark all node rows with a hash key for grouping\nmc1_nodes_tagged &lt;- mc1_nodes_raw %&gt;%\n  mutate(group_key = paste(`Node Type`, name, single, release_date, genre,\n                           notable, written_date, notoriety_date, is_sailor,\n                           is_oceanus_folk, sep = \"|\"))\n\nmc1_nodes_tagged\n\n# A tibble: 17,412 × 13\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 Song        Breaking Th… TRUE           2017 Ocea… TRUE        0           NA\n 2 Person      Carlos Duffy NA               NA &lt;NA&gt;  NA          1           NA\n 3 Person      Min Qin      NA               NA &lt;NA&gt;  NA          2           NA\n 4 Person      Xiuying Xie  NA               NA &lt;NA&gt;  NA          3           NA\n 5 RecordLabel Nautical Mi… NA               NA &lt;NA&gt;  NA          4           NA\n 6 Song        Unshackled … FALSE          2026 Lo-F… TRUE        5           NA\n 7 Person      Luke Payne   NA               NA &lt;NA&gt;  NA          6           NA\n 8 Person      Xiulan Zeng  NA               NA &lt;NA&gt;  NA          7           NA\n 9 Person      David Frank… NA               NA &lt;NA&gt;  NA          8           NA\n10 RecordLabel Colline-Cas… NA               NA &lt;NA&gt;  NA          9           NA\n# ℹ 17,402 more rows\n# ℹ 5 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;, group_key &lt;chr&gt;\n\n\nThe code below deduplicates the dataset using group_key, reducing the number of duplicated names from 4,953 to 14. The remaining 14 names appear more than once because their corresponding records differ in at least one column used to form group_key, so they are retained as distinct entries.\n\n# Step 2: Deduplicate and keep the preferred (with stage_name if available)\nmc1_nodes_dedup &lt;- mc1_nodes_tagged %&gt;%\n  group_by(group_key) %&gt;%\n  arrange(desc(!is.na(stage_name))) %&gt;%\n  slice(1) %&gt;%\n  ungroup()\n\nduplicated_name &lt;- mc1_nodes_dedup %&gt;%\n  count(name) %&gt;%\n  filter(n &gt; 1)\n\nmc1_nodes_raw %&gt;%\n  filter(name %in% duplicated_name$name) %&gt;%\n  arrange(name)\n\n# A tibble: 14 × 12\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 Song        Ancestral E… TRUE           1991 Drea… FALSE   11793           NA\n 2 Song        Ancestral E… FALSE          2039 Avan… TRUE    17133           NA\n 3 RecordLabel Coastal Ech… NA               NA &lt;NA&gt;  NA       4022           NA\n 4 Album       Coastal Ech… NA             2023 Psyc… TRUE    15065         2019\n 5 Song        Postcards f… TRUE           2023 Indi… TRUE    12852         2023\n 6 Song        Postcards f… FALSE          1984 Acou… FALSE   17214           NA\n 7 Album       Shattered R… NA             2013 Emo/… TRUE     3325         2013\n 8 Song        Shattered R… FALSE          2036 Dark… TRUE    17088           NA\n 9 Song        Unheard Fre… TRUE           2025 Alte… TRUE     7999           NA\n10 RecordLabel Unheard Fre… NA               NA &lt;NA&gt;  NA      10952           NA\n11 Song        Vanishing P… TRUE           2018 Avan… TRUE     9371         2018\n12 Song        Vanishing P… FALSE          2013 Ocea… FALSE   17338           NA\n13 RecordLabel Vertical Ho… NA               NA &lt;NA&gt;  NA       2453           NA\n14 Album       Vertical Ho… NA             2017 Doom… TRUE     9262           NA\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n\n3.3.3 Check for duplicates in mc1_edges_raw\nThe following code proceeds to check for duplicates in mc1_edges_raw.\n\n# Step 1: Identify duplicate combinations\nduplicate_summary &lt;- mc1_edges_raw %&gt;%\n  count(source, target, `Edge Type`) %&gt;%\n  filter(n &gt; 1)\n\n# Step 2: Join back to get all original duplicate rows\nmc1_edges_raw %&gt;%\n  inner_join(duplicate_summary, by = c(\"source\", \"target\", \"Edge Type\"))\n\n# A tibble: 6 × 5\n  `Edge Type` source target   key     n\n  &lt;chr&gt;        &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 PerformerOf  17057  17058     0     2\n2 PerformerOf  17057  17058     1     2\n3 PerformerOf  17349  17350     0     2\n4 PerformerOf  17349  17350     2     2\n5 PerformerOf  17355  17356     0     2\n6 PerformerOf  17355  17356     2     2\n\n\nThere are duplicates as seen above, with only differences in key. As key will not be used in subsequent data analysis, the duplicated edges will be removed with the following code.\n\nmc1_edges_raw &lt;- mc1_edges_raw %&gt;%\n  distinct(source, target, `Edge Type`, .keep_all = TRUE) %&gt;%\n  select(!key)\n\nmc1_edges_raw %&gt;%\n  count(source, target, `Edge Type`) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 4\n# ℹ 4 variables: source &lt;int&gt;, target &lt;int&gt;, Edge Type &lt;chr&gt;, n &lt;int&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#explore-and-inspect-nodes",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#explore-and-inspect-nodes",
    "title": "Take-home Exercise 2",
    "section": "4.1 Explore and inspect Nodes",
    "text": "4.1 Explore and inspect Nodes\n\nmc1_nodes_raw$release_date %&gt;% unique()\n\n [1] 2017   NA 2026 2020 2027 2022 2007 2010 2003 2023 1997 2013 2000 2025 2029\n[16] 2015 2018 2016 2014 2028 2021 2030 2011 1994 2004 1998 1991 1999 2024 2012\n[31] 2002 2006 2008 2019 1995 1989 2032 2009 2001 1996 1990 1984 2005 1993 1986\n[46] 1985 1981 1992 1987 1988 1983 2031 1975 2035 2033 2037 2036 2039 2038 2034\n[61] 1977 1979 1980 1982 2040\n\nmc1_nodes_raw %&gt;%\n  filter(grepl(\"Sailor Shift\", name)) #Sailor Shift is in name column and not in stage_name column\n\n# A tibble: 1 × 12\n  `Node Type` name         single release_date genre notable    id written_date\n  &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n1 Person      Sailor Shift NA               NA &lt;NA&gt;  NA      17255           NA\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n' will be removed from name to prevent issues with tooltip in tidygraph.\n\nmc1_nodes_clean &lt;- mc1_nodes_raw %&gt;%\n  mutate(\n    name = gsub(\"'\", \"\", name)) \n  \nkable(head(mc1_nodes_clean))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type\nname\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\nis_sailor\nis_oceanus_folk\n\n\n\n\nSong\nBreaking These Chains\nTRUE\n2017\nOceanus Folk\nTRUE\n0\nNA\nNA\nNA\nFALSE\nTRUE\n\n\nPerson\nCarlos Duffy\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nPerson\nMin Qin\nNA\nNA\nNA\nNA\n2\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nPerson\nXiuying Xie\nNA\nNA\nNA\nNA\n3\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nRecordLabel\nNautical Mile Records\nNA\nNA\nNA\nNA\n4\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nSong\nUnshackled Heart\nFALSE\n2026\nLo-Fi Electronica\nTRUE\n5\nNA\nNA\nNA\nFALSE\nFALSE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#explore-and-inspect-edges",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#explore-and-inspect-edges",
    "title": "Take-home Exercise 2",
    "section": "4.2 Explore and inspect Edges",
    "text": "4.2 Explore and inspect Edges\nThe following code chunk is used to ensure that id used in mc1_edges_raw matches the range range of id in mc1_nodes_clean.\n\nrange(mc1_nodes_clean$id)\n\n[1]     0 17411\n\nrange(mc1_edges_raw$source)\n\n[1]     0 17411\n\nrange(mc1_edges_raw$target)\n\n[1]     0 17411"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#mapping-node-name-to-edges-id",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#mapping-node-name-to-edges-id",
    "title": "Take-home Exercise 2",
    "section": "4.3 Mapping Node name to Edges id",
    "text": "4.3 Mapping Node name to Edges id\ntidygraph uses from and to columns to reference nodes. By default, tidygraph matches these edges reference against the first column in the nodes table, or against name column.\nCurrently, source and target columns in mc1_edges_raw contain id values that correspond to the id column in mc1_nodes_clean. To properly integrate with tidygraph’s conventions, the following will be done:\n\nRestructure mc1_nodes_clean\n\nRename the current name column to node_name - this is done to preserve the actual node names\nRename the id column to name so it becomes the primary identifier column that tidygraph will use for matching\n\nRename source and target columns in mc1_edges_raw, as required by tidygraph\nEnsure data type consistency: Convert the name column (formerly id) to character format to match the data type of the edge references\n\n\nmc1_nodes_clean &lt;- mc1_nodes_dedup %&gt;%\n  rename(node_name = name, name = id) %&gt;%\n  mutate(name = as.character(name)) %&gt;%\n  select(`Node Type`, node_name, release_date, genre, notable, name, single, written_date, stage_name, notoriety_date, is_sailor, is_oceanus_folk)\n\nmc1_nodes_clean\n\n# A tibble: 14,077 × 12\n   `Node Type` node_name    release_date genre notable name  single written_date\n   &lt;chr&gt;       &lt;chr&gt;               &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;chr&gt; &lt;lgl&gt;         &lt;int&gt;\n 1 Album       A Lush Dyst…         2031 Psyc… TRUE    17005 NA             2030\n 2 Album       Addicted to…         2004 Sout… TRUE    14658 NA             2000\n 3 Album       Adriatic Em…         2013 Post… TRUE    10412 NA               NA\n 4 Album       Aerial Echo…         2023 Indi… TRUE    7908  NA               NA\n 5 Album       Aftershock …         2028 Drea… TRUE    2030  NA             2021\n 6 Album       Allegretto …         2020 Indi… TRUE    6251  NA               NA\n 7 Album       Alleys and …         2029 Jazz… TRUE    1310  NA               NA\n 8 Album       Alloy Archi…         2017 Indi… TRUE    8428  NA             2017\n 9 Album       Almost (But…         2027 Alte… TRUE    14611 NA             2027\n10 Album       Altar of De…         2020 Ocea… TRUE    5883  NA               NA\n# ℹ 14,067 more rows\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n4.3.1 Creating edge mapping from old id to kept id\nIn section 3.3.2, duplicated nodes were deduplicated and removed, edges referring to the removed nodes will become invalid thus, edges will be remapped to the retained nodes. This ensures that all edges correctly point to existing nodes in the deduplicated graph.\n\n# Step 1: Create mapping of all group_key → kept id\nkey_to_id_map &lt;- mc1_nodes_dedup %&gt;%\n  select(group_key, kept_id = id)\n\n# Step 2: Map all original rows to the retained ID\nid_remap &lt;- mc1_nodes_tagged %&gt;%\n  left_join(key_to_id_map, by = \"group_key\") %&gt;%\n  select(original_id = id, kept_id)\n\nid_remap\n\n# A tibble: 17,412 × 2\n   original_id kept_id\n         &lt;int&gt;   &lt;int&gt;\n 1           0       0\n 2           1       1\n 3           2   14470\n 4           3       3\n 5           4       4\n 6           5       5\n 7           6       6\n 8           7       7\n 9           8       8\n10           9       9\n# ℹ 17,402 more rows\n\n\n\n# Step 3: Replace edges' source and target with mapped kept_id\nmc1_edges_mapped &lt;- mc1_edges_raw %&gt;%\n  left_join(id_remap, by = c(\"source\" = \"original_id\"))\n\nmc1_edges_mapped\n\n# A tibble: 37,854 × 4\n   `Edge Type`      source target kept_id\n   &lt;chr&gt;             &lt;int&gt;  &lt;int&gt;   &lt;int&gt;\n 1 InterpolatesFrom      0   1841       0\n 2 RecordedBy            0      4       0\n 3 PerformerOf           1      0       1\n 4 ComposerOf            1  16180       1\n 5 PerformerOf           2      0   14470\n 6 ProducerOf            2  16180   14470\n 7 PerformerOf           3      0       3\n 8 InterpolatesFrom      5   5088       5\n 9 InStyleOf             5  14332       5\n10 InterpolatesFrom      5  11677       5\n# ℹ 37,844 more rows\n\n\n\nmc1_edges_mapped &lt;- mc1_edges_mapped %&gt;%\n  mutate(source = kept_id) %&gt;%\n  select(-kept_id) %&gt;%\n  left_join(id_remap, by = c(\"target\" = \"original_id\")) %&gt;%\n  mutate(target = kept_id) %&gt;%\n  select(-kept_id) %&gt;%\n  rename(from = source, to = target) %&gt;%\n  mutate(from = as.character(from), to = as.character(to))\n\nmc1_edges_mapped\n\n# A tibble: 37,854 × 3\n   `Edge Type`      from  to   \n   &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;\n 1 InterpolatesFrom 0     1841 \n 2 RecordedBy       0     4    \n 3 PerformerOf      1     0    \n 4 ComposerOf       1     16180\n 5 PerformerOf      14470 0    \n 6 ProducerOf       14470 16180\n 7 PerformerOf      3     0    \n 8 InterpolatesFrom 5     5088 \n 9 InStyleOf        5     14332\n10 InterpolatesFrom 5     11677\n# ℹ 37,844 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#remove-unmatched-edges",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#remove-unmatched-edges",
    "title": "Take-home Exercise 2",
    "section": "4.4 Remove unmatched edges",
    "text": "4.4 Remove unmatched edges\nThe following code chunk removes edges that reference missing node id, ensuring that only valid edges are kept.\n\nmc1_edges_clean &lt;- mc1_edges_mapped %&gt;%\n  filter(!is.na(from), !is.na(to))\n\nThere are no unmatched edges."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#check-for-missing-nodes",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#check-for-missing-nodes",
    "title": "Take-home Exercise 2",
    "section": "4.5 Check for missing nodes",
    "text": "4.5 Check for missing nodes\nThe following code chunk checks for missing nodes being referenced in mc1_edges_clean that do not exist in mc1_nodes_clean.\n\nsetdiff(\n  unique(c(mc1_edges_clean$from, mc1_edges_clean$to)),\n  mc1_nodes_clean$name\n)\n\ncharacter(0)\n\n\nThere are no missing nodes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#validate-edges-schema",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#validate-edges-schema",
    "title": "Take-home Exercise 2",
    "section": "4.6 Validate Edges Schema",
    "text": "4.6 Validate Edges Schema\nThis section aims to ensure that each edge in the graph adheres to the schema specified in the VAST Challenge 2025 MC1 Data Description document. The following code checks whether the node types connect by each edge matches the valid source and target types for that edge’s type.\n\n# Define valid source and destination types for each edge type\nedge_rules &lt;- list(\n  PerformerOf = list(source = c(\"Person\", \"MusicalGroup\"), target = c(\"Song\", \"Album\")),\n  ComposerOf = list(source = c(\"Person\"), target = c(\"Song\", \"Album\")),\n  ProducerOf = list(source = c(\"Person\", \"RecordLabel\"), target = c(\"Song\", \"Album\", \"Person\", \"MusicalGroup\")),\n  LyricistOf = list(source = c(\"Person\"), target = c(\"Song\", \"Album\")),\n  RecordedBy = list(source = c(\"Song\", \"Album\"), target = c(\"RecordLabel\")),\n  DistributedBy = list(source = c(\"Song\", \"Album\"), target = c(\"RecordLabel\")),\n  InStyleOf = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\", \"Person\", \"MusicalGroup\")),\n  InterpolatesFrom = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  CoverOf = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  LyricalReferenceTo = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  DirectlySamples = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  MemberOf = list(source = c(\"Person\"), target = c(\"MusicalGroup\"))\n)\n\nThe following code chunk checks for any erroneous edge and node relationships defined in the code chunk above.\n\n# Create a lookup for node types\nnode_type_lookup &lt;- mc1_nodes_clean %&gt;%\n  select(name, `Node Type`) %&gt;%\n  deframe()\n\n# Add source and target node types to the edge table\nmc1_edges_checked &lt;- mc1_edges_clean %&gt;%\n  mutate(\n    source_type = node_type_lookup[from],\n    target_type = node_type_lookup[to]\n  )\n\nmc1_edges_tagged &lt;- mc1_edges_checked %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    valid = {\n      rule &lt;- edge_rules[[`Edge Type`]]\n      if (is.null(rule)) TRUE\n      else {\n        source_type %in% rule$source && target_type %in% rule$target\n      }\n    }\n  ) %&gt;%\n  ungroup()\n\n# Count and display invalid edge combinations\ninvalid_edge_summary &lt;- mc1_edges_tagged %&gt;%\n  filter(!valid) %&gt;%\n  count(`Edge Type`, source_type, target_type, sort = TRUE)\n\nprint(invalid_edge_summary)\n\n# A tibble: 24 × 4\n   `Edge Type`      source_type  target_type      n\n   &lt;chr&gt;            &lt;chr&gt;        &lt;chr&gt;        &lt;int&gt;\n 1 LyricistOf       MusicalGroup Song           106\n 2 RecordedBy       RecordLabel  Album          102\n 3 ProducerOf       MusicalGroup Song           100\n 4 ComposerOf       MusicalGroup Song            97\n 5 ProducerOf       MusicalGroup Album           31\n 6 LyricistOf       MusicalGroup Album           28\n 7 ComposerOf       MusicalGroup Album           17\n 8 InStyleOf        MusicalGroup MusicalGroup    12\n 9 InStyleOf        Person       MusicalGroup    11\n10 InterpolatesFrom MusicalGroup MusicalGroup    10\n# ℹ 14 more rows\n\n\n\n# Check total invalid edge count\ncat(\"Total invalid edges:\", sum(!mc1_edges_tagged$valid), \"\\n\")\n\nTotal invalid edges: 550 \n\n\nThere are 550 edges that do not adhere to the schema specified in the data description file provided. The following code will remove these edges.\n\n# Keep only valid edges\nmc1_edges_clean &lt;- mc1_edges_tagged %&gt;%\n  filter(valid) %&gt;%\n  select(from, to, `Edge Type`)  # drop helper columns"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#visualising-edge-and-node-types",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#visualising-edge-and-node-types",
    "title": "Take-home Exercise 2",
    "section": "4.7 Visualising Edge and Node types",
    "text": "4.7 Visualising Edge and Node types\n\nggplot(data = mc1_edges_clean,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = mc1_nodes_clean,\n       aes(y = `Node Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#creating-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#creating-knowledge-graph",
    "title": "Take-home Exercise 2",
    "section": "4.8 Creating knowledge graph",
    "text": "4.8 Creating knowledge graph\ntbl_graph() is used to create tidygraph’s graph object by using the following code chunk.\n\nmusic = tbl_graph(edges = mc1_edges_clean,\n                             nodes = mc1_nodes_clean,\n                             directed = TRUE)\n\nclass(music)\n\n[1] \"tbl_graph\" \"igraph\"   \n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-1a---who-has-she-been-most-influenced-by-over-time",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-1a---who-has-she-been-most-influenced-by-over-time",
    "title": "Take-home Exercise 2",
    "section": "5.1 Question 1a - Who has she been most influenced by over time?",
    "text": "5.1 Question 1a - Who has she been most influenced by over time?\nThe network structure below shows how Sailor Shift’s career has been influenced by others. PageRank is used to measure the overall influence of each person, musical group or work within the network. This captures both direct and indirect influences.\n\nNetwork VisualisationInfluence Summary\n\n\n\n\nCode\n# Step 0: Get name of 'Sailor Shift'\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;%\n  first()\n\n# Step 1: Find direct influence relationships from Sailor Shift\n# These are the artists/works that Sailor Shift has been influenced by\ndirect_influence_types &lt;- c(\"InStyleOf\", \"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\")\n\nsailor_direct_influences &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name, \n         `Edge Type` %in% direct_influence_types)\n\n# Step 2: Get immediate neighbors (people/groups Sailor Shift works with)\nsailor_out_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name)\n\nsailor_out_node_names &lt;- sailor_out_edges$to\n\n# Step 3: Split into people/groups vs songs/albums\nsailor_person_group &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_out_node_names, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\nsailor_songs_all &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_out_node_names, `Node Type` %in% c(\"Song\", \"Album\")) %&gt;%\n  pull(name)\n\n# Step 4: For songs/albums, find their direct influences too\nsong_influences &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs_all, \n         `Edge Type` %in% direct_influence_types)\n\n# Step 5: Get all influence targets (who influenced Sailor Shift or their works)\nall_influence_targets &lt;- unique(c(\n  sailor_direct_influences$to,\n  song_influences$to\n))\n\n# Step 6: Get creators of Sailor Shift's works (indirect influence indicators)\ncreator_edge_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\")\n\nsailor_songs &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs_all) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\nsailor_songs_out_nodes &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs) %&gt;%\n  pull(to)\n\ncreator_edges &lt;- mc1_edges_clean %&gt;%\n  filter(to %in% sailor_songs_out_nodes, `Edge Type` %in% creator_edge_types)\n\nsailor_people_group_neighbourhood_nodes &lt;- creator_edges %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 7: Combine all relevant nodes for subgraph\nsailor_all_node_names &lt;- unique(c(\n  sailor_vertex_name,\n  sailor_person_group,\n  sailor_songs,\n  sailor_songs_out_nodes,\n  sailor_people_group_neighbourhood_nodes,\n  all_influence_targets  \n))\n\n# Step 8: Create subgraph\nsub_music &lt;- music %&gt;%\n  filter(name %in% sailor_all_node_names)\n\n# Step 9: Calculate PageRank \nsub_music &lt;- sub_music %&gt;%\n  activate(nodes) %&gt;%\n  mutate(\n    pagerank = centrality_pagerank()\n  )\n\n# Step 10: Set node size based on PageRank for people/groups, fixed for others\nsub_music &lt;- sub_music %&gt;%\n  mutate(\n    is_sailor = name == sailor_vertex_name,\n    node_color = ifelse(is_sailor, \"red\", \"grey30\"),\n    tooltip_text = sprintf(\n      \"Name: %s\\nType: %s\\nPageRank: %.4f\",\n      node_name, `Node Type`, pagerank\n    ),\n    node_size = case_when(\n      `Node Type` %in% c(\"Person\", \"MusicalGroup\") ~ rescale(pagerank, to = c(4, 20)),\n      TRUE ~ 4  \n    )\n  )\n\n# Step 11: Create visualization\ng &lt;- sub_music %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(\n    aes(color = `Edge Type`), \n    alpha = 0.3,\n    arrow = arrow(length = unit(3, 'mm')),\n    end_cap = circle(3, 'mm')\n  ) +\n  geom_point_interactive(\n    aes(\n      x = x, y = y,\n      data_id = name,\n      tooltip = tooltip_text,\n      shape = `Node Type`,\n      colour = node_color,\n      size = node_size\n    )\n  ) +\n  scale_shape_discrete(name = \"Node Type\") +\n  scale_colour_identity() +\n  scale_size_identity() +\n  theme_graph(base_family = \"sans\") +\n  labs(\n    title = \"Network of Influences on Sailor Shift\"\n  )\n\ngirafe(ggobj = g, width_svg = 10, height_svg = 8)\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to people and groups only, exclude Sailor Shift node itself\ntop_influencers &lt;- sub_music %&gt;%\n  as_tibble() %&gt;%\n  filter(\n    `Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n    name != sailor_vertex_name\n  ) %&gt;%\n  arrange(desc(pagerank)) %&gt;%\n  slice_head(n = 5)\n\n# Plot\nggplot(top_influencers, aes(x = reorder(node_name, pagerank), y = pagerank, fill = `Node Type`)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    title = \"Top 5 Influences on Sailor Shift\",\n    x = \"Influencer\",\n    y = \"PageRank Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the PageRank score, it is noted that she is most influenced by musical groups as the top 3 most influences are musical groups. Phantom Roots have influenced her the most over time, this is followed by Ursus and the group she was a part of, Ivy Echos."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-1b---who-has-she-collaborated-with-and-directly-or-indirectly-influenced",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-1b---who-has-she-collaborated-with-and-directly-or-indirectly-influenced",
    "title": "Take-home Exercise 2",
    "section": "5.2 Question 1b - Who has she collaborated with and directly or indirectly influenced?",
    "text": "5.2 Question 1b - Who has she collaborated with and directly or indirectly influenced?\nThe network visualisation below explores Sailor Shift’s collaborations and influence. While the primary question centers on Sailor Shift, the analysis also incorporates Ivy Echos, the musical group that she was a member of. Including Ivy Echos is essential because Sailor Shift’s creative impact can extend beyond her solo work as her contributions as part of Ivy Echos could have influenced others. The visualisation therefore highlights not just individuals and groups who have collaborated with Sailor Shift on her works, but also those influenced by Ivy Echos, providing an extensive picture of her influence.\n\n\nCode\n# Step 1: Define all relevant edge types per schema\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\ninfluence_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\n# Step 2: Get Sailor Shift's node ID\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;% first()\n\n# Step 3: Find all Sailor Shift's works (songs/albums she performed or was lyricist of)\nsailor_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% c(\"PerformerOf\", \"LyricistOf\"), from == sailor_vertex_name) %&gt;%\n  pull(to)\n\n# Step 4: Find all Person/MusicalGroup collaborated on Sailor Shift's works (excluding herself)\nsailor_collab_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, to %in% sailor_works, from != sailor_vertex_name)\nsailor_collab_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_collab_edges$from, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\n# Step 5: Get Ivy Echos's node ID and works\nivy_echos_name &lt;- mc1_nodes_clean %&gt;%\n  filter(str_detect(node_name, regex(\"Ivy Echos\", ignore_case = TRUE))) %&gt;%\n  pull(name) %&gt;% first()\nivy_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` == \"PerformerOf\", from == ivy_echos_name) %&gt;%\n  pull(to)\nivy_works &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% ivy_works, `Node Type` %in% c(\"Song\", \"Album\")) %&gt;%\n  pull(name)\n\n# Step 6: Find all works influenced by Ivy Echos's works (Ivy Echos's works as destination of influence edges)\nivy_influenced_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_types, to %in% ivy_works)\nivy_influenced_works &lt;- ivy_influenced_edges$from\n\n# Step 7: For each influenced work, get the people/groups involved (collaborators on those works)\nivy_influenced_collab_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, to %in% ivy_influenced_works)\nivy_influenced_collab_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% ivy_influenced_collab_edges$from, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\n# Step 8: Collect all relevant nodes and edges for the network\nall_relevant_nodes &lt;- unique(c(\n  sailor_vertex_name,\n  sailor_collab_nodes,\n  sailor_works,\n  ivy_echos_name,\n  ivy_works,\n  ivy_influenced_works,\n  ivy_influenced_collab_nodes\n))\n\nall_relevant_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% all_relevant_nodes & to %in% all_relevant_nodes)\n\n# Step 9: Annotate node roles for plotting\nsub_nodes_df &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% all_relevant_nodes) %&gt;%\n  mutate(\n    node_role = case_when(\n      name == sailor_vertex_name ~ \"Sailor Shift\",\n      name == ivy_echos_name ~ \"Ivy Echos\",\n      name %in% sailor_collab_nodes ~ \"Sailor Shift Collaborator\",\n      name %in% sailor_works ~ \"Sailor Shift Work\",\n      name %in% ivy_works ~ \"Ivy Echos Work\",\n      name %in% ivy_influenced_works ~ \"Work Influenced by Ivy Echos\",\n      name %in% ivy_influenced_collab_nodes ~ \"Person/Group in Influenced Work\",\n      TRUE ~ \"Other\"\n    ),\n    node_color = case_when(\n      node_role == \"Sailor Shift\" ~ \"red\",\n      node_role == \"Ivy Echos\" ~ \"purple\",\n      node_role == \"Sailor Shift Collaborator\" ~ \"blue\",\n      node_role == \"Sailor Shift Work\" ~ \"grey30\",\n      node_role == \"Ivy Echos Work\" ~ \"green\",\n      node_role == \"Work Influenced by Ivy Echos\" ~ \"orange\",\n      node_role == \"Person/Group in Influenced Work\" ~ \"pink\",\n      TRUE ~ \"steelblue\"\n    ),\n    tooltip_text = paste0(\n      \"Name: \", node_name, \"\\n\",\n      \"Type: \", `Node Type`, \"\\n\",\n      \"Role: \", node_role, \"\\n\",\n      ifelse(!is.na(genre), paste0(\"Genre: \", genre, \"\\n\"), \"\"),\n      ifelse(!is.na(release_date), paste0(\"Release: \", release_date, \"\\n\"), \"\")\n    )\n  )\n\n# Step 10: Create tidygraph object and layout\ncareer_graph &lt;- tbl_graph(nodes = sub_nodes_df, edges = all_relevant_edges, directed = TRUE) %&gt;%\n  activate(nodes)\n\nlayout_df &lt;- create_layout(career_graph, layout = \"fr\") %&gt;%\n  as_tibble() %&gt;%\n  select(name, x, y)\n\nnodes_plot &lt;- as_tibble(career_graph) %&gt;%\n  left_join(layout_df, by = \"name\")\n\nedges_plot &lt;- all_relevant_edges %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n  rename(x_from = x, y_from = y) %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n  rename(x_to = x, y_to = y)\n\n# Step 11: Get coordinates for annotation\nsailor_coords &lt;- nodes_plot %&gt;%\n  filter(name == sailor_vertex_name) %&gt;%\n  select(x, y)\nivy_coords &lt;- nodes_plot %&gt;%\n  filter(name == ivy_echos_name) %&gt;%\n  select(x, y)\n\n# Step 12: Plot with ggplot2 + ggiraph, with annotation and legend\np &lt;- ggplot() +\n  geom_segment(\n    data = edges_plot,\n    aes(\n      x = x_from, y = y_from, xend = x_to, yend = y_to,\n      color = `Edge Type`\n    ),\n    alpha = 0.4, arrow = arrow(length = unit(3, 'mm'))\n  ) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Edge Type\") +\n  ggnewscale::new_scale_color() +\n  geom_point_interactive(\n    data = nodes_plot,\n    aes(\n      x = x, y = y,\n      tooltip = tooltip_text,\n      data_id = name,\n      color = node_role,  \n      shape = `Node Type`\n    ),\n    size = 4\n  ) +\n  scale_color_manual(\n    name = \"Node Role\",\n    values = c(\n      \"Sailor Shift\" = \"red\",\n      \"Ivy Echos\" = \"purple\", \n      \"Sailor Shift Collaborator\" = \"blue\",\n      \"Sailor Shift Work\" = \"grey30\",\n      \"Ivy Echos Work\" = \"green\",\n      \"Work Influenced by Ivy Echos\" = \"orange\",\n      \"Person/Group in Influenced Work\" = \"pink\",\n      \"Other\" = \"steelblue\"\n    ),\n    breaks = c(\n      \"Sailor Shift\",\n      \"Ivy Echos\", \n      \"Sailor Shift Collaborator\",\n      \"Sailor Shift Work\",\n      \"Ivy Echos Work\",\n      \"Work Influenced by Ivy Echos\",\n      \"Person/Group in Influenced Work\"\n    )\n  ) +\n  theme_void() +\n  labs(title = \"Sailor Shift's Collaborators and Influence\") +\n  guides(\n    color = guide_legend(\n      title = \"Node Role\",\n      override.aes = list(size = 4),\n      title.position = \"top\"\n    ),\n    shape = guide_legend(\n      title = \"Node Type\",\n      title.position = \"top\"\n    )\n  ) +\n  theme(\n    legend.position = \"right\",\n    legend.box = \"vertical\",\n    plot.title = element_text(size = 20, face = \"bold\") \n  )\n\ngirafe(ggobj = p, width_svg = 12, height_svg = 8)\n\n\n\n\n\n\nThe visualisation shows a wide array of individuals and musical groups who have collaborated with Sailor Shift on various works, this reflects her active engagement within the industry. While there are no instances of Sailor Shift directly influencing other artists, the visualisation reveals that her group, Ivy Echos, has influenced a group and four individuals through a song (Deepsea Fireflies, released in 2025). This demonstrates that Sailor Shift’s reach extends beyond her personal collaborations, contributing to a broader legacy through her involvement with Ivy Echos."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-1c---how-has-she-influenced-collaborators-of-the-broader-oceanus-folk-community",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-1c---how-has-she-influenced-collaborators-of-the-broader-oceanus-folk-community",
    "title": "Take-home Exercise 2",
    "section": "5.3 Question 1c - How has she influenced collaborators of the broader Oceanus Folk community?",
    "text": "5.3 Question 1c - How has she influenced collaborators of the broader Oceanus Folk community?\nThe network visualisation aims to analyse how Sailor Shift influenced collaborators of the broader Oceanus Folk community.\nSailor Shift and her group (Ivy Echos) were primary entities of interest, all works associated to them are compiled to form the foundation of Sailor Shift’s musical output. Based on this, several types of influence were analysed:\n\nDirect influence - This includes Oceanus Folk collaborators’ works that were explicity influenced by Sailor Shift or Ivy Echos through relationships such as CoverOf, InterpolatesFrom, LyricalReferenceTo, DirectlySamples, and InStyleOf.\nIndirect (two-step influence) - This occurs when a work by Sailor Shift or Ivy Echos influences an intermediate piece, which then goes on to influence a work by an Oceanus Folk collaborator. These two-step chains shows how Sailor Shift’s influence can propagate through the network.\nCross-collaborator influence - This captures intra-community influence where Oceanus Folk works that were initially influenced by Sailor Shift/Ivy Echos proceeded to influence other Oceanus Folk creations.\nCollaboration-mediated influence - This is transmitted through shared or bridge collaborators.\n\nShared collaborators are individuals or groups who worked with both Sailor Shift/Ivy Echos and the Oceanus Folk community\nBridge Collaborators are those who first worked with Sailor Shift/Ivy Echos and later collaborated with Ocean Folk Contributors.\n\n\nBased on the influences above, it reveals the full extent of Sailor Shift’s reach within the Oceanus Folk Community.\n\n\nCode\n# Step 1: Define edge types\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\ninfluence_edge_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\n# Step 2: Identify all nodes with genre == \"Oceanus Folk\"\noceanus_folk_works &lt;- mc1_nodes_clean %&gt;%\n  filter(genre == \"Oceanus Folk\") %&gt;%\n  pull(name)\n\n# Step 3: Identify all Person and MusicalGroup who are collaborators on Oceanus Folk works\noceanus_folk_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         to %in% oceanus_folk_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 4: Get Sailor Shift and Ivy Echos\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;% \n  first()\n\nivy_echos_name &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` == \"MemberOf\", from == sailor_vertex_name) %&gt;%\n  pull(to) %&gt;%\n  first()\n\n# Step 5: Find all works that Sailor Shift and Ivy Echos have created/performed\nsailor_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, from == sailor_vertex_name) %&gt;%\n  pull(to)\n\nivy_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, from == ivy_echos_name) %&gt;%\n  pull(to)\n\nsailor_ivy_works &lt;- unique(c(sailor_works, ivy_works))\n\n# Step 6: Find all works that the Oceanus Folk collaborators have worked on\noceanus_collaborator_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         from %in% oceanus_folk_collaborators) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\n# Step 7: Direct influence - Sailor Shift/Ivy Echos works influencing Oceanus collaborator works\ndirect_influence &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works,\n         to %in% oceanus_collaborator_works) %&gt;%\n  mutate(influence_direction = \"Sailor/Ivy → Oceanus\",\n         pathway_type = \"Direct\")\n\n# Step 8: Indirect influence - Multi-step pathways\n\n# 8a: Find intermediate works that could bridge Sailor Shift/Ivy Echos to Oceanus\n# Works influenced BY Sailor/Ivy\nsailor_influenced_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\n# Works that influence Sailor/Ivy  \nsailor_influencing_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         to %in% sailor_ivy_works) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# All intermediate works in potential pathways\nintermediate_works &lt;- unique(c(sailor_influenced_works, sailor_influencing_works))\n\n# 8b: Two-step influence: Sailor/Ivy → Intermediate → Oceanus collaborators\nindirect_influence_step1 &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works,\n         to %in% intermediate_works) %&gt;%\n  select(sailor_work = from, intermediate_work = to, step1_edge_type = `Edge Type`)\n\nindirect_influence_step2 &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% intermediate_works,\n         to %in% oceanus_collaborator_works) %&gt;%\n  select(intermediate_work = from, oceanus_work = to, step2_edge_type = `Edge Type`)\n\n# Join to find complete 2-step pathways\ntwo_step_pathways &lt;- indirect_influence_step1 %&gt;%\n  inner_join(indirect_influence_step2, by = \"intermediate_work\") %&gt;%\n  mutate(pathway_type = \"Indirect (2-step)\",\n         influence_direction = \"Sailor/Ivy → Intermediate → Oceanus\")\n\n# 8c: Cross-collaborator influence within Oceanus community\n# Find Oceanus works that were influenced by Sailor and then influenced other Oceanus works\ndirectly_influenced_oceanus_works &lt;- unique(c(direct_influence$to, two_step_pathways$oceanus_work))\n\ncross_collab_influence &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% directly_influenced_oceanus_works,\n         to %in% oceanus_collaborator_works,\n         from != to) %&gt;%\n  mutate(pathway_type = \"Cross-collaborator\",\n         influence_direction = \"Sailor-influenced Oceanus work → Other Oceanus work\")\n\n# Step 9: Collaboration-mediated influence \n\n# 9a: People who worked with both Sailor/Ivy AND Oceanus Folk collaborators\nsailor_ivy_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         to %in% sailor_ivy_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\nshared_collaborators &lt;- intersect(sailor_ivy_collaborators, oceanus_folk_collaborators)\n\n# 9b. Bridge collaborators - worked with Sailor/Ivy, then later with other Oceanus Folk collaborators\nbridge_collaborators &lt;- setdiff(sailor_ivy_collaborators, oceanus_folk_collaborators)\nbridge_to_oceanus &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         from %in% bridge_collaborators) %&gt;%\n  inner_join(\n    mc1_edges_clean %&gt;%\n      filter(`Edge Type` %in% collab_credit_types,\n             from %in% oceanus_folk_collaborators) %&gt;%\n      select(shared_work = to),\n    by = c(\"to\" = \"shared_work\")\n  ) %&gt;%\n  select(bridge_person = from, shared_work = to) %&gt;%\n  distinct()\n\n# Step 10: Identify influenced Oceanus Folk Collaborators \n\n# Get all works that show influence from Sailor/Ivy\nall_influenced_oceanus_works &lt;- unique(c(\n  direct_influence$to,\n  two_step_pathways$oceanus_work,\n  cross_collab_influence$to\n))\n\n# Find which Oceanus Folk collaborators worked on these influenced works\ndirectly_influenced_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         to %in% all_influenced_oceanus_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n         from %in% oceanus_folk_collaborators) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Add collaborators connected through shared/bridge relationships\ncollaboration_influenced &lt;- unique(c(shared_collaborators, bridge_to_oceanus$bridge_person))\ncollaboration_influenced &lt;- intersect(collaboration_influenced, oceanus_folk_collaborators)\n\ntotal_influenced_collaborators &lt;- unique(c(directly_influenced_collaborators, collaboration_influenced))\n\n# Prepare variables for tabset (initialize as NULL)\np &lt;- NULL\nsummary_stats &lt;- NULL\n\n# Step 11: Enhanced network visualisation and summary statistics \nif(length(total_influenced_collaborators) &gt; 0) {\n  \n  # Collect all relevant nodes for visualization\n  all_pathway_works &lt;- unique(c(\n    sailor_ivy_works,\n    direct_influence$from, direct_influence$to,\n    two_step_pathways$sailor_work, two_step_pathways$intermediate_work, two_step_pathways$oceanus_work,\n    cross_collab_influence$from, cross_collab_influence$to\n  ))\n  \n  all_relevant_people &lt;- unique(c(\n    sailor_vertex_name,\n    ivy_echos_name,\n    total_influenced_collaborators,\n    shared_collaborators,\n    bridge_to_oceanus$bridge_person\n  ))\n  \n  all_viz_nodes &lt;- unique(c(all_pathway_works, all_relevant_people))\n  \n  # Enhanced node classification\n  viz_nodes &lt;- mc1_nodes_clean %&gt;%\n    filter(name %in% all_viz_nodes) %&gt;%\n    mutate(\n      influence_strength = case_when(\n        name %in% direct_influence$to ~ \"Direct Target\",\n        name %in% two_step_pathways$oceanus_work ~ \"Indirect Target\", \n        name %in% cross_collab_influence$to ~ \"Secondary Target\",\n        name %in% shared_collaborators ~ \"Shared Collaborator\",\n        name %in% bridge_to_oceanus$bridge_person ~ \"Bridge Collaborator\",\n        TRUE ~ \"Network Node\"\n      ),\n      node_role = case_when(\n        name == sailor_vertex_name ~ \"Sailor Shift\",\n        name == ivy_echos_name ~ \"Ivy Echos\",\n        name %in% sailor_ivy_works ~ \"Sailor/Ivy Work\",\n        name %in% oceanus_folk_works ~ \"Oceanus Folk Work\",\n        name %in% total_influenced_collaborators ~ \"Influenced Oceanus Collaborator\",\n        name %in% oceanus_folk_collaborators ~ \"Other Oceanus Collaborator\",\n        name %in% intermediate_works ~ \"Intermediate Work\",\n        TRUE ~ \"Other\"\n      ),\n      node_color = case_when(\n        node_role == \"Sailor Shift\" ~ \"red\",\n        node_role == \"Ivy Echos\" ~ \"purple\", \n        node_role == \"Sailor/Ivy Work\" ~ \"gray30\",\n        influence_strength == \"Direct Target\" ~ \"darkred\",\n        influence_strength == \"Indirect Target\" ~ \"orange\",\n        influence_strength == \"Secondary Target\" ~ \"yellow\",\n        influence_strength == \"Shared Collaborator\" ~ \"blue\",\n        influence_strength == \"Bridge Collaborator\" ~ \"cyan\",\n        node_role == \"Influenced Oceanus Collaborator\" ~ \"darkgreen\",\n        node_role == \"Other Oceanus Collaborator\" ~ \"lightgreen\",\n        node_role == \"Intermediate Work\" ~ \"pink\",\n        TRUE ~ \"lightgray\"\n      ),\n      node_size = case_when(\n        node_role %in% c(\"Sailor Shift\", \"Ivy Echos\") ~ 8,\n        influence_strength %in% c(\"Direct Target\", \"Shared Collaborator\") ~ 6,\n        influence_strength %in% c(\"Indirect Target\", \"Bridge Collaborator\") ~ 5,\n        influence_strength == \"Secondary Target\" ~ 4,\n        TRUE ~ 3\n      ),\n      tooltip_text = paste0(\n        \"Name: \", node_name, \"\\n\",\n        \"Role: \", node_role, \"\\n\", \n        \"Influence: \", influence_strength, \"\\n\",\n        \"Type: \", `Node Type`, \"\\n\",\n        ifelse(!is.na(genre), paste0(\"Genre: \", genre), \"\")\n      )\n    )\n  \n  # Collect all relevant edges preserving original Edge Types\n  all_influence_edges &lt;- bind_rows(\n    direct_influence %&gt;% mutate(pathway_category = \"Direct\"),\n    two_step_pathways %&gt;% \n      select(from = sailor_work, to = intermediate_work, `Edge Type` = step1_edge_type) %&gt;%\n      mutate(pathway_category = \"Indirect Step 1\"),\n    two_step_pathways %&gt;% \n      select(from = intermediate_work, to = oceanus_work, `Edge Type` = step2_edge_type) %&gt;%\n      mutate(pathway_category = \"Indirect Step 2\"),\n    cross_collab_influence %&gt;% \n      select(from, to, `Edge Type`) %&gt;%\n      mutate(pathway_category = \"Cross-Collaborator\")\n  )\n  \n  viz_edges &lt;- mc1_edges_clean %&gt;%\n    filter(from %in% all_viz_nodes, to %in% all_viz_nodes) %&gt;%\n    left_join(\n      all_influence_edges %&gt;% select(from, to, pathway_category),\n      by = c(\"from\", \"to\")\n    ) %&gt;%\n    mutate(\n      # Categorize edges for visual emphasis while keeping original Edge Type\n      edge_category = case_when(\n        !is.na(pathway_category) ~ \"Influence Pathway\",\n        `Edge Type` == \"MemberOf\" & from == sailor_vertex_name ~ \"Key Membership\", \n        `Edge Type` %in% collab_credit_types ~ \"Collaboration\",\n        `Edge Type` %in% influence_edge_types ~ \"Other Influence\",\n        TRUE ~ \"Other\"\n      ),\n      edge_alpha = case_when(\n        edge_category == \"Influence Pathway\" ~ 0.9,\n        edge_category == \"Key Membership\" ~ 0.8,\n        edge_category == \"Collaboration\" ~ 0.4,\n        edge_category == \"Other Influence\" ~ 0.6,\n        TRUE ~ 0.2\n      )\n    )\n  \n  # Create network plot\n  influence_graph &lt;- tbl_graph(nodes = viz_nodes, edges = viz_edges, directed = TRUE)\n\n  layout_df &lt;- create_layout(influence_graph, layout = \"fr\") %&gt;%\n    as_tibble() %&gt;%\n    select(name, x, y)\n  \n  nodes_plot &lt;- as_tibble(influence_graph) %&gt;%\n    left_join(layout_df, by = \"name\")\n  \n  edges_plot &lt;- viz_edges %&gt;%\n    left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n    rename(x_from = x, y_from = y) %&gt;%\n    left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n    rename(x_to = x, y_to = y)\n  \n  # Create legend data frame for node colors\n  legend_data &lt;- data.frame(\n    node_color = c(\"red\", \"purple\", \"gray30\", \"darkred\", \"orange\", \"yellow\", \n                   \"blue\", \"cyan\", \"darkgreen\", \"lightgreen\", \"pink\", \"lightgray\"),\n    node_role = c(\"Sailor Shift\", \"Ivy Echos\", \"Sailor/Ivy Work\", \"Direct Target\", \n                  \"Indirect Target\", \"Secondary Target\", \"Shared Collaborator\", \n                  \"Bridge Collaborator\", \"Influenced Oceanus Collaborator\", \n                  \"Other Oceanus Collaborator\", \"Intermediate Work\", \"Other\"),\n    stringsAsFactors = FALSE\n  )\n  \n  p &lt;- ggplot() +\n    geom_segment(\n      data = edges_plot,\n      aes(x = x_from, y = y_from, xend = x_to, yend = y_to,\n          color = `Edge Type`, alpha = edge_alpha),\n      arrow = arrow(length = unit(1.5, 'mm'))\n    ) +\n    scale_alpha_identity() +\n    scale_color_discrete(name = \"Edge Type\") +\n    ggnewscale::new_scale_color() +\n    geom_point_interactive(\n      data = nodes_plot,\n      aes(x = x, y = y, tooltip = tooltip_text, data_id = name,\n          color = node_color, shape = `Node Type`, size = node_size)\n    ) +\n    scale_size_identity() +  \n    scale_color_manual(\n      name = \"Node Role\",\n      values = c(\"red\" = \"red\", \"purple\" = \"purple\", \"pink\" = \"pink\", \"darkred\" = \"darkred\",\n                 \"orange\" = \"orange\", \"yellow\" = \"yellow\", \"blue\" = \"blue\", \"cyan\" = \"cyan\", \n                 \"darkgreen\" = \"darkgreen\", \"lightgreen\" = \"lightgreen\",\n                 \"gray30\" = \"gray30\", \"lightgray\" = \"lightgray\"),\n      labels = setNames(legend_data$node_role, legend_data$node_color),\n      breaks = legend_data$node_color,\n      guide = guide_legend(override.aes = list(size = 4, shape = 16))\n    ) +\n    geom_text(\n      data = nodes_plot %&gt;% filter(node_role == \"Sailor Shift\"),\n      aes(x = x, y = y, label = \"Sailor Shift\"),\n      size = 4, fontface = \"bold\", color = \"red\", vjust = -2\n    ) +\n    theme_void() +\n    theme(\n      legend.position = \"right\",\n      legend.box = \"vertical\",\n      legend.text = element_text(size = 11),\n      legend.title = element_text(size = 16),\n      plot.title = element_text(size = 20, face = \"bold\"), \n      plot.subtitle = element_text(size = 16, face = \"plain\")    \n    ) +\n    labs(\n      title = \"Sailor Shift's Influence on Oceanus Folk Community\",\n      subtitle = str_to_title(\"Influence pathways: Direct (work-to-work), Indirect (via intermediary), Secondary (cross-collaborator), Shared/Bridge (collaboration networks)\")\n    )\n  \n  # Create summary statistics data frame\nsummary_stats &lt;- data.frame(\n  Metric = c(\n    \"Total Oceanus Folk collaborators\",\n    \"Total influenced collaborators\",\n    \"Percentage influenced (%)\",\n    \"\",\n    \"Direct influences\",\n    \"Two-step pathways\", \n    \"Cross-collaborator influences\",\n    \"Shared collaborators\",\n    \"Bridge collaborators\"\n  ),\n  Value = c(\n    length(oceanus_folk_collaborators),\n    length(total_influenced_collaborators),\n    round(100 * length(total_influenced_collaborators) / length(oceanus_folk_collaborators), 1),\n    \"\",\n    nrow(direct_influence),\n    nrow(two_step_pathways),\n    nrow(cross_collab_influence),\n    length(shared_collaborators),\n    length(unique(bridge_to_oceanus$bridge_person))\n  ),\n  stringsAsFactors = FALSE\n)\n}\n\n\n\nNetwork VisualisationSummary Statistics\n\n\n\n\nCode\ngirafe(ggobj = p, width_svg = 16, height_svg = 12)\n\n\n\n\n\n\n\n\n\n\nCode\nknitr::kable(\n  summary_stats,\n  col.names = c(\"Metric\", \"Count\"),\n  caption = \"Sailor Shift's Influence Analysis Summary\"\n)\n\n\n\nSailor Shift’s Influence Analysis Summary\n\n\nMetric\nCount\n\n\n\n\nTotal Oceanus Folk collaborators\n720\n\n\nTotal influenced collaborators\n81\n\n\nPercentage influenced (%)\n11.2\n\n\n\n\n\n\nDirect influences\n9\n\n\nTwo-step pathways\n11\n\n\nCross-collaborator influences\n10\n\n\nShared collaborators\n42\n\n\nBridge collaborators\n7\n\n\n\n\n\n\n\n\nThe above visualisation focus on the network of influence that Sailor Shift had in the Oceanus Folk community. Out of 720 Oceanus Folk collaborators, she has interacted with 81 collaborators, which is a notable influence as it is more than 10% of the community.\nWhile only 9 collaborators have been directly influenced by working closely with her/Ivy Echos, the majority of her impact is indirect. More than half of the influenced collaborators have been shaped indirectly through shared and bridged collaborators. These network-mediated pathways, including two-step and cross-collaborator connections, illustrates how her influence extends beyond those that she worked directly with.\nOverall, this showcases how Sailor Shift’s influence diffuses dynamically throughout the community where her impact in the community is not only driven by direct collaborations, but also by the broader web of relationships and interactions that connect the Oceanus Folk community."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#influence-of-oceanus-folk",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#influence-of-oceanus-folk",
    "title": "Take-home Exercise 2",
    "section": "Influence of Oceanus Folk",
    "text": "Influence of Oceanus Folk\nShowcases direct (first degree) and indirect influence (second degree)\n\n\nCode\n# Load required library\nlibrary(visNetwork)\n\n# Step 1: Identify all Oceanus Folk nodes\noceanus_folk_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(is_oceanus_folk == TRUE) %&gt;%\n  pull(name)\n\n# Step 2: Get all outgoing edges from Oceanus Folk nodes\nfirst_level_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% oceanus_folk_nodes)\n\n# Step 3: Get nodes connected to Oceanus Folk (first level)\nfirst_level_nodes &lt;- unique(c(first_level_edges$from, first_level_edges$to))\n\n# Step 4: Get second level edges (from first level nodes)\nsecond_level_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% first_level_nodes)\n\n# Step 5: Get all nodes (first and second level)\nall_nodes &lt;- unique(c(second_level_edges$from, second_level_edges$to))\n\n# Step 6: Prepare final nodes and edges\nviz_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% all_nodes) %&gt;%\n  mutate(\n    id = name,\n    label = substr(node_name, 1, 15),\n    color = ifelse(is_oceanus_folk, \"red\", \n                   ifelse(is_sailor, \"blue\", \"lightblue\")),\n    size = ifelse(is_oceanus_folk, 30, 20)\n  ) %&gt;%\n  select(id, label, color, size)\n\nviz_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% all_nodes & to %in% all_nodes) %&gt;%\n  select(from, to)\n\n# Create simple visNetwork\nvisNetwork(viz_nodes, viz_edges)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-2a---was-this-influence-intermittent-or-did-it-have-a-gradual-rise",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-2a---was-this-influence-intermittent-or-did-it-have-a-gradual-rise",
    "title": "Take-home Exercise 2",
    "section": "Question 2a - Was this influence intermittent or did it have a gradual rise?",
    "text": "Question 2a - Was this influence intermittent or did it have a gradual rise?\n\n\nCode\nlibrary(DT)\n# Step 1: Get all Oceanus Folk nodes with dates\noceanus_folk_timeline &lt;- mc1_nodes_clean %&gt;%\n  filter(is_oceanus_folk == TRUE & !is.na(release_date)) %&gt;%\n  select(name, node_name, release_date, `Node Type`) %&gt;%\n  arrange(release_date)\n\n# Step 2: Find nodes influenced by Oceanus Folk\noceanus_influence_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% oceanus_folk_timeline$name) %&gt;%\n  pull(name)\n\n# Get all edges from Oceanus Folk nodes\ninfluence_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% oceanus_influence_nodes)\n\n# Get influenced nodes\ninfluenced_timeline &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% influence_edges$to & !is.na(release_date)) %&gt;%\n  left_join(influence_edges, by = c(\"name\" = \"to\")) %&gt;%\n  left_join(mc1_nodes_clean %&gt;% select(name, source_name = node_name), \n            by = c(\"from\" = \"name\")) %&gt;%\n  select(name, node_name, release_date, `Node Type`, `Edge Type`, source_name) %&gt;%\n  arrange(release_date)\n\n# Step 3: Combine and analyze timeline\nall_timeline &lt;- bind_rows(\n  oceanus_folk_timeline %&gt;% mutate(category = \"Original Oceanus Folk\"),\n  influenced_timeline %&gt;% mutate(category = \"Directly Influenced\") %&gt;%\n                          select(name, node_name, release_date, `Node Type`, category)\n)\n\n# Step 4: Create yearly summary\nyearly_summary &lt;- all_timeline %&gt;%\n  count(release_date, category) %&gt;%\n  complete(release_date = full_seq(release_date, 1), \n           category, fill = list(n = 0)) %&gt;%\n  arrange(release_date)\n\n# Step 5: Calculate cumulative influence\ncumulative_summary &lt;- yearly_summary %&gt;%\n  group_by(category) %&gt;%\n  mutate(cumulative = cumsum(n)) %&gt;%\n  ungroup()\n\n\n\nAnnual releasesCumulative releasesOceanus Folk releasesWorks directly influenced by Oceanus Folk\n\n\n\n\nCode\nggplot(yearly_summary, aes(x = release_date, y = n, fill = category)) +\n  geom_col(position = \"dodge\", alpha = 0.7) +\n  geom_smooth(aes(color = category), method = \"loess\", se = FALSE, span = 0.5, formula = y ~ x, show.legend = FALSE) +\n  scale_fill_manual(values = c(\"Original Oceanus Folk\" = \"red\", \n                               \"Directly Influenced\" = \"grey30\")) +\n  scale_color_manual(values = c(\"Original Oceanus Folk\" = \"red\", \n                                \"Directly Influenced\" = \"grey30\")) +\n  labs(title = \"Oceanus Folk Influence Over Time - Annual Releases\",\n       x = \"Release Year\", \n       y = \"Number of Releases\",\n       fill = \"Category\", \n       color = \"Trend\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(cumulative_summary, aes(x = release_date, y = cumulative, color = category)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(size = 2) +\n  scale_color_manual(values = c(\"Original Oceanus Folk\" = \"red\", \n                              \"Directly Influenced\" = \"grey30\")) +\n  labs(title = \"Cumulative Oceanus Folk Influence Over Time\",\n       subtitle = \"Shows whether influence was gradual or intermittent\",\n       x = \"Release Year\", \n       y = \"Cumulative Number of Releases\",\n       color = \"Category\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndatatable(oceanus_folk_timeline, \n          caption = \"Original Oceanus Folk Releases\",\n          options = list(pageLength = 10, scrollX = TRUE),\n          filter = 'top')\n\n\n\n\n\n\n\n\n\n\nCode\ndatatable(influenced_timeline, \n          caption = \"Releases Directly Influenced by Oceanus Folk\",\n          options = list(pageLength = 10, scrollX = TRUE),\n          filter = 'top')\n\n\n\n\n\n\n\n\n\nLooking at works which are directly influenced by Oceanus Folk, the releases started increasing from 2000 and peak around 2010 but started to decline in the late 2010s. Thus, the influence was gradual but started to fade in late 2010s till 2040."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-2b---what-genres-and-top-artists-have-been-most-influenced-by-oceanus-folk",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-2b---what-genres-and-top-artists-have-been-most-influenced-by-oceanus-folk",
    "title": "Take-home Exercise 2",
    "section": "Question 2b - What genres and top artists have been most influenced by Oceanus Folk?",
    "text": "Question 2b - What genres and top artists have been most influenced by Oceanus Folk?\n\n\nCode\n# Find directly influenced nodes\ninfluenced_timeline &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% influence_edges$to & !is.na(release_date)) %&gt;%\n  left_join(influence_edges, by = c(\"name\" = \"to\")) %&gt;%\n  left_join(mc1_nodes_clean %&gt;% select(name, source_name = node_name), \n            by = c(\"from\" = \"name\")) %&gt;%\n  select(name, node_name, release_date, `Node Type`, `Edge Type`, source_name, genre) %&gt;%\n  arrange(release_date)\n\n# Exclude 'Oceanus Folk' from genres\ntop_genres &lt;- influenced_timeline %&gt;%\n  filter(!is.na(genre), genre != \"Oceanus Folk\") %&gt;%  \n  count(genre, sort = TRUE) %&gt;%\n  top_n(10, n)\n\n# Bar plot\nggplot(top_genres, aes(x = reorder(genre, n), y = n, fill = n)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1, size = 3) +\n  scale_fill_gradient(low = \"#fee0d2\", high = \"#99000d\") + \n  labs(\n    title = \"Top 10 Genres Influenced by Oceanus Folk\",\n    x = \"Genre\",\n    y = \"Number of Influenced Works\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  ylim(0, max(top_genres$n) * 1.1)\n\n\n\n\n\n\n\n\n\nThe above showed that Indie Folk was the most significantly influenced, followed by Synthwave and Dream Pop.\nThe following analysis focuses on artists who have been most influenced by Oceanus Folk works using network analysis and PageRank centrality measures.\n\nDirect influence: Artists whose works explicitly reference, cover, interpolate from, sample, or are styled after Oceanus Folk pieces\nIndirect influence: Artists influenced by works that were themselves influenced by Oceanus Folk (2-step influence chains)\n\nThe PageRank metric accounts for both the quantity and quality of influence connections, giving higher scores to artists who are:\n\nInfluenced by multiple Oceanus Folk works\nConnected to highly influential works in the network\nPart of important influence cascades\n\n\nInfluence OverviewTop Influenced Artists RankingInfluence Pathways AnalysisSummary Statistics\n\n\n\n\nCode\n# Step 1: Define influence edge types\ninfluence_types &lt;- c(\"InStyleOf\", \"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\")\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\n\n# Step 2: Identify all Oceanus Folk works\noceanus_folk_works &lt;- mc1_nodes_clean %&gt;%\n  filter(genre == \"Oceanus Folk\") %&gt;%\n  pull(name)\n\n# Step 3: Find all works that are directly influenced by Oceanus Folk works\ndirect_influence_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_types, \n         to %in% oceanus_folk_works)\n\ndirectly_influenced_works &lt;- direct_influence_edges$from\n\n# Step 4: Find artists/groups who created the influenced works\ninfluenced_artists_direct &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         to %in% directly_influenced_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 5: Find indirect influence (2-step pathways)\nsecond_level_influence_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_types,\n         to %in% directly_influenced_works)\n\nsecond_level_influenced_works &lt;- second_level_influence_edges$from\n\ninfluenced_artists_indirect &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         to %in% second_level_influenced_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 6: Combine all influenced artists\nall_influenced_artists &lt;- unique(c(influenced_artists_direct, influenced_artists_indirect))\n\n# Step 7: Build the influence network (artist/work subgraph)\n# Gather all relevant nodes (works and artists) and edges\nrelevant_works &lt;- unique(c(oceanus_folk_works, directly_influenced_works, second_level_influenced_works))\nrelevant_artists &lt;- unique(c(influenced_artists_direct, influenced_artists_indirect))\nrelevant_nodes &lt;- unique(c(relevant_works, relevant_artists))\n\n# Filter nodes and edges for the subgraph\ninfluence_network_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% relevant_nodes)\n\ninfluence_network_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% relevant_nodes, to %in% relevant_nodes)\n\n# Create tidygraph object for the influence network\ninfluence_network &lt;- tbl_graph(\n  nodes = influence_network_nodes,\n  edges = influence_network_edges,\n  directed = TRUE\n)\n\n# Step 8: Calculate centrality measures\ninfluence_network &lt;- influence_network %&gt;%\n  activate(nodes) %&gt;%\n  mutate(\n    pagerank = centrality_pagerank(directed = TRUE, damping = 0.85),\n    betweenness = centrality_betweenness(directed = TRUE),\n    in_degree = centrality_degree(mode = \"in\")\n  )\n\n# Step 9: Create summary visualisation showing the reach of Oceanus Folk influence\ninfluence_summary &lt;- data.frame(\n  Category = c(\"Oceanus Folk Works\", \"Directly Influenced Works\", \"Indirectly Influenced Works\", \n               \"Directly Influenced Artists\", \"Indirectly Influenced Artists\", \"Total Unique Artists\"),\n  Count = c(length(oceanus_folk_works), length(directly_influenced_works), \n            length(second_level_influenced_works), length(influenced_artists_direct),\n            length(influenced_artists_indirect), length(all_influenced_artists))\n)\n\nggplot(influence_summary, aes(x = reorder(Category, Count), y = Count, fill = Count)) +\n  geom_bar(stat = \"identity\", alpha = 0.8) +\n  coord_flip() +\n  scale_fill_gradient(low = \"lightblue\", high = \"steelblue\", name = \"Count\") +\n  labs(\n    title = \"Oceanus Folk Influence Cascade\",\n    subtitle = \"Showing the reach of influence from works to artists\",\n    x = \"Category\",\n    y = \"Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 11)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Step 10: Extract and rank the top influenced artists\ntop_influenced_artists &lt;- influence_network %&gt;%\n  as_tibble() %&gt;%\n  filter(\n    `Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n    name %in% all_influenced_artists\n  ) %&gt;%\n  arrange(desc(pagerank)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(\n    influence_type = case_when(\n      name %in% influenced_artists_direct & name %in% influenced_artists_indirect ~ \"Both Direct & Indirect\",\n      name %in% influenced_artists_direct ~ \"Direct\",\n      name %in% influenced_artists_indirect ~ \"Indirect\",\n      TRUE ~ \"Other\"\n    )\n  ) %&gt;%\n  select(\n    Artist = node_name,\n    Type = `Node Type`, \n    `Influence Type` = influence_type,\n    `PageRank Score` = pagerank,\n    `In-Degree` = in_degree,\n    `Betweenness` = betweenness\n  )\n\n# Step 11: Create visualisation\np1 &lt;- ggplot(top_influenced_artists, aes(x = reorder(Artist, `PageRank Score`), y = `PageRank Score`, fill = `Influence Type`)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Artists Most Influenced by Oceanus Folk\",\n    subtitle = \"Ranked by PageRank centrality score\",\n    x = \"Artist/Group\",\n    y = \"PageRank Score\"\n  ) +\n  scale_fill_brewer(palette = \"Set1\", name = \"Influence Type\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 11),\n    axis.text.y = element_text(size = 10)\n  )\n\nprint(p1)\n\n\n\n\n\n\n\n\n\nCode\n# Step 12: Display detailed table\nknitr::kable(\n  top_influenced_artists,\n  caption = \"Detailed metrics for top influenced artists\",\n  digits = 4\n)\n\n\n\nDetailed metrics for top influenced artists\n\n\n\n\n\n\n\n\n\n\nArtist\nType\nInfluence Type\nPageRank Score\nIn-Degree\nBetweenness\n\n\n\n\nRadiant Siblings\nMusicalGroup\nIndirect\n6e-04\n4\n0.0\n\n\nLunar Drift\nMusicalGroup\nBoth Direct & Indirect\n5e-04\n4\n0.0\n\n\nNordic Kitchen Collective\nMusicalGroup\nBoth Direct & Indirect\n5e-04\n4\n1.5\n\n\nMidnight Protocol\nMusicalGroup\nDirect\n5e-04\n3\n0.0\n\n\nRazor’s Lament\nMusicalGroup\nIndirect\n5e-04\n3\n0.0\n\n\nUndetected\nMusicalGroup\nBoth Direct & Indirect\n5e-04\n3\n0.0\n\n\nLunar Syntax\nMusicalGroup\nDirect\n4e-04\n3\n0.0\n\n\nIvory Pulse\nMusicalGroup\nIndirect\n4e-04\n2\n0.0\n\n\nHex Collective\nMusicalGroup\nBoth Direct & Indirect\n4e-04\n2\n0.0\n\n\nLunar Pulse\nMusicalGroup\nIndirect\n4e-04\n2\n0.0\n\n\n\n\n\n\n\n\n\nCode\n# Summarise the counts of each influence type among edges from Oceanus Folk works\ninfluence_type_summary &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_types, to %in% oceanus_folk_works) %&gt;%\n  group_by(`Influence Type` = `Edge Type`) %&gt;%\n  summarise(Count = n(), .groups = \"drop\") %&gt;%\n  arrange(desc(Count))\n\n# Visualisation\nggplot(influence_type_summary, aes(x = reorder(`Influence Type`, Count), y = Count, fill = Count)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  scale_fill_gradient(low = \"lightblue\", high = \"steelblue\") + \n  coord_flip() +\n  labs(\n    title = \"Types of Influence from Oceanus Folk\",\n    x = \"Influence Type\",\n    y = \"Number of Occurrences\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Prepare summary statistics as a data frame\ninfluence_summary &lt;- data.frame(\n  Statistic = c(\n    \"Total Oceanus Folk works\",\n    \"Total works directly influenced\",\n    \"Total works indirectly influenced\",\n    \"Total artists directly influenced\",\n    \"Total artists indirectly influenced\",\n    \"Total unique influenced artists\",\n    \"Direct influence pathways\"\n  ),\n  Count = c(\n    length(oceanus_folk_works),\n    length(directly_influenced_works),\n    length(second_level_influenced_works),\n    length(influenced_artists_direct),\n    length(influenced_artists_indirect),\n    length(all_influenced_artists),\n    nrow(direct_influence_edges)\n  )\n)\n\n# Display as a kable\nknitr::kable(influence_summary, caption = \"Influence Summary Statistics\")\n\n\n\nInfluence Summary Statistics\n\n\nStatistic\nCount\n\n\n\n\nTotal Oceanus Folk works\n305\n\n\nTotal works directly influenced\n377\n\n\nTotal works indirectly influenced\n345\n\n\nTotal artists directly influenced\n893\n\n\nTotal artists indirectly influenced\n843\n\n\nTotal unique influenced artists\n1143\n\n\nDirect influence pathways\n377\n\n\n\n\n\n\n\n\nThe influence overview highlights how creative works have shaped artists, tracing the reach and depth of Oceanus Folk’s impact in the industry.\nFrom Artists Ranking, Radiant Siblings emerges as the most influenced artists through indirect connections. This is followed by Lunar Drift and the Nordic Kitchen Collective, both of whom were shaped by a combination of direct and indirect influences.\nAmongst the top 10 artists most influenced by Oceanus Folk, 4 were influenced indirectly and another 4 were shaped through both direct and indirect pathway, while only 2, Midnight Protocol and Lunar Syntax, were influenced solely through direct connections.\nLastly, the Influence Pathway Analysis reveals that the most frequent mode of influence was through the InStyleOf relationship, followed by InterpolatesFrom, underscoring stylistic adaptation as a key mechanism of artistic transmission."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-2c---how-has-oceanus-folk-changed-with-the-rise-of-sailor-shift",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02 - working copy.html#question-2c---how-has-oceanus-folk-changed-with-the-rise-of-sailor-shift",
    "title": "Take-home Exercise 2",
    "section": "Question 2c - How has Oceanus Folk changed with the rise of Sailor Shift?",
    "text": "Question 2c - How has Oceanus Folk changed with the rise of Sailor Shift?\n\n\nCode\nlibrary(tidyr)\n\n# Step 1: Get Sailor Shift's career timeline\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;%\n  first()\n\nsailor_debut &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name, `Edge Type` %in% c(\"PerformerOf\", \"LyricistOf\")) %&gt;%\n  left_join(mc1_nodes_clean %&gt;% select(name, release_date), by = c(\"to\" = \"name\")) %&gt;%\n  filter(!is.na(release_date)) %&gt;%\n  arrange(release_date) %&gt;%\n  slice_head(n = 1) %&gt;%\n  pull(release_date)\n\n# Step 2: Analyse Oceanus Folk works before and after Sailor Shift\noceanus_folk_works &lt;- mc1_nodes_clean %&gt;%\n  filter(is_oceanus_folk == TRUE, !is.na(release_date)) %&gt;%\n  mutate(\n    era = case_when(\n      release_date &lt; sailor_debut ~ \"Pre-Sailor Shift\",\n      release_date &gt;= sailor_debut ~ \"Sailor Shift Era\",\n      TRUE ~ \"Unknown\"\n    )\n  )\n\n# Step 3: Find influence sources for Oceanus Folk works\ninfluence_edge_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\noceanus_influences &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% oceanus_folk_works$name) %&gt;%\n  left_join(mc1_nodes_clean %&gt;% select(name, source_genre = genre, source_type = `Node Type`), \n            by = c(\"to\" = \"name\")) %&gt;%\n  left_join(oceanus_folk_works %&gt;% select(name, era, release_date), \n            by = c(\"from\" = \"name\")) %&gt;%\n  filter(!is.na(source_genre), !is.na(era),\n         source_genre != \"Oceanus Folk\") \n\n# Step 4: Analyse genre influences by era\ngenre_influence_summary &lt;- oceanus_influences %&gt;%\n  count(era, source_genre, sort = TRUE) %&gt;%\n  group_by(era) %&gt;%\n  mutate(\n    total_influences = sum(n),\n    percentage = round(100 * n / total_influences, 1)\n  ) %&gt;%\n  ungroup()\n\n# Step 5: Identify contemporary inspiration sources (post-Sailor Shift)\ncontemporary_inspiration &lt;- genre_influence_summary %&gt;%\n  filter(era == \"Sailor Shift Era\") %&gt;%\n  arrange(desc(n)) %&gt;%\n  slice_head(n = 8)\n\n# Step 6: Compare influence patterns between eras\nera_comparison &lt;- genre_influence_summary %&gt;%\n  select(era, source_genre, n, percentage) %&gt;%\n  pivot_wider(names_from = era, values_from = c(n, percentage), values_fill = 0) %&gt;%\n  mutate(\n    change_in_count = `n_Sailor Shift Era` - `n_Pre-Sailor Shift`,\n    change_in_percentage = `percentage_Sailor Shift Era` - `percentage_Pre-Sailor Shift`\n  ) %&gt;%\n  arrange(desc(`n_Sailor Shift Era`))\n\n# Step 7: Analyze temporal patterns of influence\nyearly_genre_influence &lt;- oceanus_influences %&gt;%\n  count(release_date, source_genre) %&gt;%\n  complete(release_date = full_seq(release_date, 1), \n           source_genre, fill = list(n = 0)) %&gt;%\n  arrange(release_date)\n\n# Step 8: Identify emerging vs declining genres\ngenre_trend_analysis &lt;- oceanus_influences %&gt;%\n  mutate(period = case_when(\n    release_date &lt; sailor_debut ~ \"Pre-Sailor\",\n    release_date &gt;= sailor_debut ~ \"Post-Sailor\"\n  )) %&gt;%\n  count(period, source_genre) %&gt;%\n  pivot_wider(names_from = period, values_from = n, values_fill = 0) %&gt;%\n  mutate(\n    total_influence = `Pre-Sailor` + `Post-Sailor`,\n    trend = case_when(\n      `Post-Sailor` &gt; `Pre-Sailor` * 2 ~ \"Strongly Emerging\",\n      `Post-Sailor` &gt; `Pre-Sailor` ~ \"Emerging\",\n      `Post-Sailor` == `Pre-Sailor` ~ \"Stable\",\n      `Post-Sailor` &lt; `Pre-Sailor` & `Post-Sailor` &gt; 0 ~ \"Declining\",\n      `Post-Sailor` == 0 & `Pre-Sailor` &gt; 0 ~ \"Disappeared\",\n      TRUE ~ \"New Genre\"\n    )\n  ) %&gt;%\n  filter(total_influence &gt;= 2) %&gt;%  # Focus on genres with meaningful influence\n  arrange(desc(`Post-Sailor`))\n\n\n\nContemporary Inspiration SourcesEra ComparisonGenre Trend AnalysisTemporal EvolutionSummary Statistics\n\n\n\n\nCode\nggplot(contemporary_inspiration, aes(x = reorder(source_genre, n), y = n, fill = n)) +\n  geom_col(alpha = 0.7) +\n  geom_text(aes(label = paste0(n, \" (\", percentage, \"%)\")), \n            hjust = -0.1, size = 3.5) +\n  coord_flip() +\n  labs(\n    title = \"Top Genres Influencing Oceanus Folk in the Sailor Shift Era\",\n    subtitle = paste0(\"Based on \", sum(contemporary_inspiration$n), \n                 \" influence relationships from \", sailor_debut, \"-\", \n                 max(oceanus_folk_works$release_date, na.rm = TRUE)),\n    x = \"Source Genre\",\n    y = \"Number of Influences\"\n  ) +\n  scale_fill_gradient(low = \"lightblue\", high = \"steelblue\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncomparison_table &lt;- era_comparison %&gt;%\n  select(\n    Genre = source_genre,\n    `Pre-Sailor Count` = `n_Pre-Sailor Shift`,\n    `Pre-Sailor %` = `percentage_Pre-Sailor Shift`,\n    `Sailor Era Count` = `n_Sailor Shift Era`,\n    `Sailor Era %` = `percentage_Sailor Shift Era`,\n    `Change in Count` = change_in_count,\n    `Change in %` = change_in_percentage\n  ) %&gt;%\n  filter(`Sailor Era Count` &gt; 0 | `Pre-Sailor Count` &gt; 0) %&gt;%\n  arrange(desc(`Sailor Era Count`))\n\nkable(comparison_table, \n      caption = \"Oceanus Folk Influence Sources: Before vs After Sailor Shift\",\n      digits = 1)\n\n\n\nOceanus Folk Influence Sources: Before vs After Sailor Shift\n\n\n\n\n\n\n\n\n\n\n\nGenre\nPre-Sailor Count\nPre-Sailor %\nSailor Era Count\nSailor Era %\nChange in Count\nChange in %\n\n\n\n\nIndie Folk\n60\n63.8\n40\n30.8\n-20\n-33.0\n\n\nDream Pop\n2\n2.1\n13\n10.0\n11\n7.9\n\n\nPsychedelic Rock\n2\n2.1\n10\n7.7\n8\n5.6\n\n\nSynthwave\n10\n10.6\n9\n6.9\n-1\n-3.7\n\n\nDesert Rock\n1\n1.1\n8\n6.2\n7\n5.1\n\n\nDoom Metal\n6\n6.4\n8\n6.2\n2\n-0.2\n\n\nIndie Rock\n1\n1.1\n7\n5.4\n6\n4.3\n\n\nAlternative Rock\n2\n2.1\n6\n4.6\n4\n2.5\n\n\nAmericana\n1\n1.1\n4\n3.1\n3\n2.0\n\n\nBlues Rock\n0\n0.0\n4\n3.1\n4\n3.1\n\n\nSpace Rock\n0\n0.0\n4\n3.1\n4\n3.1\n\n\nSynthpop\n7\n7.4\n3\n2.3\n-4\n-5.1\n\n\nSouthern Gothic Rock\n1\n1.1\n3\n2.3\n2\n1.2\n\n\nSymphonic Metal\n0\n0.0\n3\n2.3\n3\n2.3\n\n\nAvant-Garde Folk\n0\n0.0\n2\n1.5\n2\n1.5\n\n\nPost-Apocalyptic Folk\n0\n0.0\n2\n1.5\n2\n1.5\n\n\nEmo/Pop Punk\n0\n0.0\n1\n0.8\n1\n0.8\n\n\nIndie Pop\n0\n0.0\n1\n0.8\n1\n0.8\n\n\nJazz Surf Rock\n0\n0.0\n1\n0.8\n1\n0.8\n\n\nLo-Fi Electronica\n0\n0.0\n1\n0.8\n1\n0.8\n\n\nCeltic Folk\n1\n1.1\n0\n0.0\n-1\n-1.1\n\n\n\n\n\n\n\n\n\nCode\ntrend_colors &lt;- c(\n  \"Strongly Emerging\" = \"darkgreen\",\n  \"Emerging\" = \"lightgreen\", \n  \"Stable\" = \"yellow\",\n  \"Declining\" = \"orange\",\n  \"Disappeared\" = \"red\",\n  \"New Genre\" = \"purple\"\n)\n\nggplot(genre_trend_analysis, aes(x = `Pre-Sailor`, y = `Post-Sailor`, color = trend)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  geom_text(aes(label = source_genre), vjust = -0.5, hjust = 0.5, size = 3, check_overlap = TRUE) +\n  scale_color_manual(values = trend_colors) +\n  labs(\n    title = \"Genre Influence Trends: Pre vs Post Sailor Shift\",\n    subtitle = \"Points above diagonal line indicate genres gaining influence\",\n    x = \"Influences Pre-Sailor Shift\",\n    y = \"Influences Post-Sailor Shift\",\n    color = \"Trend Classification\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Focus on top genres for temporal analysis\ntop_genres &lt;- contemporary_inspiration %&gt;%\n  slice_head(n = 6) %&gt;%\n  pull(source_genre)\n\ntemporal_data &lt;- yearly_genre_influence %&gt;%\n  filter(source_genre %in% top_genres) %&gt;%\n  group_by(source_genre) %&gt;%\n  mutate(cumulative = cumsum(n)) %&gt;%\n  ungroup()\n\nggplot(temporal_data, aes(x = release_date, y = cumulative, color = source_genre)) +\n  geom_line(size = 1.2, alpha = 0.8) +\n  geom_vline(xintercept = sailor_debut, linetype = \"dashed\", color = \"red\", size = 1) +\n  annotate(\"text\", x = sailor_debut + 0.5, y = max(temporal_data$cumulative) * 0.8, \n           label = \"Sailor Shift Debut\", angle = 90, color = \"red\", size = 3.5) +\n  scale_color_brewer(type = \"qual\", palette = \"Set2\") +\n  labs(\n    title = \"Cumulative Influence of Top Genres on Oceanus Folk Over Time\",\n    x = \"Year\",\n    y = \"Cumulative Number of Influences\",\n    color = \"Source Genre\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Create summary statistics\ntotal_pre_sailor &lt;- sum(genre_influence_summary$n[genre_influence_summary$era == \"Pre-Sailor Shift\"])\ntotal_post_sailor &lt;- sum(genre_influence_summary$n[genre_influence_summary$era == \"Sailor Shift Era\"])\n\nunique_genres_pre &lt;- length(unique(oceanus_influences$source_genre[oceanus_influences$era == \"Pre-Sailor Shift\"]))\nunique_genres_post &lt;- length(unique(oceanus_influences$source_genre[oceanus_influences$era == \"Sailor Shift Era\"]))\n\nnew_genres &lt;- genre_trend_analysis %&gt;%\n  filter(trend == \"New Genre\") %&gt;%\n  nrow()\n\nemerging_genres &lt;- genre_trend_analysis %&gt;%\n  filter(trend %in% c(\"Emerging\", \"Strongly Emerging\")) %&gt;%\n  nrow()\n\nsummary_stats &lt;- data.frame(\n  Metric = c(\n    \"Total Oceanus Folk works analyzed\",\n    \"Works in Pre-Sailor Shift era\",\n    \"Works in Sailor Shift era\", \n    \"\",\n    \"Total influence relationships\",\n    \"Influences in Pre-Sailor era\",\n    \"Influences in Sailor Shift era\",\n    \"Percentage increase in influences\",\n    \"\",\n    \"Unique genres (Pre-Sailor)\",\n    \"Unique genres (Sailor Era)\", \n    \"New genres emerged\",\n    \"Genres showing growth\",\n    \"\",\n    \"Top contemporary inspiration\",\n    \"Second most influential genre\",\n    \"Third most influential genre\"\n  ),\n  Value = c(\n    nrow(oceanus_folk_works),\n    sum(oceanus_folk_works$era == \"Pre-Sailor Shift\"),\n    sum(oceanus_folk_works$era == \"Sailor Shift Era\"),\n    \"\",\n    nrow(oceanus_influences),\n    total_pre_sailor,\n    total_post_sailor,\n    paste0(\"+\", round(100 * (total_post_sailor - total_pre_sailor) / total_pre_sailor, 1), \"%\"),\n    \"\",\n    unique_genres_pre,\n    unique_genres_post,\n    new_genres,\n    emerging_genres,\n    \"\",\n    contemporary_inspiration$source_genre[1],\n    contemporary_inspiration$source_genre[2], \n    contemporary_inspiration$source_genre[3]\n  )\n)\n\nkable(summary_stats, \n      col.names = c(\"Metric\", \"Value\"),\n      caption = \"Oceanus Folk Evolution: Key Statistics\")\n\n\n\nOceanus Folk Evolution: Key Statistics\n\n\nMetric\nValue\n\n\n\n\nTotal Oceanus Folk works analyzed\n305\n\n\nWorks in Pre-Sailor Shift era\n156\n\n\nWorks in Sailor Shift era\n149\n\n\n\n\n\n\nTotal influence relationships\n224\n\n\nInfluences in Pre-Sailor era\n94\n\n\nInfluences in Sailor Shift era\n130\n\n\nPercentage increase in influences\n+38.3%\n\n\n\n\n\n\nUnique genres (Pre-Sailor)\n12\n\n\nUnique genres (Sailor Era)\n20\n\n\nNew genres emerged\n0\n\n\nGenres showing growth\n13\n\n\n\n\n\n\nTop contemporary inspiration\nIndie Folk\n\n\nSecond most influential genre\nDream Pop\n\n\nThird most influential genre\nPsychedelic Rock\n\n\n\n\n\n\n\n\nInspiration sources during Sailor Shift’s era\n\nIndie Folk leads with 40 influences (30.8% of total)\nDream Pop follows with 13 influences (10% of total)\nPsychedelic Rock ranks third with 10 influences (7.7% of total)\n\nGenres with biggest growth, comparing pre-Sailor vs Sailor era\n\nDream Pop: +11 influences (+7.9% points)\nPsychedelic Rock: +8 influences (+5.6% points)\nDesert Rock: +7 influences (+5.1% points)\n\nDiversity Impact\n\nGenre diversity increased by 8 genres\nTotal influence relationships increased by 38.3%\n\nThe analysis reveals how Oceanus Folk has evolved significantly with Sailor Shift’s rise, showing both increased diversity in influences and shifts in the relative importance of different genres as inspiration sources.\n\n# Get Sailor Shift's name\nsailor_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name)\n\n\n# Find debut year\nsailor_debut_date &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_name, `Edge Type` %in% c(\"PerformerOf\", \"LyricistOf\")) %&gt;%\n  left_join(mc1_nodes_clean %&gt;% select(name, release_date), by = c(\"to\" = \"name\")) %&gt;%\n  arrange(release_date) %&gt;%\n  slice_head(n = 1) %&gt;%\n  pull(release_date)\n\nprint(paste(\"Sailor Shift debuted in:\", sailor_debut_date))\n\n[1] \"Sailor Shift debuted in: 2024\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html",
    "title": "Hands-on Exercise 8b",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, one can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. This hands-on exercise will cover how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\n\nThis hands-on exercise will be covering the following:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.\n\n\n\n\nEnsure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nThe basic information of the newly created sgpools_sf can be displayed using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data.\n\n\n\n\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n           size = 1,\n           col = \"black\",\n           lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)\n\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)\n\n\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1) + \n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore ending the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#overview",
    "title": "Hands-on Exercise 8b",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, one can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. This hands-on exercise will cover how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#learning-outcomes",
    "title": "Hands-on Exercise 8b",
    "section": "",
    "text": "This hands-on exercise will be covering the following:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#getting-started",
    "title": "Hands-on Exercise 8b",
    "section": "",
    "text": "Ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 8b",
    "section": "",
    "text": "The data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nThe basic information of the newly created sgpools_sf can be displayed using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#drawing-proportional-symbol-map",
    "title": "Hands-on Exercise 8b",
    "section": "",
    "text": "To create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n           size = 1,\n           col = \"black\",\n           lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)\n\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)\n\n\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1) + \n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore ending the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#all-about-tmap-package",
    "title": "Hands-on Exercise 8b",
    "section": "6.1 All about tmap package",
    "text": "6.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#geospatial-data-wrangling-1",
    "title": "Hands-on Exercise 8b",
    "section": "6.2 Geospatial data wrangling",
    "text": "6.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#data-wrangling",
    "title": "Hands-on Exercise 8b",
    "section": "6.3 Data wrangling",
    "text": "6.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#reference",
    "title": "Hands-on Exercise 8b",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html",
    "title": "Hands-on Exercise 8c",
    "section": "",
    "text": "This hands-on exercise provides hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nThis hands-on exercise will be covering the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap\n\n\n\n\n\n\n\n\npacman::p_load(tmap, tidyverse, sf)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\n\n\n\n\n\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(fill = \"wp_functional\",\n             fill.scale = tm_scale_intervals(\n               style = \"equal\",\n               n = 10,\n               values = \"brewer.blues\"),\n             fill.legend = tm_legend(\n               position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of functional water point by LGAs\")\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(fill = \"total_wp\",\n             fill.scale = tm_scale_intervals(\n               style = \"equal\",\n               n = 10,\n               values = \"brewer.blues\"),\n             fill.legend = tm_legend(\n               position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of total water point by LGAs\")\n\n\ntmap_arrange(p2, p1, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nTabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_polygons(\"pct_functional\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Rate map of functional water point by LGAs\")\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_polygons(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nTest the newly created function with the following code.\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map.\nArguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nReturns:\n\nA tmap-element (plots a map)\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#overview",
    "title": "Hands-on Exercise 8c",
    "section": "",
    "text": "This hands-on exercise provides hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nThis hands-on exercise will be covering the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#getting-started",
    "title": "Hands-on Exercise 8c",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 8c",
    "section": "",
    "text": "p1 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(fill = \"wp_functional\",\n             fill.scale = tm_scale_intervals(\n               style = \"equal\",\n               n = 10,\n               values = \"brewer.blues\"),\n             fill.legend = tm_legend(\n               position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of functional water point by LGAs\")\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(fill = \"total_wp\",\n             fill.scale = tm_scale_intervals(\n               style = \"equal\",\n               n = 10,\n               values = \"brewer.blues\"),\n             fill.legend = tm_legend(\n               position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of total water point by LGAs\")\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 8c",
    "section": "",
    "text": "In much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nTabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_polygons(\"pct_functional\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Rate map of functional water point by LGAs\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#extreme-value-maps",
    "title": "Hands-on Exercise 8c",
    "section": "",
    "text": "Extreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_polygons(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nTest the newly created function with the following code.\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map.\nArguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nReturns:\n\nA tmap-element (plots a map)\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  }
]