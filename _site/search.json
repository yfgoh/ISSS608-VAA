[
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html",
    "title": "TestMC2",
    "section": "",
    "text": "This take-home exercise will be covering VAST Challenge 2025 Mini-Challenge 2.\n\n\n\nOceanus has enjoyed a relatively simple, fishing-based economy for decades. However, in recent times tourism has greatly expanded and resulted in significant changes. The local government set up an oversight board - Commission on Overseeing the Economic Future of Oceanus (COOTEFOO) - to monitor the current economy and advise how to prepare for the future. It is an appointed board that has no direct power on rules/spending BUT has a lot of clout in the civil service and gets government money to do its job…ostensibly in an unbiased way.\nRecently COOTEFOO was hit by a sequence of scandals that roughly break down into two camps:\n\nFishing is Living and Heritage (FILAH) accuses the board of being biased toward the new tourism economy and inappropriately attending to the potential in those ventures, ignoring the historical powerhouse of the economy: Getting lots of fish out of the water and off to hungry people. They accuse some COOTEFOO members of bias against fishing.\nTourism Raises OceanUs Together (TROUT) accuses the board of being biased toward an entrenched interest and constantly “appeasing” the fishing industry, ignoring the new/growing avenues for economic stability. They accuse some members of ignoring the brave-new-world and living in the past.\n\nA journalist, Edwina Darling Moray (E.D. to her friends), at the Haacklee Herald is working on a story about government accountability. She has acquired the datasets that TROUT and FILIAH are working from, which includes meeting minutes and travel records of COOTEFOO members. She also has acquired additional records that TROUT and FILAH did not. Moray has employed a staff programmer to massage the data into a consistent format for analysis – a knowledge graph. You are picking up the work from that programmer to design visualizations to support Moray’s understanding of what is going on. Moray is not a knowledge graph expert, but she understands the workings of Oceanus well. She wants you to design a visual interface to explore the accusations in context and discern which are founded and which are spurious.\n\n\n\n\nBased on the datasets that TROUT & FILAH have provided, use visual analytics to determine if each group’s accusations are supported by their own record set. In other words, develop a visualization to highlight bias (if present) in TROUT & FILAHS datasets. Is there evidence of bias in the COOTEFOO member actions in either dataset?\nAs a journalist, Ms. Moray would like a more complete picture of the COOTEFOO’s actions and activities. She has arranged to combine the data provided by TROUT and FILAH into a single knowledge graph along with additional records. Design visual analytics approaches for this combined knowledge graph to see how members of COOTEFOO spend their time. Is the committee as a whole biased? Provide visual evidence for your conclusions.\nThe TROUT and FILAH datasets are incomplete. Use your visualizations to compare and contrast conclusions drawn from the TROUT and FILAH datasets separately with behaviors in the whole dataset. Are the accusations of TROUT strengthened, weakened or unchanged when taken in context of the whole dataset?\nDesign a visualization that allows Ms. Moray to pick a person and highlight the differences in that person’s behavior as illustrated through the different datasets. Focus on the contrast in the story each dataset tells.\n\nPick at least one COOTEFOO member accused by TROUT. Illustrate how your understanding of their activities changed when using the more complete dataset.\nWhat are the key pieces of evidence missing from the original TROUT data that most influenced the change in judgement.\nWhose behaviors are most impacted by sampling bias when looking at the FILAH dataset in context of the other data?\nIllustrate the bias of the FILAH data in the context of the whole dataset.\n\n\n\n\n\nFor the purpose of this exercise, five R packages will be used. They are tidyverse, jsonlite, tidygraph, ggraph and SmartEDA.\n\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environemnt.\n\npacman::p_load(tidyverse, jsonlite,\n               tidygraph, ggraph,\n               SmartEDA)\n\n\n\n\nFor the purpose of this exercise, FILAH.json file will be used.\nIn the code chunk below, fromJSON() of jsonlite package is used to import FILAH.json file into R and save the output object\n\nfilah &lt;- fromJSON(\"MC2/data/FILAH.json\")\ntrout &lt;- fromJSON(\"MC2/data/TROUT.json\")\njournalist &lt;- fromJSON(\"MC2/data/journalist.json\")\nroad_map &lt;- fromJSON(\"MC2/data/road_map.json\")\n\n\n\nBefore preparing the data, it is always a good practice to examine the structure of filah knowledge graph.\nIn the code chunk below glimpse() is used to reveal the structure of filah knowledge graph.\n\nglimpse(filah)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 396 obs. of  17 variables:\n  ..$ type       : chr [1:396] \"meeting\" \"meeting\" \"meeting\" \"meeting\" ...\n  ..$ date       : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ label      : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ id         : chr [1:396] \"Meeting_1\" \"Meeting_2\" \"Meeting_3\" \"Meeting_4\" ...\n  ..$ name       : chr [1:396] NA NA NA NA ...\n  ..$ role       : chr [1:396] NA NA NA NA ...\n  ..$ short_topic: chr [1:396] NA NA NA NA ...\n  ..$ long_topic : chr [1:396] NA NA NA NA ...\n  ..$ short_title: chr [1:396] NA NA NA NA ...\n  ..$ long_title : chr [1:396] NA NA NA NA ...\n  ..$ plan_type  : chr [1:396] NA NA NA NA ...\n  ..$ lat        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ lon        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ zone       : chr [1:396] NA NA NA NA ...\n  ..$ zone_detail: chr [1:396] NA NA NA NA ...\n  ..$ start      : chr [1:396] NA NA NA NA ...\n  ..$ end        : chr [1:396] NA NA NA NA ...\n $ links     :'data.frame': 765 obs. of  9 variables:\n  ..$ role     : chr [1:765] \"part_of\" \"part_of\" \"part_of\" \"part_of\" ...\n  ..$ source   : chr [1:765] \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" ...\n  ..$ target   : chr [1:765] \"fish_vacuum_Meeting_1_Introduction_Discussion\" \"fish_vacuum_Meeting_1_Introduction\" \"seafood_festival_Meeting_1_Discussion\" \"seafood_festival_Meeting_1_Feasibility\" ...\n  ..$ key      : int [1:765] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:765] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:765] NA NA NA NA ...\n  ..$ industry :List of 765\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. .. [list output truncated]\n  ..$ status   : chr [1:765] NA NA NA NA ...\n  ..$ time     : chr [1:765] NA NA NA NA ...\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that Industry field is in list data type. In general, this data type is not acceptable by tbl_graph() of tidygraph. In order to avoid error arise when building tidygraph object, it is wiser to exclude this field from the edges data table. However, it might be still useful in subsequent analysis.\n\n\n\n\n\n\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from filah tibble dataframe into two separate tibble dataframes called filah_nodes and filah_edges respectively.\n\nfilah_nodes &lt;- as_tibble(filah$nodes)\nfilah_edges &lt;- as_tibble(filah$links)\n\n\n\nIn the code chunk below, ExpCatViz() of SmartEDA package is used to reveal the frequency distribution of all categorical fields in filah_nodes tibble dataframe.\n\nExpCatViz(data=filah_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\nOn the other hands, code chunk below uses ExpCATViz() of SmartEDA package to reveal the frequency distribution of all categorical fields in filah_edges tibble dataframe.\n\nExpCatViz(data=filah_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nExpNumViz(filah_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\nExpNumViz(filah_edges)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfilah_nodes_cleaned &lt;- filah_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(id, type, label)   \n\n\n\n\n\nfilah_edges_cleaned &lt;- filah_edges %&gt;%\n  rename(from = source, to = target) %&gt;%\n  mutate(across(c(from, to), as.character)) %&gt;%\n  filter(from %in% filah_nodes_cleaned$id, to %in% filah_nodes_cleaned$id)\n\n# Remove problematic columns from edge table for graph building\nfilah_edges_min &lt;- filah_edges_cleaned %&gt;%\n  select(from, to, role)  # Only basic fields needed for graph structure\n\n\n\n\n\nfilah_graph &lt;- tbl_graph(\n  nodes = filah_nodes_cleaned, \n  edges = filah_edges_min, \n  directed = TRUE)\n\n\n\n\n\n\n\nNote\n\n\n\nSince the similar steps will be used to clean and wrangle TROUT.json and journalist.json, you might want to consider converting the above code chunks into R function(s).\n\n\n\n\n\n\n\n\nclean_nodes &lt;- function(nodes_df) {\n  nodes_df %&gt;%\n    mutate(id = as.character(id)) %&gt;%\n    filter(!is.na(id)) %&gt;%\n    distinct(id, .keep_all = TRUE) %&gt;%\n    select(id, type, label)\n}\n\n\n\n\n\nclean_edges &lt;- function(edges_df, cleaned_nodes_df) {\n  edges_df %&gt;%\n    rename(from = source, to = target) %&gt;%\n    mutate(across(c(from, to), as.character)) %&gt;%\n    filter(from %in% cleaned_nodes_df$id, to %in% cleaned_nodes_df$id)\n}\n\n\n\n\n\nminimize_edges &lt;- function(cleaned_edges_df) {\n  cleaned_edges_df %&gt;%\n    select(from, to, role)\n}\n\n\n\n\n\nbuild_graph &lt;- function(nodes_df, edges_df) {\n  tbl_graph(\n    nodes = nodes_df,\n    edges = edges_df,\n    directed = TRUE\n  )\n}\n\n\n\n\n\nprocess_graph_data &lt;- function(nodes_df, edges_df) {\n  nodes_cleaned &lt;- clean_nodes(nodes_df)\n  edges_cleaned &lt;- clean_edges(edges_df, nodes_cleaned)\n  edges_min &lt;- minimize_edges(edges_cleaned)\n  build_graph(nodes_cleaned, edges_min)\n}\n\n\n\n\n\n\nIn this section, we will use ggraph’s functions to visualise and analyse the graph object.\n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)\n\nIn the code chunk below, ggraph functions are used to create the whole graph.\n\nggraph(filah_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: ggrepel: 245 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nglimpse(trout)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 164 obs. of  17 variables:\n  ..$ type       : chr [1:164] \"plan\" \"plan\" \"plan\" \"meeting\" ...\n  ..$ short_title: chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" NA ...\n  ..$ long_title : chr [1:164] \"Present findings from the environmental impact study\" \"Report on travel and submit letter of support for low-volume unload crane\" \"Discuss maintenance plan and designate travel representatives\" NA ...\n  ..$ plan_type  : chr [1:164] \"Report\" \"report\" \"proposal\" NA ...\n  ..$ label      : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting 16\" ...\n  ..$ id         : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting_16\" ...\n  ..$ date       : chr [1:164] NA NA NA \"Meeting 16\" ...\n  ..$ short_topic: chr [1:164] NA NA NA NA ...\n  ..$ long_topic : chr [1:164] NA NA NA NA ...\n  ..$ lat        : num [1:164] NA NA NA NA NA ...\n  ..$ lon        : num [1:164] NA NA NA NA NA ...\n  ..$ zone       : chr [1:164] NA NA NA NA ...\n  ..$ zone_detail: chr [1:164] NA NA NA NA ...\n  ..$ name       : chr [1:164] NA NA NA NA ...\n  ..$ role       : chr [1:164] NA NA NA NA ...\n  ..$ start      : chr [1:164] NA NA NA NA ...\n  ..$ end        : chr [1:164] NA NA NA NA ...\n $ links     :'data.frame': 378 obs. of  9 variables:\n  ..$ role     : chr [1:378] \"plan\" \"participant\" \"plan\" \"participant\" ...\n  ..$ source   : chr [1:378] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"low_volume_crane_Meeting_8_Report\" ...\n  ..$ target   : chr [1:378] \"marine_life_deck\" \"Teddy Goldstein\" \"low_volume_crane\" \"Seal\" ...\n  ..$ key      : int [1:378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:378] NA -0.5 NA 0.1 NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:378] NA \"Prefers resources to be allocated toward the fishing industry.\" NA \"Recognizes the crane's benefit to small-scale operations.\" ...\n  ..$ industry :List of 378\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. .. [list output truncated]\n  ..$ status   : chr [1:378] NA NA NA NA ...\n  ..$ time     : chr [1:378] NA NA NA NA ...\n\n\n\n\n\n\n\ntrout_nodes &lt;- as_tibble(trout$nodes)\ntrout_edges &lt;- as_tibble(trout$links)\n\n\n\n\nExpCatViz(data=trout_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\nExpCatViz(data=trout_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nExpNumViz(trout_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\nExpNumViz(trout_edges)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrout_graph &lt;- process_graph_data(trout_nodes, trout_edges)\n\n\n\n\nset.seed(1234)\n\n\nggraph(trout_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: ggrepel: 47 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#objective",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#objective",
    "title": "TestMC2",
    "section": "",
    "text": "This take-home exercise will be covering VAST Challenge 2025 Mini-Challenge 2."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#background",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#background",
    "title": "TestMC2",
    "section": "",
    "text": "Oceanus has enjoyed a relatively simple, fishing-based economy for decades. However, in recent times tourism has greatly expanded and resulted in significant changes. The local government set up an oversight board - Commission on Overseeing the Economic Future of Oceanus (COOTEFOO) - to monitor the current economy and advise how to prepare for the future. It is an appointed board that has no direct power on rules/spending BUT has a lot of clout in the civil service and gets government money to do its job…ostensibly in an unbiased way.\nRecently COOTEFOO was hit by a sequence of scandals that roughly break down into two camps:\n\nFishing is Living and Heritage (FILAH) accuses the board of being biased toward the new tourism economy and inappropriately attending to the potential in those ventures, ignoring the historical powerhouse of the economy: Getting lots of fish out of the water and off to hungry people. They accuse some COOTEFOO members of bias against fishing.\nTourism Raises OceanUs Together (TROUT) accuses the board of being biased toward an entrenched interest and constantly “appeasing” the fishing industry, ignoring the new/growing avenues for economic stability. They accuse some members of ignoring the brave-new-world and living in the past.\n\nA journalist, Edwina Darling Moray (E.D. to her friends), at the Haacklee Herald is working on a story about government accountability. She has acquired the datasets that TROUT and FILIAH are working from, which includes meeting minutes and travel records of COOTEFOO members. She also has acquired additional records that TROUT and FILAH did not. Moray has employed a staff programmer to massage the data into a consistent format for analysis – a knowledge graph. You are picking up the work from that programmer to design visualizations to support Moray’s understanding of what is going on. Moray is not a knowledge graph expert, but she understands the workings of Oceanus well. She wants you to design a visual interface to explore the accusations in context and discern which are founded and which are spurious."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#task-and-questions",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#task-and-questions",
    "title": "TestMC2",
    "section": "",
    "text": "Based on the datasets that TROUT & FILAH have provided, use visual analytics to determine if each group’s accusations are supported by their own record set. In other words, develop a visualization to highlight bias (if present) in TROUT & FILAHS datasets. Is there evidence of bias in the COOTEFOO member actions in either dataset?\nAs a journalist, Ms. Moray would like a more complete picture of the COOTEFOO’s actions and activities. She has arranged to combine the data provided by TROUT and FILAH into a single knowledge graph along with additional records. Design visual analytics approaches for this combined knowledge graph to see how members of COOTEFOO spend their time. Is the committee as a whole biased? Provide visual evidence for your conclusions.\nThe TROUT and FILAH datasets are incomplete. Use your visualizations to compare and contrast conclusions drawn from the TROUT and FILAH datasets separately with behaviors in the whole dataset. Are the accusations of TROUT strengthened, weakened or unchanged when taken in context of the whole dataset?\nDesign a visualization that allows Ms. Moray to pick a person and highlight the differences in that person’s behavior as illustrated through the different datasets. Focus on the contrast in the story each dataset tells.\n\nPick at least one COOTEFOO member accused by TROUT. Illustrate how your understanding of their activities changed when using the more complete dataset.\nWhat are the key pieces of evidence missing from the original TROUT data that most influenced the change in judgement.\nWhose behaviors are most impacted by sampling bias when looking at the FILAH dataset in context of the other data?\nIllustrate the bias of the FILAH data in the context of the whole dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#getting-started",
    "title": "TestMC2",
    "section": "",
    "text": "For the purpose of this exercise, five R packages will be used. They are tidyverse, jsonlite, tidygraph, ggraph and SmartEDA.\n\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environemnt.\n\npacman::p_load(tidyverse, jsonlite,\n               tidygraph, ggraph,\n               SmartEDA)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#importing-knowledge-graph-data",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#importing-knowledge-graph-data",
    "title": "TestMC2",
    "section": "",
    "text": "For the purpose of this exercise, FILAH.json file will be used.\nIn the code chunk below, fromJSON() of jsonlite package is used to import FILAH.json file into R and save the output object\n\nfilah &lt;- fromJSON(\"MC2/data/FILAH.json\")\ntrout &lt;- fromJSON(\"MC2/data/TROUT.json\")\njournalist &lt;- fromJSON(\"MC2/data/journalist.json\")\nroad_map &lt;- fromJSON(\"MC2/data/road_map.json\")\n\n\n\nBefore preparing the data, it is always a good practice to examine the structure of filah knowledge graph.\nIn the code chunk below glimpse() is used to reveal the structure of filah knowledge graph.\n\nglimpse(filah)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 396 obs. of  17 variables:\n  ..$ type       : chr [1:396] \"meeting\" \"meeting\" \"meeting\" \"meeting\" ...\n  ..$ date       : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ label      : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ id         : chr [1:396] \"Meeting_1\" \"Meeting_2\" \"Meeting_3\" \"Meeting_4\" ...\n  ..$ name       : chr [1:396] NA NA NA NA ...\n  ..$ role       : chr [1:396] NA NA NA NA ...\n  ..$ short_topic: chr [1:396] NA NA NA NA ...\n  ..$ long_topic : chr [1:396] NA NA NA NA ...\n  ..$ short_title: chr [1:396] NA NA NA NA ...\n  ..$ long_title : chr [1:396] NA NA NA NA ...\n  ..$ plan_type  : chr [1:396] NA NA NA NA ...\n  ..$ lat        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ lon        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ zone       : chr [1:396] NA NA NA NA ...\n  ..$ zone_detail: chr [1:396] NA NA NA NA ...\n  ..$ start      : chr [1:396] NA NA NA NA ...\n  ..$ end        : chr [1:396] NA NA NA NA ...\n $ links     :'data.frame': 765 obs. of  9 variables:\n  ..$ role     : chr [1:765] \"part_of\" \"part_of\" \"part_of\" \"part_of\" ...\n  ..$ source   : chr [1:765] \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" ...\n  ..$ target   : chr [1:765] \"fish_vacuum_Meeting_1_Introduction_Discussion\" \"fish_vacuum_Meeting_1_Introduction\" \"seafood_festival_Meeting_1_Discussion\" \"seafood_festival_Meeting_1_Feasibility\" ...\n  ..$ key      : int [1:765] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:765] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:765] NA NA NA NA ...\n  ..$ industry :List of 765\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. .. [list output truncated]\n  ..$ status   : chr [1:765] NA NA NA NA ...\n  ..$ time     : chr [1:765] NA NA NA NA ...\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that Industry field is in list data type. In general, this data type is not acceptable by tbl_graph() of tidygraph. In order to avoid error arise when building tidygraph object, it is wiser to exclude this field from the edges data table. However, it might be still useful in subsequent analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#extracting-the-edges-and-nodes-tables",
    "title": "TestMC2",
    "section": "",
    "text": "Next, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from filah tibble dataframe into two separate tibble dataframes called filah_nodes and filah_edges respectively.\n\nfilah_nodes &lt;- as_tibble(filah$nodes)\nfilah_edges &lt;- as_tibble(filah$links)\n\n\n\nIn the code chunk below, ExpCatViz() of SmartEDA package is used to reveal the frequency distribution of all categorical fields in filah_nodes tibble dataframe.\n\nExpCatViz(data=filah_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\nOn the other hands, code chunk below uses ExpCATViz() of SmartEDA package to reveal the frequency distribution of all categorical fields in filah_edges tibble dataframe.\n\nExpCatViz(data=filah_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nExpNumViz(filah_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\nExpNumViz(filah_edges)\n\n[[1]]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#data-cleaning-and-wrangling",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#data-cleaning-and-wrangling",
    "title": "TestMC2",
    "section": "",
    "text": "filah_nodes_cleaned &lt;- filah_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(id, type, label)   \n\n\n\n\n\nfilah_edges_cleaned &lt;- filah_edges %&gt;%\n  rename(from = source, to = target) %&gt;%\n  mutate(across(c(from, to), as.character)) %&gt;%\n  filter(from %in% filah_nodes_cleaned$id, to %in% filah_nodes_cleaned$id)\n\n# Remove problematic columns from edge table for graph building\nfilah_edges_min &lt;- filah_edges_cleaned %&gt;%\n  select(from, to, role)  # Only basic fields needed for graph structure\n\n\n\n\n\nfilah_graph &lt;- tbl_graph(\n  nodes = filah_nodes_cleaned, \n  edges = filah_edges_min, \n  directed = TRUE)\n\n\n\n\n\n\n\nNote\n\n\n\nSince the similar steps will be used to clean and wrangle TROUT.json and journalist.json, you might want to consider converting the above code chunks into R function(s).\n\n\n\n\n\n\n\n\nclean_nodes &lt;- function(nodes_df) {\n  nodes_df %&gt;%\n    mutate(id = as.character(id)) %&gt;%\n    filter(!is.na(id)) %&gt;%\n    distinct(id, .keep_all = TRUE) %&gt;%\n    select(id, type, label)\n}\n\n\n\n\n\nclean_edges &lt;- function(edges_df, cleaned_nodes_df) {\n  edges_df %&gt;%\n    rename(from = source, to = target) %&gt;%\n    mutate(across(c(from, to), as.character)) %&gt;%\n    filter(from %in% cleaned_nodes_df$id, to %in% cleaned_nodes_df$id)\n}\n\n\n\n\n\nminimize_edges &lt;- function(cleaned_edges_df) {\n  cleaned_edges_df %&gt;%\n    select(from, to, role)\n}\n\n\n\n\n\nbuild_graph &lt;- function(nodes_df, edges_df) {\n  tbl_graph(\n    nodes = nodes_df,\n    edges = edges_df,\n    directed = TRUE\n  )\n}\n\n\n\n\n\nprocess_graph_data &lt;- function(nodes_df, edges_df) {\n  nodes_cleaned &lt;- clean_nodes(nodes_df)\n  edges_cleaned &lt;- clean_edges(edges_df, nodes_cleaned)\n  edges_min &lt;- minimize_edges(edges_cleaned)\n  build_graph(nodes_cleaned, edges_min)\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#visualising-the-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#visualising-the-knowledge-graph",
    "title": "TestMC2",
    "section": "",
    "text": "In this section, we will use ggraph’s functions to visualise and analyse the graph object.\n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)\n\nIn the code chunk below, ggraph functions are used to create the whole graph.\n\nggraph(filah_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: ggrepel: 245 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#importing-knowledge-graph---trout",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#importing-knowledge-graph---trout",
    "title": "TestMC2",
    "section": "",
    "text": "glimpse(trout)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 164 obs. of  17 variables:\n  ..$ type       : chr [1:164] \"plan\" \"plan\" \"plan\" \"meeting\" ...\n  ..$ short_title: chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" NA ...\n  ..$ long_title : chr [1:164] \"Present findings from the environmental impact study\" \"Report on travel and submit letter of support for low-volume unload crane\" \"Discuss maintenance plan and designate travel representatives\" NA ...\n  ..$ plan_type  : chr [1:164] \"Report\" \"report\" \"proposal\" NA ...\n  ..$ label      : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting 16\" ...\n  ..$ id         : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting_16\" ...\n  ..$ date       : chr [1:164] NA NA NA \"Meeting 16\" ...\n  ..$ short_topic: chr [1:164] NA NA NA NA ...\n  ..$ long_topic : chr [1:164] NA NA NA NA ...\n  ..$ lat        : num [1:164] NA NA NA NA NA ...\n  ..$ lon        : num [1:164] NA NA NA NA NA ...\n  ..$ zone       : chr [1:164] NA NA NA NA ...\n  ..$ zone_detail: chr [1:164] NA NA NA NA ...\n  ..$ name       : chr [1:164] NA NA NA NA ...\n  ..$ role       : chr [1:164] NA NA NA NA ...\n  ..$ start      : chr [1:164] NA NA NA NA ...\n  ..$ end        : chr [1:164] NA NA NA NA ...\n $ links     :'data.frame': 378 obs. of  9 variables:\n  ..$ role     : chr [1:378] \"plan\" \"participant\" \"plan\" \"participant\" ...\n  ..$ source   : chr [1:378] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"low_volume_crane_Meeting_8_Report\" ...\n  ..$ target   : chr [1:378] \"marine_life_deck\" \"Teddy Goldstein\" \"low_volume_crane\" \"Seal\" ...\n  ..$ key      : int [1:378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:378] NA -0.5 NA 0.1 NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:378] NA \"Prefers resources to be allocated toward the fishing industry.\" NA \"Recognizes the crane's benefit to small-scale operations.\" ...\n  ..$ industry :List of 378\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. .. [list output truncated]\n  ..$ status   : chr [1:378] NA NA NA NA ...\n  ..$ time     : chr [1:378] NA NA NA NA ..."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#extracting-the-edges-and-nodes-tables-1",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#extracting-the-edges-and-nodes-tables-1",
    "title": "TestMC2",
    "section": "",
    "text": "trout_nodes &lt;- as_tibble(trout$nodes)\ntrout_edges &lt;- as_tibble(trout$links)\n\n\n\n\nExpCatViz(data=trout_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\nExpCatViz(data=trout_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nExpNumViz(trout_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\nExpNumViz(trout_edges)\n\n[[1]]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC2.html#data-cleaning-and-wrangling-1",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC2.html#data-cleaning-and-wrangling-1",
    "title": "TestMC2",
    "section": "",
    "text": "trout_graph &lt;- process_graph_data(trout_nodes, trout_edges)\n\n\n\n\nset.seed(1234)\n\n\nggraph(trout_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: ggrepel: 47 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02MC3.html",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02MC3.html",
    "title": "Take-Home Exercise 2 Minicase 3",
    "section": "",
    "text": "pacman::p_load(tidyverse, jsonlite,\n               tidygraph, ggraph,\n               SmartEDA)\n\n\nMC3 &lt;- fromJSON(\"MC3/data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"MC3/data/MC3_schema.json\")\n\n\nglimpse(MC3)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n\n\n\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\n\nExpCatViz(data=mc3_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source, \n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), \n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id, \n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to)) \n\n\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\nmc3_graph &lt;- tbl_graph(\n  nodes = mc3_nodes_final,\n  edges = mc3_edges_final,\n  directed = TRUE\n)\n\n\nstr(mc3_graph)\n\nClasses 'tbl_graph', 'igraph'  hidden list of 10\n $ : num 1159\n $ : logi TRUE\n $ : num [1:3226] 0 0 0 0 0 0 0 1 1 1 ...\n $ : num [1:3226] 1137 356 746 894 875 ...\n $ : NULL\n $ : NULL\n $ : NULL\n $ : NULL\n $ :List of 4\n  ..$ : num [1:3] 1 0 1\n  ..$ : Named list()\n  ..$ :List of 31\n  .. ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  .. ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  .. ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  .. ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ findings         : chr [1:1159] NA NA NA NA ...\n  .. ..$ content          : chr [1:1159] NA NA NA NA ...\n  .. ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ results          : chr [1:1159] NA NA NA NA ...\n  .. ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ destination      : chr [1:1159] NA NA NA NA ...\n  .. ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  .. ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  .. ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  .. ..$ reference        : chr [1:1159] NA NA NA NA ...\n  .. ..$ date             : chr [1:1159] NA NA NA NA ...\n  .. ..$ time             : chr [1:1159] NA NA NA NA ...\n  .. ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  .. ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  .. ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  .. ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  .. ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  .. ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ operational_role : chr [1:1159] NA NA NA NA ...\n  .. ..$ new_index        : int [1:1159] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ :List of 2\n  .. ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  .. ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n $ :&lt;environment: 0x00000225f9bb23f8&gt; \n - attr(*, \"active\")= chr \"nodes\"\n\n\n\nset.seed(1234)\n\n\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "",
    "text": "This exercise aims to enhance a visualisation originally created by a fellow course-mate as a graphic editor of a media company that publishes daily content on digital platforms. The critique will be made with reference to the following principles extracted from Ben Jones’ article (“Data Visualization: Clarity or Aesthetics?”)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#objective",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#objective",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "",
    "text": "This exercise aims to enhance a visualisation originally created by a fellow course-mate as a graphic editor of a media company that publishes daily content on digital platforms. The critique will be made with reference to the following principles extracted from Ben Jones’ article (“Data Visualization: Clarity or Aesthetics?”)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#load-packages",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "2.1 Load packages",
    "text": "2.1 Load packages\nThe following R packages will be loaded using the pacman::p_load() function.\n\npacman::p_load(ggrepel, patchwork, \n               tidyverse, scales,\n               ggridges)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#import-data",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "2.2 Import data",
    "text": "2.2 Import data\nThis exercise will be using the same dataset as Phase 1 of Take-Home Exercise 1. Thus, proceed to import data with the following code.\n\ndata &lt;- read_csv(\"data/respopagesex2024.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#data-preprocessing",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#data-preprocessing",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "2.3 Data preprocessing",
    "text": "2.3 Data preprocessing\nSince the goal of this exercise is to provide critiques on the original visualisation, the data pre-processing will follow the process of the original visualisation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#original-work",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#original-work",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "3.1 Original Work",
    "text": "3.1 Original Work\nThe chosen submission had the following visualisation for Top 10 Planning Areas by Total Population.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntop_pa &lt;- data %&gt;%\n  group_by(PA) %&gt;%\n  summarise(Total_Pop = sum(Pop)) %&gt;%\n  arrange(desc(Total_Pop)) %&gt;%\n  slice_head(n = 10)\n\nggplot(top_pa, aes(x = reorder(PA, Total_Pop), y = Total_Pop)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Top 10 Most Populous Planning Areas (2024)\",\n       x = \"Planning Area\", y = \"Total Population\") +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#critique",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#critique",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "3.2 Critique",
    "text": "3.2 Critique\nClarity\nWhy it is clear:\n\nClear and purposeful layout: Bar chart is a good choice for communicating ranked categorical data. It is simple, direct and allows readers to immediately grasp the key message of the data visualisation.\nLogical ordering: The planning areas are arranged in descending order based on population size. This allows readers to quickly identify which areas are the most densely populated at the first glance and easily understand relative magnitude.\n\nWhy it can be confusing:\n\nScientific notation undermines readability: Displaying population values in scientific notations will require readers to engage in additional cognitive effort and may be difficult for non-technical readers. This introduces friction into the reading experience. On fast-scrolling digital platforms, accessible by general public of all ages and abilities, reducing interpretation barriers is critical.\nTitle and labels lack specificity: The title does not specify the scope of population (whether non-residents are included). Similarly, the x-axis label “Total Population” which is vague in a demographic context where definitions matter. To enhance the clarity, “Total Population” can be defined as “Resident Population” and source can be added to the data visualisation for readers to have further reference on the definition of “Resident Population” and the year of reference.\n\nAesthetic\nWhy it is beautiful:\n\nSimple and clean theme with faint gridlines: There are no unnecessary details, thus successfully avoiding distractions that do not contribute to understanding.\nOrientation of bar chart: Horizontal orientation is able to accommodate long planning area names without truncation or overlapping, which enhances readability.\n\nWhy it can be ugly:\n\nDull visualisation: While using a single blue shade avoids unnecessary noise, it fails to enhance visual interest or guide the reader’s attention. As Ben Jones mentioned, aesthetics and clarity can come hand-in-hand where aesthetics can aid clarity when used meaningfully. Applying a colour gradient, dark to light based on population size, or selectively highlighting the most populous area, would create visual contrast that draws attention and support the ranking narrative, without adding clutter."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#remake",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01P2.html#remake",
    "title": "Take-home Exercise 1 Phase 2",
    "section": "3.3 Remake",
    "text": "3.3 Remake\nBased on the critique in section 3.2, a revised version of the original visualisation has been created. It retains the strengths of the original visualisation while refining the areas identified for improvement.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Summarise top 10 planning areas by resident population\ntop_pa &lt;- data %&gt;%\n  group_by(PA) %&gt;%\n  summarise(Total_Pop = sum(Pop)) %&gt;%\n  arrange(desc(Total_Pop)) %&gt;%\n  slice_head(n = 10)\n\n# Prepare data for plotting\ntop_pa &lt;- top_pa %&gt;%\n  arrange(desc(Total_Pop)) %&gt;%\n  mutate(PA = factor(PA, levels = rev(PA)),\n         Fill = Total_Pop)\n\n# Create the plot\nggplot(top_pa, aes(x = PA, y = Total_Pop, fill = Fill)) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_gradient(low = \"#bdd7e7\", high = \"#08519c\", guide = \"none\") +\n  scale_y_continuous(labels = comma) +\n  labs(\n    title = \"Top 10 Planning Areas by Resident Population\",\n    x = \"Planning Area\",\n    y = \"Number of Residents\",\n    caption = \"Source: Department of Statistics Singapore (2024)\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title.x = element_text(margin = margin(t = 10)),\n    axis.title.y = element_text(margin = margin(r = 10)),\n    plot.caption = element_text(hjust = 1, size = 8, color = \"gray30\")\n  )"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 — Visual Analytics and Applications",
    "section": "",
    "text": "Welcome to my website for ISSS608: Visual Analytics and Applications. Here, you’ll find a collection of my learnings and coursework from the course, reflecting the skills and knowledge I’ve gained throughout this journey.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nMay 28, 2025\n\n\nTake-home Exercise 2\n\n\n\n\nMay 20, 2025\n\n\nHands-on Exercise 6\n\n\n\n\nMay 17, 2025\n\n\nIn-class Exercise 5 Mini Challenge 1\n\n\n\n\nMay 13, 2025\n\n\nHands-on Exercise 5\n\n\n\n\nMay 6, 2025\n\n\nHands-on Exercise 4a\n\n\n\n\nMay 6, 2025\n\n\nHands-on Exercise 4b\n\n\n\n\nMay 6, 2025\n\n\nHands-on Exercise 4c\n\n\n\n\nMay 6, 2025\n\n\nHands-on Exercise 4d\n\n\n\n\nMay 6, 2025\n\n\nTake-home Exercise 1 Phase 2\n\n\n\n\nApr 30, 2025\n\n\nTake-home Exercise 1\n\n\n\n\nApr 29, 2025\n\n\nHands-on Exercise 3a\n\n\n\n\nApr 29, 2025\n\n\nHands-on Exercise 3b\n\n\n\n\nApr 22, 2025\n\n\nHands-on Exercise 2\n\n\n\n\nApr 18, 2025\n\n\nHands-on Exercise 1\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "This hands-on exercise will allow one to create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\nLoad the following packages for this exercise.\n\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nIn this section, a calendar heatmap will be created programmatically by using ggplot2 package.\n\nBy end of this section, one will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore plotting the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\n\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, these are the steps:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\nThis section will be going through how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis section will be covering how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Countries\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "This hands-on exercise will allow one to create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Load the following packages for this exercise.\n\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, a calendar heatmap will be created programmatically by using ggplot2 package.\n\nBy end of this section, one will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore plotting the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\n\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, these are the steps:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "This section will be going through how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "This section will be covering how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Countries\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. This hands-on exercise will be covering the following:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. This hands-on exercise will compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  x_range = c(0, 6500),  #&lt;&lt;\n  y_range = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ndata_type argument is used to change from default “SR” to “PR” (i.e. proportions).\nxrange and yrange are used to set the range of x-axis and y-axis\n\n\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\n\n\nThis section will provide hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhances working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, cumulative death rate and standard error of cumulative death rate needs to be derived.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly\n\n\n\n\n\n\n\n\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#overview",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. This hands-on exercise will be covering the following:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#importing-data",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "In this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. This hands-on exercise will compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "FunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  x_range = c(0, 6500),  #&lt;&lt;\n  y_range = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ndata_type argument is used to change from default “SR” to “PR” (i.e. proportions).\nxrange and yrange are used to set the range of x-axis and y-axis\n\n\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "This section will provide hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhances working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, cumulative death rate and standard error of cumulative death rate needs to be derived.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#references",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "funnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "This hands-on exercise will be covering the following:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n-   To provide alternative statistical inference methods by default. \n-   To follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nUsing the following code, import exam_data.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information:\n\nstatistical details\nBayes Factor\nsample sizes\ndistribution summary\n\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information:\n\nstatistical details\nBayes Factor\nsample sizes\ndistribution summary\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nCodePlot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "This hands-on exercise will be covering the following:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n-   To provide alternative statistical inference methods by default. \n-   To follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#importing-data",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "Using the following code, import exam_data.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information:\n\nstatistical details\nBayes Factor\nsample sizes\ndistribution summary\n\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information:\n\nstatistical details\nBayes Factor\nsample sizes\ndistribution summary\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nCodePlot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, one will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore starting on animated graphs, it will be important to ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts.\n\n\n\n\n\n\n\n\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nAs mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nThe basic ggplot2 functions are used to create a static bubble plot as shown below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\nAs shown in the following plot,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')          \n\n\n\n\n\n\n\n\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, one will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object. :::\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\nIn this sub-section, one will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp\n\n\n\n\n\n\n\n\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#overview",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, one will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore starting on animated graphs, it will be important to ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#getting-started",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "First, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nAs mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "gganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nThe basic ggplot2 functions are used to create a static bubble plot as shown below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\nAs shown in the following plot,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "In Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, one will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object. :::\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\nIn this sub-section, one will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#reference",
    "title": "Hands-on Exercise 3b",
    "section": "",
    "text": "Getting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "This chapter will introduce several ggplot2 extensions for creating a more elegant and effective statistical graphics. By the end of this exercise, one should be able to:\n\ncontrol the placement of annontation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in the ggthemes and hrbrthemes packages, and\nplot composite figure by combining ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\nBesides tidyverse, the following R packages will be used in this exercise.\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe code chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\nThe following code chunk loads the extrafont package and imports system fonts so that they can be used in plots, which is instrumental in packages such as hrbrthemes.\n\npacman::p_load(extrafont)\nfont_import()\n\nImporting fonts may take a few minutes, depending on the number of fonts and the speed of the system.\nContinue? [y/n] \n\nloadfonts(device = \"win\")\n\n\n\n\nThis exercise will be using a data file called Exam_data. It consists of year-end examination grades of a cohort of primary 3 students from a local school. It is in a csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\nOne of the challenges in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in the examples on below.  \nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "This chapter will introduce several ggplot2 extensions for creating a more elegant and effective statistical graphics. By the end of this exercise, one should be able to:\n\ncontrol the placement of annontation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in the ggthemes and hrbrthemes packages, and\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Besides tidyverse, the following R packages will be used in this exercise.\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe code chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\nThe following code chunk loads the extrafont package and imports system fonts so that they can be used in plots, which is instrumental in packages such as hrbrthemes.\n\npacman::p_load(extrafont)\nfont_import()\n\nImporting fonts may take a few minutes, depending on the number of fonts and the speed of the system.\nContinue? [y/n] \n\nloadfonts(device = \"win\")\n\n\n\n\nThis exercise will be using a data file called Exam_data. It consists of year-end examination grades of a cohort of primary 3 students from a local school. It is in a csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annontation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annontation-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "One of the challenges in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in the examples on below.  \nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "The plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2",
    "section": "2.5 Beyond Single Graph",
    "text": "2.5 Beyond Single Graph\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, one will learn how to create composite plot by combining multiple graphs. First, the three statistical graphics will be created by using the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\nNext\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\nLastly, a scatterplot for English score versus Maths score will be created as shown below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n2.5.1 Creating Composite Graphics: pathwork methods\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, a ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure will be further explored.\nPatchwork package has a very simple syntax where one can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n2.5.2 Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Notice the simplicity of the syntax.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\n2.5.3 Combining three ggplot2 graphs\nMore complex composite can be plotted using appropriate operators. For example, the composite figure below is plotted by using:\n\n/ operator to stack two ggplot2 graphs,\n| operator to place the plots beside each other,\n() operator the define the sequence of the plotting.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n2.5.4 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n2.5.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, one or several plots or graphic elements can be freely placed on top or below another plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n2.5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#additional-work-for-exploration",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#additional-work-for-exploration",
    "title": "Hands-on Exercise 2",
    "section": "2.6 Additional work for exploration",
    "text": "2.6 Additional work for exploration\nThis section is reserved for further exploration."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 2",
    "section": "2.7 Reference",
    "text": "2.7 Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello! I’m Yi Fang, a postgraduate student with a passion for uncovering insights through analytics.\nThis site is my space to explore and refine my skills in visual analytics, while sharing my learning journey along the way. I’m also currently learning RStudio to broaden my analytical toolkit and deepen my understanding of data storytelling. I’m excited to grow, experiment, and hopefully connect with others who are just as excited about the power of analytics!\n\n\n\n Back to top"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcomes",
    "title": "Hands-on Exercise 1",
    "section": "1.1 Learning outcomes",
    "text": "1.1 Learning outcomes\nKey objectives of the following sections:\n\nlearn basic principles and essential components of ggplot2,\ngain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics, and\napply essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started-1",
    "title": "Hands-on Exercise 1",
    "section": "1.2 Getting started",
    "text": "1.2 Getting started\nBefore we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk on the below assumes that you already have pacman package installed. If not, please go ahead install pacman first."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "1.3 Introducing ggplot",
    "text": "1.3 Introducing ggplot\nggplot2 is a R package for declaratively creating data-driven graphics based on The Grammar of Graphics. It is also part of the tidyverse family specially designed for visual exploration and communication. For more detail, visit ggplot2 link.\n\n1.3.1 R Graphics VS ggplot\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR Graphicsggplots2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nggplot2 encourages deeper thinking about visualisation by connecting variables to visual elements."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\nBefore we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n1.4.1 A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1",
    "section": "1.5 Essential Grammatical Elements in ggplot2: data",
    "text": "1.5 Essential Grammatical Elements in ggplot2: data\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1",
    "section": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call.\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nggplot includes the x-axis and the axis’s label."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 1",
    "section": "1.7 Essential Grammatical Elements in ggplot2: geom",
    "text": "1.7 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nA plot must have at least one geom; there is no upper limit. geom can be added to a plot using the + operator. For complete list of geometric objects, please refer to here.\n\n1.7.1 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n1.7.2 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\nThe following code chunk performs the following steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n1.7.3 Geometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\n1.7.4 Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n1.7.5 Modifying a geometric object by changing aes()\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic(). This approach can be used to colour, fill and alpha of the geometric.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n1.7.6 Geometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram. It is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using color or fill arguments of aes().\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n1.7.7 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n1.7.8 Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n1.7.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n1.7.10 geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "1.8 Essential Grammatical Elements in ggplot2: stat",
    "text": "1.8 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n1.8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n1.8.3 Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n1.8.4 Adding a best fit curve on a scatterplot\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\n\n\n\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default method used is loess.\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "1.9 Essential Grammatical Elements in ggplot2: Facets",
    "text": "1.9 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n1.9.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n1.9.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "1.10 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "1.10 Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n- [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out). - [`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped. - [`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot). - [`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n1.10.1 Working with Coordinates\nBy default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe following code chunk flips the horizontal bar chart into a vertical bar chart by adding coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n1.10.2 Changing the y- and x-axis range\nNotice that the y- and x-axis range are not the same.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, linewidth=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below standardised both y- and x-axis to the range of 0 to 100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "1.11 Essential Grammatical Elements in ggplot2: themes",
    "text": "1.11 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n1.11.1 Working with themes\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 1",
    "section": "1.12 Reference",
    "text": "1.12 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "In this hands-on exercise, one will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages.\n\n\n\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\n\n\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\nCode chunk in the second tab below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\nCode chunk in the second tab shows the second interactive feature of ggiraph, namely data_id.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. Note: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.\n\n\n\n\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nKey learning points here:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,\n\n\n\n\n\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!.\n\n\n\n\n\n\n\n\n\n\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "In this hands-on exercise, one will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "First, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "In this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "ggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\nCode chunk in the second tab below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\nCode chunk in the second tab shows the second interactive feature of ggiraph, namely data_id.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. Note: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "Plotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nKey learning points here:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "Crosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "title": "Hands-on Exercise 3a",
    "section": "",
    "text": "This link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. Some of the popular statistical graphics methods for visualising distribution were covered in Hands-on Exercise 1. These includes histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, two relatively new statistical graphic methods for visualising distribution will be covered, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. This section will cover how to plot ridgeline plot using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nTo fill the area under the ridgeline with varying colors instead of a single solid color, one can use either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nThe ridgeline plot can be colored based on quantile by using geom_density_ridges_gradient(). This is calculated using stat(quantile) aesthetic as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quantiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, one will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\nNext, add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, dd the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. Select side = “left” to place it on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\n\n\n\n\nReference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. Some of the popular statistical graphics methods for visualising distribution were covered in Hands-on Exercise 1. These includes histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, two relatively new statistical graphic methods for visualising distribution will be covered, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Ridgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. This section will cover how to plot ridgeline plot using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nTo fill the area under the ridgeline with varying colors instead of a single solid color, one can use either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nThe ridgeline plot can be colored based on quantile by using geom_density_ridges_gradient(). This is calculated using stat(quantile) aesthetic as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quantiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-using-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-using-raincloud-plot",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Raincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, one will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\nNext, add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, dd the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. Select side = “left” to place it on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#references",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Reference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. To create statistical graphics for visualising uncertainty, the following will be covered in this hands-on exercise.\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\nstringr for automatically wrapping text\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse, stringr)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\nThis section will go through how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nTableCode\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\nStandard error bars of means maths score by race will be plotted as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, the confidence intervals of mean maths score by race can also be plotted.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nThis section will cover how to plot interactive error bars for the 99% confidence interval of mean math score by race as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(6,6),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average &lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, it is best to read the syntax reference for more details.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nTo show 99% and 95% confidence, refer to the following code.\n\nPlot for 99% CIPlot for 95% CICodes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# For 99% CI\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.99,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n# For 95% CI\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, it is advisable to read the syntax reference for more details.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, it is advisable to read the syntax reference for more details.\n\n\n\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\nNext, the code chunk below will be used to build the HOPs.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. To create statistical graphics for visualising uncertainty, the following will be covered in this hands-on exercise.\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\nstringr for automatically wrapping text\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse, stringr)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "A point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\nThis section will go through how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nTableCode\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\nStandard error bars of means maths score by race will be plotted as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, the confidence intervals of mean maths score by race can also be plotted.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nThis section will cover how to plot interactive error bars for the 99% confidence interval of mean math score by race as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(6,6),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average &lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "ggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, it is best to read the syntax reference for more details.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nTo show 99% and 95% confidence, refer to the following code.\n\nPlot for 99% CIPlot for 95% CICodes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# For 99% CI\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.99,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n# For 95% CI\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, it is advisable to read the syntax reference for more details.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, it is advisable to read the syntax reference for more details."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcomes-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcomes-plots-hops",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\nNext, the code chunk below will be used to build the HOPs.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "This hands-on exercise will be going through how to model, analyse and visualise network data using R, this includes the following.\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\n\n\n\n\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)\n\n\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 54 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 54 employees.\n\n\n\n\n\nIn this step, import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nShow the code\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nNext, examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, proceed to aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\n\n\n\nIn this section, one will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, it is advisable to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, it is recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\nShow the code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 1372 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before getting started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\nIn this section, theme_graph() will be used to remove the x and y axes. Before getting started, it is advisable to read it’s reference guide at least once.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nlayout argument is used to define the layout to be used.\n\n\n\n\n\nIn this section, each node will be coloured by referring to their respective departments.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is best to read its reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\n\nShow the code\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable to read its reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nNodes can be moved and the graph will use an algorithm to keep the nodes properly spaced.\nIt can also be zoom in and out on the plot and moved around to re-center.\n\n\n\n\nBefore plotting the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "This hands-on exercise will be going through how to model, analyse and visualise network data using R, this includes the following.\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 54 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 54 employees.\n\n\n\n\n\nIn this step, import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nShow the code\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nNext, examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, proceed to aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this section, one will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, it is advisable to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, it is recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\nShow the code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 1372 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "ggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before getting started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\nIn this section, theme_graph() will be used to remove the x and y axes. Before getting started, it is advisable to read it’s reference guide at least once.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nlayout argument is used to define the layout to be used.\n\n\n\n\n\nIn this section, each node will be coloured by referring to their respective departments.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nShow the code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Another very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is best to read its reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\n\nShow the code\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable to read its reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Centrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "visNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nNodes can be moved and the graph will use an algorithm to keep the nodes properly spaced.\nIt can also be zoom in and out on the plot and moved around to re-center.\n\n\n\n\nBefore plotting the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\npacman::p_load(jsonlite, tidyverse, SmartEDA, tidygraph, ggraph)\n\n\n\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object.\n\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\nstr(kg, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tbl &lt;- as_tibble(kg$links)\n\n\n\n\n\n\nggplot(data = edges_tbl,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid_map &lt;- tibble(id = nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)))\n\nThis ensures each id from node list is mapped to the correct number.\n\n\n\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\nThe number of observations in edges_tbl should be the same as before running this code chunk.\nBefore doing leftjoin, there are only 4 variables. AFter doing the leftjoin, there is two additional variables.\n\n\n\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from),!is.na(to))\n\nThis will get rid of any missing values.\n\n\n\nLastly, tbl_graph() is used to create tidygraph’s graph object by using the code chunk below.\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl,\n                   edges = edges_tbl,\n                   directed = kg$directed)\n\nDirected will be plugged from kg table’s directed column.\n\n\n\n\n\nset.seed(1234)\n\nThis is to ensure reproducibility. ### Visualising the Whole Graph\n\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3,               # line, alpha is transparency \n                 colour = \"gray\") + \n  geom_node_point(aes(color = `Node Type`), # point (plot after line so that it doesn't get covered by line)\n                  size = 4) +               # size of point  \n  geom_node_text(aes(label = name),         # label using name\n                 repel = TRUE,              # prevent overlapping names, force words apart\n                 size = 2.5) +\n  theme_void()\n\n\n\nIn this section, we are interested to create a sub-graph base on MemberOf vaue in Edge Type column of the edges data frame.\n\n\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%                     # Focus on edges table\n  filter(`Edge Type` == \"MemberOf\")       # Filter to Memberof\n\n\n\n\n\nused_nodes_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from,to) %&gt;%            # Only selected variables\n  unlist() %&gt;%                  # beCause it is a graph model, not a list\n  unique()\n\nThis is to eliminate orphan nodes.\n\n\n\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;% \n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_nodes_indices) %&gt;%\n  select(-row_id)  # optional clean up\n\n\n\n\n\nggraph(graph_memberof,\n       layout = \"fr\") + \n  geom_edge_link(alpha = 0.5,\n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`),\n                  size = 1) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#importing-knowledge-graph-data",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#importing-knowledge-graph-data",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "In the code chunk below, fromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object.\n\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\nstr(kg, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tbl &lt;- as_tibble(kg$links)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#initial-eda",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#initial-eda",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "ggplot(data = edges_tbl,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#creating-knowledge-graph",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#creating-knowledge-graph",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "id_map &lt;- tibble(id = nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)))\n\nThis ensures each id from node list is mapped to the correct number.\n\n\n\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\nThe number of observations in edges_tbl should be the same as before running this code chunk.\nBefore doing leftjoin, there are only 4 variables. AFter doing the leftjoin, there is two additional variables.\n\n\n\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from),!is.na(to))\n\nThis will get rid of any missing values.\n\n\n\nLastly, tbl_graph() is used to create tidygraph’s graph object by using the code chunk below.\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl,\n                   edges = edges_tbl,\n                   directed = kg$directed)\n\nDirected will be plugged from kg table’s directed column."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#visualising-the-knowledge-graph",
    "href": "In-class_Ex/In-class_Ex05/MC1/In-class_Ex05_MC1.html#visualising-the-knowledge-graph",
    "title": "In-class Exercise 5 Mini Challenge 1",
    "section": "",
    "text": "set.seed(1234)\n\nThis is to ensure reproducibility. ### Visualising the Whole Graph\n\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3,               # line, alpha is transparency \n                 colour = \"gray\") + \n  geom_node_point(aes(color = `Node Type`), # point (plot after line so that it doesn't get covered by line)\n                  size = 4) +               # size of point  \n  geom_node_text(aes(label = name),         # label using name\n                 repel = TRUE,              # prevent overlapping names, force words apart\n                 size = 2.5) +\n  theme_void()\n\n\n\nIn this section, we are interested to create a sub-graph base on MemberOf vaue in Edge Type column of the edges data frame.\n\n\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%                     # Focus on edges table\n  filter(`Edge Type` == \"MemberOf\")       # Filter to Memberof\n\n\n\n\n\nused_nodes_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from,to) %&gt;%            # Only selected variables\n  unlist() %&gt;%                  # beCause it is a graph model, not a list\n  unique()\n\nThis is to eliminate orphan nodes.\n\n\n\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;% \n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_nodes_indices) %&gt;%\n  select(-row_id)  # optional clean up\n\n\n\n\n\nggraph(graph_memberof,\n       layout = \"fr\") + \n  geom_edge_link(alpha = 0.5,\n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`),\n                  size = 1) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "With reference to Singstat, Singapore’s resident population, consisting of citizens and permanent residents, stands at 4.18 million in 2024, with close to 20% of residents aged 65 and above. The population is distributed across 55 planning areas and 332 subzones.\n\n\n\nThis exercise will assume the role of a graphical editor of a media company planning to release an article on demographic structures and distribution of Singapore in 2024. The focus will be on presenting key demographics insights through visualisations.\nThe data will be processed by using appropriate tidyverse family of packages and the data visualisation will be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#overview",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#overview",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "With reference to Singstat, Singapore’s resident population, consisting of citizens and permanent residents, stands at 4.18 million in 2024, with close to 20% of residents aged 65 and above. The population is distributed across 55 planning areas and 332 subzones.\n\n\n\nThis exercise will assume the role of a graphical editor of a media company planning to release an article on demographic structures and distribution of Singapore in 2024. The focus will be on presenting key demographics insights through visualisations.\nThe data will be processed by using appropriate tidyverse family of packages and the data visualisation will be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#getting-started",
    "title": "Take-home Exercise 1",
    "section": "2 Getting started",
    "text": "2 Getting started\n\n2.1 Load packages\nThe following R packages will be loaded using the pacman::p_load() function.\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\npatchwork: an R package for preparing composite figure created using ggplot2.\nscales: an R package used for scaling and formatting data in visualisation.\nggridges: an R package for creating the density ridge plot.\n\n\npacman::p_load(ggrepel, patchwork, \n               tidyverse, scales,\n               ggridges) \n\n\n\n2.2 Import data\nThis exercise will be using Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore (DOS) \nProceed to load the dataset with the following code.\n\nrespop_data &lt;- read_csv(\"data/respopagesex2024.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1",
    "section": "3 Data Wrangling",
    "text": "3 Data Wrangling\nUsing glimpse() function, we get an overview of the dataset.\n\nglimpse(respop_data)\n\nRows: 60,424\nColumns: 6\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ Age  &lt;chr&gt; \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", …\n$ Sex  &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Females\", \"Male…\n$ Pop  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, 30, 10, 3…\n$ Time &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024,…\n\n\nThe dataset has 60,424 rows with 6 columns. This also shows the data type for each column.\n\n3.1 Check for duplicates\nA check for duplicates will be conducted with the duplicated function.\n\nrespop_data[duplicated(respop_data),]\n\n# A tibble: 0 × 6\n# ℹ 6 variables: PA &lt;chr&gt;, SZ &lt;chr&gt;, Age &lt;chr&gt;, Sex &lt;chr&gt;, Pop &lt;dbl&gt;,\n#   Time &lt;dbl&gt;\n\n\nAs indicated in the results, there are no duplicates.\n\n\n3.2 Check for missing values\nUsing the code below, proceed to check for missing values.\n\nfor(column_name in names(respop_data)) {\n  na_count &lt;- sum(is.na(respop_data[[column_name]]))\n\n  if (na_count &gt; 0) {\n    message(\"Column '\", column_name, \"' has \", na_count, \" NA values.\")\n  }\n}\n\n\n\n3.3 Recoding\nFor Age column, it is categorical due to the inclusion of an open-ended group, 90_and_Over. For this exercise, 90_and_Over was recoded to 90 so that Age could be treated as a numeric variable while still including this group in the analysis. This ensures that the completeness of the data. The following code will recode 90_and_Over to 90 and cast Age as numeric.\n\nrespop_data_clean &lt;- respop_data %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"90\", Age)) %&gt;%\n  mutate(Age = as.numeric(Age))\n\n\n\n3.4 Creating new column\nWith reference to URA Master Plan 2025, the 55 planning areas are classified into their respective regions with the following code.\n\nregion_mapping &lt;- c(\n  \"Ang Mo Kio\" = \"North-East\", \"Bedok\" = \"East\", \"Bishan\" = \"Central\", \n  \"Boon Lay\" = \"West\", \"Bukit Batok\" = \"West\", \"Bukit Merah\" = \"Central\", \n  \"Bukit Panjang\" = \"West\", \"Bukit Timah\" = \"Central\", \"Central Water Catchment\" = \"North\", \n  \"Changi\" = \"East\", \"Changi Bay\" = \"East\", \"Choa Chu Kang\" = \"West\", \n  \"Clementi\" = \"West\", \"Downtown Core\" = \"Central\", \"Geylang\" = \"Central\", \n  \"Hougang\" = \"North-East\", \"Jurong East\" = \"West\", \"Jurong West\" = \"West\", \n  \"Kallang\" = \"Central\", \"Lim Chu Kang\" = \"North\", \"Mandai\" = \"North\", \n  \"Marina East\" = \"Central\", \"Marina South\" = \"Central\", \"Marine Parade\" = \"Central\", \n  \"Museum\" = \"Central\", \"Newton\" = \"Central\", \"North-Eastern Islands\" = \"North-East\", \n  \"Novena\" = \"Central\", \"Orchard\" = \"Central\", \"Outram\" = \"Central\", \n  \"Pasir Ris\" = \"East\", \"Paya Lebar\" = \"East\", \"Pioneer\" = \"West\", \n  \"Punggol\" = \"North-East\", \"Queenstown\" = \"Central\", \"River Valley\" = \"Central\", \n  \"Rochor\" = \"Central\", \"Seletar\" = \"North-East\", \"Sembawang\" = \"North\", \n  \"Sengkang\" = \"North-East\", \"Serangoon\" = \"North-East\", \"Simpang\" = \"North\", \n  \"Singapore River\" = \"Central\", \"Southern Islands\" = \"Central\", \"Straits View\" = \"Central\", \n  \"Sungei Kadut\" = \"North\", \"Tampines\" = \"East\", \"Tanglin\" = \"Central\", \n  \"Tengah\" = \"West\", \"Toa Payoh\" = \"Central\", \"Tuas\" = \"West\", \n  \"Western Islands\" = \"West\", \"Western Water Catchment\" = \"West\", \"Woodlands\" = \"North\", \n  \"Yishun\" = \"North\"\n)\n\nrespop_data_clean &lt;- respop_data_clean %&gt;%\n  mutate(Region = region_mapping[PA])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-visualisation",
    "title": "Take-home Exercise 1",
    "section": "4 Data visualisation",
    "text": "4 Data visualisation\n\n4.1 National Distribution of Age and Sex Demographics\nTo gain an overview of the national age and sex demographics, we use a population pyramid that highlights the age distribution by sex. The stacked bar chart further illustrates the sex distribution within each age group.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create 5-year age bands\nnational_data &lt;- respop_data_clean %&gt;%\n  mutate(Age = as.integer(Age)) %&gt;%\n  mutate(\n    AgeBand = case_when(\n      Age &gt;= 90 ~ \"90+\",\n      TRUE ~ paste0(floor(Age / 5) * 5, \"-\", floor(Age / 5) * 5 + 4)\n    )\n  ) %&gt;%\n  group_by(AgeBand, Sex) %&gt;%\n  summarise(Total = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(\n    Total = ifelse(Sex == \"Males\", -Total, Total),\n    AgeBand = factor(AgeBand, levels = c(\n      paste0(seq(0, 85, 5), \"-\", seq(4, 89, 5)), \"90+\"\n    ))\n  )\n\n# Determine max population size for label positioning\nmax_pop &lt;- max(abs(national_data$Total))\ntop_age_band &lt;- tail(levels(national_data$AgeBand), 1)  \n\n# Population Pyramid plot with 90+ and top annotations\npyramid_plot &lt;- ggplot(national_data, aes(x = AgeBand, y = Total, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  coord_flip() +\n  scale_y_continuous(\n    labels = function(x) comma(abs(x)),\n    breaks = pretty_breaks()\n  ) +\n  labs(\n    title = \"Population Pyramid\",\n    x = \"Age Group\",\n    y = \"Population\"\n  ) +\n  scale_fill_manual(values = c(\"Males\" = \"#A1B8E0\", \"Females\" = \"#F8C1C1\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"none\"\n  ) +\n  annotate(\"text\", x = top_age_band, y = -max_pop * 0.5, label = \"Males\", color = \"#4A4A4A\", fontface = \"bold\", size = 3) +\n  annotate(\"text\", x = top_age_band, y = max_pop * 0.5, label = \"Females\", color = \"#4A4A4A\", fontface = \"bold\", size = 3)\n\nstacked_data &lt;- respop_data_clean %&gt;%\n  mutate(Age = as.integer(Age)) %&gt;%\n  mutate(\n    AgeBand = case_when(\n      Age &gt;= 90 ~ \"90+\",\n      TRUE ~ paste0(floor(Age / 5) * 5, \"-\", floor(Age / 5) * 5 + 4)\n    ),\n    AgeBand = factor(AgeBand, levels = c(\n      paste0(seq(0, 85, 5), \"-\", seq(4, 89, 5)), \"90+\"\n    ))\n  ) %&gt;%\n  group_by(AgeBand, Sex) %&gt;%\n  summarise(Pop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  group_by(AgeBand) %&gt;%\n  mutate(Proportion = Pop / sum(Pop)) %&gt;%\n  ungroup()\n\n# 100% Stacked Bar Chart using categorical age bands\nstacked_bar_plot &lt;- ggplot(stacked_data, aes(x = AgeBand, y = Proportion, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    title = \"Age-Sex Distribution\",\n    x = \"Age Group\",\n    y = \"Proportion within Age Group\"\n  ) +\n  scale_fill_manual(values = c(\"Males\" = \"#A1B8E0\", \"Females\" = \"#F8C1C1\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"  \n  ) +\n  # Annotate \"Males\" label\n  annotate(\"text\", x = 2, y = 0.3, label = \"Males\", color = \"#4A4A4A\", fontface = \"bold\", size = 3) +\n  # Annotate \"Females\" label\n  annotate(\"text\", x = 2, y = 0.9, label = \"Females\", color = \"#4A4A4A\", fontface = \"bold\", size = 3)\n\n\n# Arrange both plots side by side\npyramid_plot + stacked_bar_plot\n\n\n\n\nInsights\n\nThe national population pyramid highlights an ageing demographic with a significant concentration of the population observed between the age bands of 30-34 and 65-69, reflecting a large middle-aged and older working population.\nOn the other hand, the base of the pyramid is distinctively narrow, indicating persistently low birth rates and a declining proportion of younger residents.\nThe overall shape of the pyramid is generally symmetrical, suggesting a relatively balanced distribution between males and females across most age bands. However, the disparities become evident in the older age band. From the 75-79 band onwards, the females increasingly outnumber the males as seen in the 100% stacked bar chart.\n\n\n\n4.2 Population Size and Age Group Concentrations by Region\nThis section explores how the population is spread across different age groups in each region. The stacked bar chart shows the breakdown across five age groups for each region. Additionally, a slope chart shows the proportion of the youth against the senior populations, providing a simple visual of how each region’s population skews younger or older.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage_group_plot &lt;- respop_data_clean %&gt;%\n  mutate(Age_Group = cut(Age, breaks = c(0, 14, 24, 44, 64, Inf),\n                         labels = c(\"0-14\", \"15-24\", \"25-44\", \"45-64\", \"65+\"))) %&gt;%\n  filter(!is.na(Age_Group)) %&gt;%  \n  group_by(Region, Age_Group) %&gt;%\n  summarise(Total_Pop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(Region = fct_reorder(Region, Total_Pop, .fun = sum, .desc = TRUE)) %&gt;%\n  ggplot(aes(x = Region, y = Total_Pop, fill = Age_Group)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Age Group Distribution by Region\",\n       x = \"Region\", y = \"Population\", fill = \"Age Group\") +\n  scale_fill_manual(values = c(\"0-14\" = \"#FFB6C1\",\n                               \"15-24\" = \"#B3D9FF\", \n                               \"25-44\" = \"#A7D8C7\", \n                               \"45-64\" = \"#FFD1A9\",  \n                               \"65+\" = \"#E0B0FF\")) +  \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5))\n\n# Second plot (Slope Chart for Youth vs Senior Population)\nyouth_senior_data &lt;- respop_data_clean %&gt;%\n  mutate(Age_Group = case_when(\n    Age &lt;= 24 ~ \"Youth (0–24)\",\n    Age &gt;= 65 ~ \"Senior (65+)\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(Age_Group)) %&gt;%\n  group_by(Region, Age_Group) %&gt;%\n  summarise(Total_Pop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = Age_Group, values_from = Total_Pop) %&gt;%\n  mutate(\n    `Youth-to-Senior Ratio` = `Youth (0–24)` / `Senior (65+)`\n  ) %&gt;%\n  pivot_longer(\n    cols = c(`Youth (0–24)`, `Senior (65+)`),\n    names_to = \"Group\",\n    values_to = \"Population\"\n  )\n\n# Slope chart plot\nslope_chart_plot &lt;- ggplot(youth_senior_data, aes(x = Group, y = Population, group = Region)) +\n  geom_line(aes(color = Region), linewidth = 1) +\n  geom_point(aes(color = Region), size = 3) +\n  labs(title = \"Youth vs Senior Population by Region\",\n       x = \"\", y = \"Population\") +\n  theme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5))\n\n# Combine both plots side by side\nage_group_plot + slope_chart_plot\n\n\n\n\nInsights\n\nThe North-East region is the most populous, followed closely by the Central and West regions. In contrast, the East and North regions have significantly smaller populations.\nThe North-East also has the highest proportion of children aged 0–14, reinforcing its reputation as a family-oriented region popular with young households.\nThe Central region has the highest concentration of senior citizens (aged 65 and above), followed by the North-East and West regions, while the North region has the smallest senior population.\nAge groups of 0-14 and 15-24 remain relatively small across all regions, reflecting a broader national trend of declining birth rates.\nThe Central region stands out with a near-equal number of youths (aged 0–24) and seniors (65+). Despite signs of ageing, each region still has more youths than seniors, highlighting the continued presence of younger populations alongside an ageing demographic.\n\n\n\n4.3 Regional Age Profiles and Distribution Patterns\nTo get a better understanding of the age distribution and variation across the regions, we plot the following boxplot and density ridge plot.\n\nThe boxplot provides an overview of the age distribution within each region while highlighting the median, mean, interquartiles and range. This allows for easy comparison of the central tendency and spread of ages across regions.\nMeanwhile, the density ridge plot offers a more nuanced view by visualising the probability density of the age distribution. This reveals the relative density of different age groups across regions, emphasising the shapes and variations in distribution.\n\nTogether, these two visualisation provides a more comprehensive view of the population’s age structure, addressing the regional differences.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Boxplot\nrespop_expanded &lt;- respop_data_clean %&gt;%\n  uncount(weights = Pop)\nboxplot_plot &lt;- ggplot(respop_expanded, aes(y = Region, x = Age, fill = Region)) + \n  geom_boxplot() + \n  labs(title = \"Age Distribution Across Regions\",\n       x = \"Age\",\n       y = \"Region\") +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour = \"#9B2D20\",       \n               size = 4)   +\n  scale_fill_manual(values = c(\n    \"Central\" = \"#F9E29D\",   \n    \"East\" = \"#D6AEDD\",      \n    \"North\" = \"#F6B6A1\",   \n    \"North-East\" = \"#A9D8C9\",\n    \"West\" = \"#F7A1A0\"      \n  )) +\n  theme_minimal() +\n  theme(axis.title = element_text(size = 10),\n        plot.title = element_text(hjust = 0.5),\n        legend.position = \"none\",\n        )\n\n# Density Ridge Plot\ndensity_ridge_plot &lt;- respop_data_clean %&gt;%\n  ggplot(aes(x = Age, y = Region, \n             height = after_stat(density), \n             fill = Region, weight = Pop)) +\n  geom_density_ridges(stat = \"density\", scale = 3, alpha = 0.7, color = \"white\") +\n  labs(title = \"Weighted Age Density Distribution by Region\",\n       x = \"Age\", y = \"Region\") +\n  scale_fill_manual(values = c(\n    \"Central\" = \"#F9E29D\",  \n    \"East\" = \"#D6AEDD\",    \n    \"North\" = \"#F6B6A1\",     \n    \"North-East\" = \"#A9D8C9\",\n    \"West\" = \"#F7A1A0\"       \n  )) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5))\n\n\ndensity_ridge_plot / boxplot_plot\n\n\n\n\nInsights\n\nAll regions show signs of an ageing population, with noticeable age densities continuing into the 60s to 70s.\nAmong the regions, the North stands out with the youngest age profile, with lowest mean and median. Meanwhile, the Central region has the oldest demographic profile, with the highest mean and median, and a wider spread towards older age groups.\nBoth the North and North-East regions have their mean nearly identical to its own median, indicating a relatively balanced age distribution. Additionally, these two regions have a younger skew compared to the other regions.\nThe East and Central regions exhibit broader age distributions into the older age range. Their mean and median are also higher than that of the other regions, suggesting a more mature population."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#summary-and-conclusion",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#summary-and-conclusion",
    "title": "Take-home Exercise 1",
    "section": "5 Summary and conclusion",
    "text": "5 Summary and conclusion\nThese data visualisation serves as a foundation for telling the story of Singapore’s population in 2024. It strives to help readers better understand Singapore’s demographic landscape and its regional age patterns.\nSingapore’s demographic structure in 2024 indicates an ageing population, with most residents aged between 30 to 69 and a shrinking base of younger residents. While the overall gender distribution is relatively well-balanced, females increasingly outnumber males in the older age groups from age 75 onwards.\nAcross regions, ageing is evident as well. Notably, the Central region has the oldest demographic, while the North has the youngest demographic. Additionally, the North-East is the most populous with the largest proportion of children aged below 14 and below, cementing its reputation as a place of residence for young families."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#reference",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#reference",
    "title": "Take-home Exercise 1",
    "section": "6 Reference",
    "text": "6 Reference\n\nSingstat\nURA Master Plan 2025"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "This take-home exercise will be done in reference to the VAST Challenge 2025 and provide solutions to the first question of Mini-Challenge 1.\n\n\nOne of music’s biggest superstars is Oceanus native Sailor Shift. From humble beginnings, Sailor has grown in popularity and now enjoys fans around the world. Sailor started her career on the island nation of Oceanus which can be clearly seen in her early work, she started in the genre of “Oceanus Folk”. While Sailor has moved away from the traditional Oceanus style, the Oceanus Folk has made a name for itself in the musical world. The popularity of this music is one of the factors driving an increase in tourism to a quiet island nation that used to be known for fishing.\nIn 2023, Sailor Shift joined the Ivy Echoes – an all-female Oceanus Folk band consisting of Sailor (vocalist), Maya Jensen (vocalist), Lila “Lilly” Hartman (guitarist), Jade Thompson (drummer), and Sophie Ramirez (bassist). They played together at venues throughout Oceanus but had broken up to pursue their individual careers by 2026. Sailor’s breakthrough came in 2028 when one of her singles went viral, launched to the top of the global charts (something no other Oceanus Folk song had ever done). Since then, she has only continued to grow in popularity worldwide.\nSailor has released a new album almost every year since her big break, and each has done better than the last. Although she has remained primarily a solo artist, she has also frequently collaborated with other established artists, especially in the Indie Pop and Indie Folk genres. She herself has branched out musically over the years but regularly returns to the Oceanus Folk genre — even as the genre’s influence on the rest of the music world has spread even more.\nSailor has always been passionate about two things: (1) spreading Oceanus Folk, and (2) helping lesser-known artists break into music. Because of those goals, she’s particularly famous for her frequent collaborations.\nAdditionally, because of Sailor’s success, more attention began to be paid over the years to her previous bandmates. All 4 have continued in the music industry—Maya as an independent vocalist, Lilly and Jade as instrumentalists in other bands, and Sophie as a music producer for a major record label. In various ways, all of them have contributed to the increased influence of Oceanus folk, resulting in a new generation of up-and-coming Oceanus Folk artists seeking to make a name for themselves in the music industry.\nNow, as Sailor returns to Oceanus in 2040, a local journalist – Silas Reed – is writing a piece titled Oceanus Folk: Then-and-Now that aims to trace the rise of Sailor and the influence of Oceanus Folk on the rest of the music world. He has collected a large dataset of musical artists, producers, albums, songs, and influences and organized it into a knowledge graph. Your task is to help Silas create beautiful and informative visualizations of this data and uncover new and interesting information about Sailor’s past, her rise to stardom, and her influence.\n\n\n\nThe objective of this take-home exercise is to address the following tasks and questions of VAST Challenge 2025’s Mini-Challenge 1.\n\nDesign and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career\n\nWho has she been most influenced by over time?\nWho has she collaborated with and directly or indirectly influenced?\nHow has she influenced collaborators of the broader Oceanus Folk community?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#load-the-packages",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#load-the-packages",
    "title": "Take-home Exercise 2",
    "section": "2.1 Load the packages",
    "text": "2.1 Load the packages\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environemnt.\n\npacman::p_load(jsonlite, tidyverse, ggtext,\n                knitr, lubridate, patchwork,\n                ggraph, tidygraph, igraph, scales,\n                ggiraph, dplyr, stringr, ggnewscale)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#importing-knowledge-graph-data",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#importing-knowledge-graph-data",
    "title": "Take-home Exercise 2",
    "section": "2.2 Importing Knowledge Graph Data",
    "text": "2.2 Importing Knowledge Graph Data\nfromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object.\n\nmc1_data &lt;- fromJSON(\"MC1/data/MC1_graph.json\")\n\n\n2.2.1 Inspect structure\nHere, str() is used to reveal the structure of mc1_data object.\n\nstr(mc1_data, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "title": "Take-home Exercise 2",
    "section": "2.3 Extracting the edges and nodes tables",
    "text": "2.3 Extracting the edges and nodes tables\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from mc1_data object into two separate tibble data frames called mc1_nodes_raw and mc1_edges_raw respectively.\n\nmc1_nodes_raw &lt;- as_tibble(mc1_data$nodes)\nglimpse(mc1_nodes_raw)\n\nRows: 17,412\nColumns: 10\n$ `Node Type`    &lt;chr&gt; \"Song\", \"Person\", \"Person\", \"Person\", \"RecordLabel\", \"S…\n$ name           &lt;chr&gt; \"Breaking These Chains\", \"Carlos Duffy\", \"Min Qin\", \"Xi…\n$ single         &lt;lgl&gt; TRUE, NA, NA, NA, NA, FALSE, NA, NA, NA, NA, TRUE, NA, …\n$ release_date   &lt;chr&gt; \"2017\", NA, NA, NA, NA, \"2026\", NA, NA, NA, NA, \"2020\",…\n$ genre          &lt;chr&gt; \"Oceanus Folk\", NA, NA, NA, NA, \"Lo-Fi Electronica\", NA…\n$ notable        &lt;lgl&gt; TRUE, NA, NA, NA, NA, TRUE, NA, NA, NA, NA, TRUE, NA, N…\n$ id             &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ written_date   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020\", NA, NA,…\n$ stage_name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ notoriety_date &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\nkable(head(mc1_nodes_raw, 5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type\nname\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\n\n\n\n\nSong\nBreaking These Chains\nTRUE\n2017\nOceanus Folk\nTRUE\n0\nNA\nNA\nNA\n\n\nPerson\nCarlos Duffy\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\n\n\nPerson\nMin Qin\nNA\nNA\nNA\nNA\n2\nNA\nNA\nNA\n\n\nPerson\nXiuying Xie\nNA\nNA\nNA\nNA\n3\nNA\nNA\nNA\n\n\nRecordLabel\nNautical Mile Records\nNA\nNA\nNA\nNA\n4\nNA\nNA\nNA\n\n\n\n\n\n\nmc1_edges_raw &lt;- as_tibble(mc1_data$links)\n\nglimpse(mc1_edges_raw)\n\nRows: 37,857\nColumns: 4\n$ `Edge Type` &lt;chr&gt; \"InterpolatesFrom\", \"RecordedBy\", \"PerformerOf\", \"Composer…\n$ source      &lt;int&gt; 0, 0, 1, 1, 2, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ target      &lt;int&gt; 1841, 4, 0, 16180, 0, 16180, 0, 5088, 14332, 11677, 2479, …\n$ key         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\nkable(head(mc1_edges_raw, 5))\n\n\n\n\nEdge Type\nsource\ntarget\nkey\n\n\n\n\nInterpolatesFrom\n0\n1841\n0\n\n\nRecordedBy\n0\n4\n0\n\n\nPerformerOf\n1\n0\n0\n\n\nComposerOf\n1\n16180\n0\n\n\nPerformerOf\n2\n0\n0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#initial-eda",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#initial-eda",
    "title": "Take-home Exercise 2",
    "section": "3.4 Initial EDA",
    "text": "3.4 Initial EDA\nApply appropriate EDA methods to examine the data.\nIn this code chunk below, ggplot2 functions are used the reveal the frequency distribution of Edge Type field of edges_tbl.\n\nggplot(data = edges_tbl,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nOn the other hands, code chunk below uses ggplot2 functions to reveal the frequency distribution of Node Type field of nodes_tbl.\n\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#creating-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#creating-knowledge-graph",
    "title": "Take-home Exercise 2",
    "section": "4.8 Creating knowledge graph",
    "text": "4.8 Creating knowledge graph\ntbl_graph() is used to create tidygraph’s graph object by using the following code chunk.\n\nmusic = tbl_graph(edges = mc1_edges_clean,\n                             nodes = mc1_nodes_clean,\n                             directed = TRUE)\n\nclass(music)\n\n[1] \"tbl_graph\" \"igraph\"   \n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html",
    "title": "TestMC1",
    "section": "",
    "text": "Design and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career\n\nWho has she been most influenced by over time?\nWho has she collaborated with and directly or indirectly influenced?\nHow has she influenced collaborators of the broader Oceanus Folk community?\n\nDevelop visualizations that illustrate how the influence of Oceanus Folk has spread through the musical world.\n\nWas this influence intermittent or did it have a gradual rise?\nWhat genres and top artists have been most influenced by Oceanus Folk?\nOn the converse, how has Oceanus Folk changed with the rise of Sailor Shift? From which genres does it draw most of its contemporary inspiration?\n\nUse your visualizations to develop a profile of what it means to be a rising star in the music industry.\n\nVisualize the careers of three artists. Compare and contrast their rise in popularity and influence.\nUsing this characterization, give three predictions of who the next Oceanus Folk stars with be over the next five years."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#tasks-and-questions",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#tasks-and-questions",
    "title": "TestMC1",
    "section": "",
    "text": "Design and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career\n\nWho has she been most influenced by over time?\nWho has she collaborated with and directly or indirectly influenced?\nHow has she influenced collaborators of the broader Oceanus Folk community?\n\nDevelop visualizations that illustrate how the influence of Oceanus Folk has spread through the musical world.\n\nWas this influence intermittent or did it have a gradual rise?\nWhat genres and top artists have been most influenced by Oceanus Folk?\nOn the converse, how has Oceanus Folk changed with the rise of Sailor Shift? From which genres does it draw most of its contemporary inspiration?\n\nUse your visualizations to develop a profile of what it means to be a rising star in the music industry.\n\nVisualize the careers of three artists. Compare and contrast their rise in popularity and influence.\nUsing this characterization, give three predictions of who the next Oceanus Folk stars with be over the next five years."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#data-source",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#data-source",
    "title": "TestMC1",
    "section": "1.3 Data Source",
    "text": "1.3 Data Source\nThe data for this exercise is from VAST 2025 MC1."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#data-description",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#data-description",
    "title": "TestMC1",
    "section": "1.4 Data Description",
    "text": "1.4 Data Description\nGraph Description - Directed Multigraph - # nodes: 17,412 - # edges: 37, 857 - 18 connected components - Possible node types are: {Person, Song, RecordLabel, Album, MusicalGroup} - Possible edge types are: {MemberOf, PerformerOf, ComposerOf, ProducerOf, LyricistOf, InStyleOf, InterpolatesFrom, CoverOf, LyricalReferenceTo, DirectlySamples, RecordedBy, DistributedBy} - The graph format is a JSON file. The root-level JSON object consists of graph-level properties specifying that it is directed and a multigraph, a “nodes” key which holds the list of nodes, and a “links” key which holds the list of edges.\nThe data for this challenge comes from two different sources:\n\nan online, crowdsourced repository of musical influence, where contributors have manually notated instances in which songs or albums have sampled, covered, or otherwise drawn inspiration from previous work.\naggregate-level descriptions of song popularity, as labeled by our journalist, Silas Reed. These notations (notable and notoriety_date) are directly based on both the number of sales and streams that the song/album has achieved as well as the whether or not the work landed on a top record chart."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#install-and-load-the-required-libraries",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#install-and-load-the-required-libraries",
    "title": "TestMC1",
    "section": "1.5 Install and Load the Required Libraries",
    "text": "1.5 Install and Load the Required Libraries\nUtility Tools\n\njsonlite: To parse JSON\ntidyverse - Data science tools\nggtext - Tools for text formatting\nknitr - For better table displays\nlubridate - For processing date and time\n\nGraphing Tools\n\npatchwork - For combining ggplot plots\nggraph - For plotting network data\ntidygraph - For graph manipulations\nigraph - Contains functions for network analysis\nggiraph - Interactive plots\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\n\nShow code\npacman::p_load(jsonlite, tidyverse, ggtext,\n                knitr, lubridate, patchwork,\n                ggraph, tidygraph, igraph,\n                ggiraph)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#importing-data",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#importing-data",
    "title": "TestMC1",
    "section": "[1-1:]1.6 Importing Data",
    "text": "[1-1:]1.6 Importing Data\nFor the purpose of this exercise, a data file called MC1_graph will be used. The code chunk below imports respopagesex2024.csv into R environment by using read_csv() function of readr package (under tidyverse).\n\n\n\n\n\n\nCode\n\n\n\n\n\n\n\nShow code\nmc1_data &lt;- fromJSON(\"MC1/data/MC1_graph.json\")\nglimpse(mc1_data)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n  ..$ node_default: Named list()\n  ..$ edge_default: Named list()\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n  ..$ Node Type     : chr [1:17412] \"Song\" \"Person\" \"Person\" \"Person\" ...\n  ..$ name          : chr [1:17412] \"Breaking These Chains\" \"Carlos Duffy\" \"Min Qin\" \"Xiuying Xie\" ...\n  ..$ single        : logi [1:17412] TRUE NA NA NA NA FALSE ...\n  ..$ release_date  : chr [1:17412] \"2017\" NA NA NA ...\n  ..$ genre         : chr [1:17412] \"Oceanus Folk\" NA NA NA ...\n  ..$ notable       : logi [1:17412] TRUE NA NA NA NA TRUE ...\n  ..$ id            : int [1:17412] 0 1 2 3 4 5 6 7 8 9 ...\n  ..$ written_date  : chr [1:17412] NA NA NA NA ...\n  ..$ stage_name    : chr [1:17412] NA NA NA NA ...\n  ..$ notoriety_date: chr [1:17412] NA NA NA NA ...\n $ links     :'data.frame': 37857 obs. of  4 variables:\n  ..$ Edge Type: chr [1:37857] \"InterpolatesFrom\" \"RecordedBy\" \"PerformerOf\" \"ComposerOf\" ...\n  ..$ source   : int [1:37857] 0 0 1 1 2 2 3 5 5 5 ...\n  ..$ target   : int [1:37857] 1841 4 0 16180 0 16180 0 5088 14332 11677 ...\n  ..$ key      : int [1:37857] 0 0 0 0 0 0 0 0 0 0 ...\n\n\n\n\n\n\nSeparating into node and edge data\n\nmc1_nodes_raw &lt;- as_tibble(mc1_data$nodes)\n\nglimpse(mc1_nodes_raw)\n\nRows: 17,412\nColumns: 10\n$ `Node Type`    &lt;chr&gt; \"Song\", \"Person\", \"Person\", \"Person\", \"RecordLabel\", \"S…\n$ name           &lt;chr&gt; \"Breaking These Chains\", \"Carlos Duffy\", \"Min Qin\", \"Xi…\n$ single         &lt;lgl&gt; TRUE, NA, NA, NA, NA, FALSE, NA, NA, NA, NA, TRUE, NA, …\n$ release_date   &lt;chr&gt; \"2017\", NA, NA, NA, NA, \"2026\", NA, NA, NA, NA, \"2020\",…\n$ genre          &lt;chr&gt; \"Oceanus Folk\", NA, NA, NA, NA, \"Lo-Fi Electronica\", NA…\n$ notable        &lt;lgl&gt; TRUE, NA, NA, NA, NA, TRUE, NA, NA, NA, NA, TRUE, NA, N…\n$ id             &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ written_date   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020\", NA, NA,…\n$ stage_name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ notoriety_date &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\nkable(head(mc1_nodes_raw, 5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type\nname\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\n\n\n\n\nSong\nBreaking These Chains\nTRUE\n2017\nOceanus Folk\nTRUE\n0\nNA\nNA\nNA\n\n\nPerson\nCarlos Duffy\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\n\n\nPerson\nMin Qin\nNA\nNA\nNA\nNA\n2\nNA\nNA\nNA\n\n\nPerson\nXiuying Xie\nNA\nNA\nNA\nNA\n3\nNA\nNA\nNA\n\n\nRecordLabel\nNautical Mile Records\nNA\nNA\nNA\nNA\n4\nNA\nNA\nNA\n\n\n\n\n\n\nmc1_edges_raw &lt;- as_tibble(mc1_data$links)\n\nglimpse(mc1_edges_raw)\n\nRows: 37,857\nColumns: 4\n$ `Edge Type` &lt;chr&gt; \"InterpolatesFrom\", \"RecordedBy\", \"PerformerOf\", \"Composer…\n$ source      &lt;int&gt; 0, 0, 1, 1, 2, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ target      &lt;int&gt; 1841, 4, 0, 16180, 0, 16180, 0, 5088, 14332, 11677, 2479, …\n$ key         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\nkable(head(mc1_edges_raw, 10))\n\n\n\n\nEdge Type\nsource\ntarget\nkey\n\n\n\n\nInterpolatesFrom\n0\n1841\n0\n\n\nRecordedBy\n0\n4\n0\n\n\nPerformerOf\n1\n0\n0\n\n\nComposerOf\n1\n16180\n0\n\n\nPerformerOf\n2\n0\n0\n\n\nProducerOf\n2\n16180\n0\n\n\nPerformerOf\n3\n0\n0\n\n\nInterpolatesFrom\n5\n5088\n0\n\n\nInStyleOf\n5\n14332\n0\n\n\nInterpolatesFrom\n5\n11677\n0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#creating-the-global-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#creating-the-global-knowledge-graph",
    "title": "TestMC1",
    "section": "Creating the global knowledge graph",
    "text": "Creating the global knowledge graph\ntbl_graph() is used to create tidygraph’s graph object by using the code chunk below\n\nmusic = tbl_graph(edges = mc1_edges_clean,\n                             nodes = mc1_nodes_clean,\n                             directed = TRUE)\n\n\nset.seed(1234)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#question-1a-who-has-she-been-most-influenced-by-over-time",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#question-1a-who-has-she-been-most-influenced-by-over-time",
    "title": "TestMC1",
    "section": "Question 1a Who has she been most influenced by over time?",
    "text": "Question 1a Who has she been most influenced by over time?\nHow do I find who is she influenced by?\n\n# Convert tbl_graph to igraph\nig &lt;- as.igraph(music)\n\n# Get index for 'Sailor Shift'\nsailor_idx &lt;- which(V(ig)$name == \"Sailor Shift\")\n\n# Get 2-degree ego neighbourhood\nneighbourhood_nodes &lt;- ego(ig, order = 2, nodes = sailor_idx, mode = \"out\")[[1]]\n\n# Step 2: Get 2-degree in-neighbours to those filtered out-neighbours\nin_to_out_neighbours &lt;- unique(unlist(\n  lapply(neighbourhood_nodes, function(n) {\n    ego(ig, order = 1, nodes = n, mode = \"in\")[[1]]\n  })\n))\n\n# Step 3: Combine all relevant nodes (Sailor Shift + out-neighbours + their 2-degree in-neighbours)\nall_nodes &lt;- unique(c(sailor_idx, neighbourhood_nodes, in_to_out_neighbours))\n\n# Induce subgraph and convert to tbl_graph\nsub_music &lt;- induced_subgraph(ig, vids = all_nodes) %&gt;% \n  as_tbl_graph()\n\n# Convert to igraph for path computation\nig_sub &lt;- as.igraph(sub_music)\n\n# Re-identify 'Sailor Shift' in the new graph\nsailor_idx_sub &lt;- which(V(ig_sub)$name == \"Sailor Shift\")\n\n# Compute shortest paths from Sailor Shift\nsp &lt;- shortest_paths(ig_sub, from = sailor_idx_sub, mode = \"out\", output = \"vpath\")$vpath\n\nWarning in shortest_paths(ig_sub, from = sailor_idx_sub, mode = \"out\", output =\n\"vpath\"): At vendor/cigraph/src/paths/unweighted.c:444 : Couldn't reach some\nvertices.\n\n# Count path dependencies (with safety for unreachable nodes)\nnode_names &lt;- V(ig_sub)$name\ndep_score &lt;- sapply(node_names, function(n) {\n  sum(sapply(sp, function(path) {\n    if (length(path) == 0) return(FALSE)\n    n %in% names(path)\n  }))\n})\n\n# Attach to tbl_graph\nsub_music &lt;- sub_music %&gt;%\n  mutate(sailor_dependency = dep_score)\n\n\ng &lt;- sub_music %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_fan(\n    aes(\n      colour = `Edge Type`,\n      start_cap = circle(1, 'mm'),\n      end_cap = circle(1, 'mm')\n      ),\n    arrow = arrow(length = unit(2, 'mm')),\n    alpha = 0.4\n    ) +\n  geom_point_interactive(\n    aes(\n      x = x,\n      y = y,\n      data_id = name,\n      tooltip = sprintf(\"%s&lt;br/&gt;(%s)\", name, released_year),\n      colour = genre,\n      size = sailor_dependency,\n      shape = `Node Type`\n      ),\n    show.legend = c(size = FALSE)\n    )+ \n  geom_node_text(\n    aes(\n      label = ifelse(`name` == \"Sailor Shift\", \"Sailor Shift\", NA)\n    ),\n    size = 4,\n    colour = 'red',\n    show.legend = FALSE\n    ) +\n  theme_graph() +\n  theme(legend.text = element_text(size = 6),\n        legend.title = element_text(size = 9)) +\n  scale_shape_discrete(name = \"Node Type\")\ng &lt;- g + theme_minimal(base_family = \"sans\")\n\ngirafe(ggobj = g, width_svg = 10, height_svg = 9)\n\nWarning: Removed 331 rows containing missing values or values outside the scale range\n(`geom_text()`).\n\n\n\n\n\n\n\n# Extract node data\nnode_data &lt;- as_tibble(sub_music)\n\n# View top 5 nodes with highest sailor_dependency\nnode_data %&gt;%\n  arrange(desc(sailor_dependency)) %&gt;%\n  head(5) %&gt;%\n  select(`Node Type`, name, sailor_dependency) %&gt;%\n  kable()\n\n\n\n\nNode Type\nname\nsailor_dependency\n\n\n\n\nPerson\nSailor Shift\n112\n\n\nMusicalGroup\nThe Fiddle & The Fjord\n13\n\n\nMusicalGroup\nDrowned Harbor\n13\n\n\nMusicalGroup\nIvy Echos\n11\n\n\nMusicalGroup\nThe Saltwater Weavers\n10"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#b-who-has-she-collaborated-with-and-directly-or-indirectly-influenced",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#b-who-has-she-collaborated-with-and-directly-or-indirectly-influenced",
    "title": "TestMC1",
    "section": "1.b Who has she collaborated with and directly or indirectly influenced?",
    "text": "1.b Who has she collaborated with and directly or indirectly influenced?\n\nDirectly\nFind all immediate people and musical groups Sailor Shift directly influenced\n\n# Convert tbl_graph to igraph\nig &lt;- as.igraph(music)\n\n# Get index for 'Sailor Shift'\nsailor_idx &lt;- which(V(ig)$name == \"Sailor Shift\")\n\n# Get 1-degree in ego neighbourhood\nneighbourhood_nodes &lt;- ego(ig, order = 1, nodes = sailor_idx, mode = \"in\")[[1]]\n\n# Induce subgraph and convert to tbl_graph\nsub_music &lt;- induced_subgraph(ig, vids = neighbourhood_nodes) %&gt;% \n  as_tbl_graph()\n\n\ng &lt;- sub_music %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_fan(\n    aes(\n      colour = `Edge Type`,\n      start_cap = circle(2, 'mm'),\n      end_cap = circle(2, 'mm')\n      ),\n    arrow = arrow(length = unit(2, 'mm')),\n    alpha = 0.4\n    ) +\n  geom_point_interactive(\n    aes(\n      x = x,\n      y = y,\n      data_id = name,\n      tooltip = sprintf(\"%s&lt;br/&gt;(%s)\", name, released_year),\n      colour = genre,\n      shape = `Node Type`\n      ),\n    show.legend = c(size = FALSE)\n    )+ \n  geom_node_text(\n    aes(\n      label = ifelse(`name` == \"Sailor Shift\", \"Sailor Shift\", NA)\n    ),\n    size = 4,\n    colour = 'red',\n    show.legend = FALSE\n    ) +\n  theme_graph() +\n  theme(legend.text = element_text(size = 6),\n        legend.title = element_text(size = 9)) +\n  scale_shape_discrete(name = \"Node Type\")\ng &lt;- g + theme_minimal(base_family = \"sans\")\ngirafe(ggobj = g, width_svg = 8, height_svg = 6)\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_text()`).\n\n\n\n\n\n\n\n# Extract node data\nnode_data &lt;- as_tibble(sub_music)\n\nnode_data %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  select(`Node Type`, name) %&gt;%\n  kable()\n\n\n\n\nNode Type\nname\n\n\n\n\nMusicalGroup\nCassette Future\n\n\nMusicalGroup\nSilver Veil\n\n\nMusicalGroup\nThe Phantom Operators\n\n\nMusicalGroup\nThe Hollow Monarchs\n\n\nPerson\nCassian Storm\n\n\nPerson\nClaire Holmes\n\n\nPerson\nSailor Shift\n\n\nMusicalGroup\nCopper Canyon Ghosts"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#indirect",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#indirect",
    "title": "TestMC1",
    "section": "1.2 Indirect",
    "text": "1.2 Indirect\nFind all the songs and albums that Sailor Shift produced, then get 2 degree in neighbours from the songs / albums to see who has been influenced by her songs or made songs influenced by her songs or have direct collaboration with her\n\n# Step 1: Get Sailor Shift's 1-degree out-neighbours\nsailor_idx &lt;- which(V(ig)$name == \"Sailor Shift\")\nout_edges &lt;- incident(ig, sailor_idx, mode = \"out\")\n\n# Filter edges by desired Edge Type\nvalid_edge_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\nvalid_edges &lt;- out_edges[E(ig)[out_edges]$`Edge Type` %in% valid_edge_types]\n\n# Get target nodes from valid edges\nout_neighbours &lt;- as.integer(ends(ig, valid_edges, names = FALSE)[, 2])  # target vertex of each edge\n\n# Filter to only songs or albums\nout_neighbours &lt;- out_neighbours[\n  V(ig)[out_neighbours]$`Node Type` %in% c(\"Song\", \"Album\")\n]\n\n# Step 2: Get 1-degree in-neighbours to those filtered out-neighbours\nin_to_out_neighbours &lt;- unique(unlist(\n  lapply(out_neighbours, function(n) {\n    ego(ig, order = 1, nodes = n, mode = \"in\")[[1]]\n  })\n))\n\n# Step 3: Combine all relevant nodes (Sailor Shift + out-neighbours + their 2-degree in-neighbours)\nall_nodes &lt;- unique(c(sailor_idx, out_neighbours, in_to_out_neighbours))\n\n# Step 4: Induce subgraph over combined nodes\nsubgraph &lt;- induced_subgraph(ig, vids = all_nodes)\nsub_music &lt;- as_tbl_graph(subgraph)\n\n# Convert to igraph for path computation\nig_sub &lt;- as.igraph(sub_music)\n\n# Re-identify 'Sailor Shift' in the new graph\nsailor_idx_sub &lt;- which(V(ig_sub)$name == \"Sailor Shift\")\n\n# Compute shortest paths from Sailor Shift (all directions in subgraph)\nsp &lt;- shortest_paths(ig_sub, from = sailor_idx_sub, mode = \"all\", output = \"vpath\")$vpath\n\n# Count path dependencies (including Sailor Shift)\nnode_names &lt;- V(ig_sub)$name\ndep_score &lt;- sapply(node_names, function(n) {\n  sum(sapply(sp, function(path) {\n    if (length(path) == 0) return(FALSE)\n    n %in% names(path)\n  }))\n})\n\n# Attach path dependency score to graph\nsub_music &lt;- sub_music %&gt;%\n  mutate(sailor_dependency = dep_score)\n\n\ng &lt;- sub_music %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_fan(\n    aes(\n      colour = `Edge Type`,\n      start_cap = circle(2, 'mm'),\n      end_cap = circle(2, 'mm')\n      ),\n    arrow = arrow(length = unit(2, 'mm')),\n    alpha = 0.4\n    ) +\n  geom_point_interactive(\n    aes(\n      x = x,\n      y = y,\n      data_id = name,\n      tooltip = sprintf(\"%s&lt;br/&gt;(%s)\", name, released_year),\n      colour = genre,\n      size = sailor_dependency,\n      shape = `Node Type`\n      ),\n    show.legend = c(size = FALSE)\n    )+ \n  geom_node_text(\n    aes(\n      label = ifelse(`name` == \"Sailor Shift\", \"Sailor Shift\", NA)\n    ),\n    size = 4,\n    colour = 'red',\n    show.legend = FALSE\n    ) +\n  theme_graph() +\n  theme(legend.text = element_text(size = 6),\n        legend.title = element_text(size = 9)) +\n  scale_shape_discrete(name = \"Node Type\")\ng &lt;- g + theme_minimal(base_family = \"sans\")\ngirafe(ggobj = g, width_svg = 8, height_svg = 6)\n\nWarning: Removed 90 rows containing missing values or values outside the scale range\n(`geom_text()`).\n\n\n\n\n\n\n\n# Extract node data\nnode_data &lt;- as_tibble(sub_music)\n\nnode_data %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  arrange(desc(sailor_dependency)) %&gt;%\n  select(`Node Type`, name) %&gt;%\n  kable()\n\n\n\n\nNode Type\nname\n\n\n\n\nPerson\nSailor Shift\n\n\nMusicalGroup\nIvy Echos\n\n\nPerson\nMichael Harris\n\n\nPerson\nZane Cruz\n\n\nPerson\nIris Moon\n\n\nMusicalGroup\nViolet Engines\n\n\nPerson\nSophie Bennett\n\n\nPerson\nKara Lee\n\n\nPerson\nEthan Clarke\n\n\nMusicalGroup\nTidal Reverie\n\n\nPerson\nOlivia Carter\n\n\nPerson\nLucas Bennett\n\n\nPerson\nMaya Torres\n\n\nMusicalGroup\nCrimson Carriage\n\n\nPerson\nArlo Sterling\n\n\nPerson\nLyra Blaze\n\n\nPerson\nOrion Cruz\n\n\nPerson\nElara May\n\n\nPerson\nCassian Rae\n\n\nMusicalGroup\nThe Brine Choir\n\n\nPerson\nZachary Cole\n\n\nPerson\nLia Grant\n\n\nMusicalGroup\nSelkies Hollow\n\n\nPerson\nRusty Riggins\n\n\nPerson\nFinn McGraw\n\n\nPerson\nWilliam Tidewell\n\n\nPerson\nEwan MacCrae\n\n\nPerson\nAstrid Nørgaard\n\n\nPerson\nFreya Lindholm\n\n\nPerson\nLiam OSullivan\n\n\nPerson\nFiona Mercer\n\n\nPerson\nKai Reynolds\n\n\nPerson\nAiden Harper\n\n\nPerson\nFinn Morgan\n\n\nPerson\nSkylar Brooks\n\n\nMusicalGroup\nThe Wave Riders\n\n\nPerson\nMia Waters\n\n\nPerson\nLila Rivers\n\n\nMusicalGroup\nSirens Call\n\n\nPerson\nMaya Jensen\n\n\nPerson\nLila “Lilly” Hartman\n\n\nPerson\nJade Thompson\n\n\nPerson\nSophie Ramirez\n\n\nPerson\nCoralia Bellweather\n\n\nPerson\nLevi Holloway\n\n\nPerson\nMarin Thorne\n\n\nPerson\nJonah Calloway\n\n\nPerson\nBeatrice Albright\n\n\nPerson\nDaniel OConnell"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/TestMC1.html#c-how-has-she-influenced-collaborators-of-the-broader-oceanus-folk-community",
    "href": "Take-home_Ex/Take-home_Ex2/TestMC1.html#c-how-has-she-influenced-collaborators-of-the-broader-oceanus-folk-community",
    "title": "TestMC1",
    "section": "1.c How has she influenced collaborators of the broader Oceanus Folk community?",
    "text": "1.c How has she influenced collaborators of the broader Oceanus Folk community?\n\nSailor centric\n\n# Convert tbl_graph to igraph\nig &lt;- as.igraph(music)\n\n# Get index for 'Sailor Shift'\nsailor_idx &lt;- which(V(ig)$name == \"Sailor Shift\")\n\n# Get 1-degree ego from Sailor Shift (as integer indices)\nsailor_ego &lt;- ego(ig, order = 1, nodes = sailor_idx, mode = \"out\")[[1]]\n\nsailor_ego_idx &lt;- as.integer(sailor_ego)\n\n# Get indices for all Oceanus Folk nodes\noceanus_idx &lt;- which(V(ig)$genre == \"Oceanus Folk\")\n\n# Get 1-degree inward ego for each Oceanus Folk node\noceanus_ego_list &lt;- ego(ig, order = 1, nodes = oceanus_idx, mode = \"in\")\n\n# Flatten and convert to integer indices\noceanus_ego_idx &lt;- unique(unlist(lapply(oceanus_ego_list, as.integer)))\n\n# Combine both sets of indices\ncombined_indices &lt;- unique(c(sailor_ego_idx, oceanus_ego_idx))\n\n# Induce subgraph from combined set\nsub_music &lt;- induced_subgraph(ig, vids = combined_indices) %&gt;%\n  as_tbl_graph()\n\n# Convert to igraph for path computation\nig_sub &lt;- as.igraph(sub_music)\n\n# Re-identify Sailor Shift index in subgraph\nsailor_idx_sub &lt;- which(V(ig_sub)$name == \"Sailor Shift\")\n\n# Compute shortest paths *to* Sailor Shift (mode = \"in\")\nsp &lt;- shortest_paths(ig_sub, from = sailor_idx_sub, mode = \"in\", output = \"vpath\")$vpath\n\nWarning in shortest_paths(ig_sub, from = sailor_idx_sub, mode = \"in\", output =\n\"vpath\"): At vendor/cigraph/src/paths/unweighted.c:444 : Couldn't reach some\nvertices.\n\n# Count path dependencies\nnode_names &lt;- V(ig_sub)$name\ndep_score &lt;- sapply(node_names, function(n) {\n  sum(sapply(sp, function(path) {\n    if (length(path) == 0) return(FALSE)\n    n %in% names(path)\n  }))\n})\n\n# Add sailor_dependency to tbl_graph\nsub_music &lt;- sub_music %&gt;%\n  mutate(sailor_dependency = dep_score)\n\n\ng &lt;- sub_music %&gt;%\n  ggraph(layout = \"nicely\") + \n  geom_edge_fan(\n    aes(\n      colour = `Edge Type`,\n      start_cap = circle(1, 'mm'),\n      end_cap = circle(1, 'mm')\n      ),\n    arrow = arrow(length = unit(2, 'mm')),\n    alpha = 0.4\n    ) +\n  geom_point_interactive(\n    aes(\n      x = x,\n      y = y,\n      data_id = name,\n      tooltip = sprintf(\"%s&lt;br/&gt;(%s)\", name, released_year),\n      colour = genre,\n      size = sailor_dependency,\n      shape = `Node Type`\n      ),\n    show.legend = c(size = FALSE)\n    )+ \n  geom_node_text(\n    aes(\n      label = ifelse(`name` == \"Sailor Shift\", \"Sailor Shift\", NA)\n    ),\n    size = 4,\n    colour = 'red',\n    show.legend = FALSE\n    ) +\n  theme_graph() +\n  theme(legend.text = element_text(size = 6),\n        legend.title = element_text(size = 9)) +\n  scale_shape_discrete(name = \"Node Type\")\ng &lt;- g + theme_minimal(base_family = \"sans\")\ngirafe(ggobj = g, width_svg = 11, height_svg = 8)\n\nWarning: Removed 1184 rows containing missing values or values outside the scale range\n(`geom_text()`)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#background",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#background",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "One of music’s biggest superstars is Oceanus native Sailor Shift. From humble beginnings, Sailor has grown in popularity and now enjoys fans around the world. Sailor started her career on the island nation of Oceanus which can be clearly seen in her early work, she started in the genre of “Oceanus Folk”. While Sailor has moved away from the traditional Oceanus style, the Oceanus Folk has made a name for itself in the musical world. The popularity of this music is one of the factors driving an increase in tourism to a quiet island nation that used to be known for fishing.\nIn 2023, Sailor Shift joined the Ivy Echoes – an all-female Oceanus Folk band consisting of Sailor (vocalist), Maya Jensen (vocalist), Lila “Lilly” Hartman (guitarist), Jade Thompson (drummer), and Sophie Ramirez (bassist). They played together at venues throughout Oceanus but had broken up to pursue their individual careers by 2026. Sailor’s breakthrough came in 2028 when one of her singles went viral, launched to the top of the global charts (something no other Oceanus Folk song had ever done). Since then, she has only continued to grow in popularity worldwide.\nSailor has released a new album almost every year since her big break, and each has done better than the last. Although she has remained primarily a solo artist, she has also frequently collaborated with other established artists, especially in the Indie Pop and Indie Folk genres. She herself has branched out musically over the years but regularly returns to the Oceanus Folk genre — even as the genre’s influence on the rest of the music world has spread even more.\nSailor has always been passionate about two things: (1) spreading Oceanus Folk, and (2) helping lesser-known artists break into music. Because of those goals, she’s particularly famous for her frequent collaborations.\nAdditionally, because of Sailor’s success, more attention began to be paid over the years to her previous bandmates. All 4 have continued in the music industry—Maya as an independent vocalist, Lilly and Jade as instrumentalists in other bands, and Sophie as a music producer for a major record label. In various ways, all of them have contributed to the increased influence of Oceanus folk, resulting in a new generation of up-and-coming Oceanus Folk artists seeking to make a name for themselves in the music industry.\nNow, as Sailor returns to Oceanus in 2040, a local journalist – Silas Reed – is writing a piece titled Oceanus Folk: Then-and-Now that aims to trace the rise of Sailor and the influence of Oceanus Folk on the rest of the music world. He has collected a large dataset of musical artists, producers, albums, songs, and influences and organized it into a knowledge graph. Your task is to help Silas create beautiful and informative visualizations of this data and uncover new and interesting information about Sailor’s past, her rise to stardom, and her influence."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#tasks-and-questions",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#tasks-and-questions",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "The objective of this take-home exercise is to address the following tasks and questions of VAST Challenge 2025’s Mini-Challenge 1.\n\nDesign and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career\n\nWho has she been most influenced by over time?\nWho has she collaborated with and directly or indirectly influenced?\nHow has she influenced collaborators of the broader Oceanus Folk community?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#data-overview",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#data-overview",
    "title": "Take-home Exercise 2",
    "section": "2.4 Data Overview",
    "text": "2.4 Data Overview\nBefore proceeding to data pre-processing, we examine the data to gain a clearer understanding of the dataset and to verify the structural integrity of the imported graph.\nIn this code chunk below, ggplot2 functions are used the reveal the frequency distribution of Node Type field of mc1_nodes_raw.\n\nggplot(data = mc1_nodes_raw,\n       aes(y = `Node Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nOn the other hand, code chunk below uses ggplot2 functions to reveal the frequency distribution of Edge Type field of mc1_edges_raw.\n\nggplot(data = mc1_edges_raw,\n       aes(y = `Edge Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#data-pre-processing",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#data-pre-processing",
    "title": "Take-home Exercise 2",
    "section": "3 Data Pre-processing",
    "text": "3 Data Pre-processing\n\n3.1 Adding identifying columns\nAs a large part of this mini-challenge centers around Sailor Shift and the genre of “Oceanus Folk”, the following code chunk will add columns to help with identification and filtering of Sailor Shift and the work in the genre of “Oceanus Folk”. This will help with analysis in addressing the questions and tasks.\n\nmc1_nodes_raw &lt;- mc1_nodes_raw %&gt;%\n  mutate(\n    is_sailor = (\n      str_detect(name, regex(\"sailor shift\", ignore_case = TRUE))\n    ) %&gt;% replace_na(FALSE),\n    \n    is_oceanus_folk = str_detect(genre, regex(\"oceanus folk\", ignore_case = TRUE)) %&gt;% #na/not oceanus folk = false\n      replace_na(FALSE)\n  )\n\n\n\n3.2 Converting date field\nThe following code chunk will convert date fields from chr to int for later analysis. Note that dates only appear for Song and Album.\n\nmc1_nodes_raw &lt;- mc1_nodes_raw %&gt;%\n  mutate(across(c(release_date, notoriety_date, written_date),\n                ~as.integer(if_else(`Node Type` %in% c(\"Song\", \"Album\"), ., NA_character_))))\n\n\n\n3.3 Check for duplicates\n\n3.3.1 Check for duplicates in mc1_nodes_raw\nThe following code chunk checks for id duplicates in mc1_nodes_raw.\n\nmc1_nodes_raw %&gt;%\n  count(id) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: id &lt;int&gt;, n &lt;int&gt;\n\n\nThere are no duplicated id in mc1_nodes_raw.\nThe following code chunk checks for name duplicates in mc1_nodes_raw.\n\nduplicated_name &lt;- mc1_nodes_raw %&gt;%\n  count(name) %&gt;%\n  filter(n &gt; 1)\n\nduplicated_name\n\n# A tibble: 1,611 × 2\n   name                 n\n   &lt;chr&gt;            &lt;int&gt;\n 1 Agata Records        2\n 2 Ancestral Echoes     2\n 3 Angela Thompson      2\n 4 Anthony Davis        2\n 5 Anthony Smith        2\n 6 Asuka Takahashi      3\n 7 Brandon Wilson       2\n 8 Brian Gonzalez       2\n 9 Bryan Garcia         2\n10 Bryan Smith          3\n# ℹ 1,601 more rows\n\n\nThe following code chunk shows all rows from mc1_nodes_raw that have duplicated names, and sorting them alphabetically by the name column. There are a total of 4,953 records with duplicated names in mc1_nodes_raw.\n\nmc1_nodes_raw %&gt;%\n  filter(name %in% duplicated_name$name) %&gt;%\n  arrange(name)\n\n# A tibble: 4,953 × 12\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 RecordLabel Agata Recor… NA               NA &lt;NA&gt;  NA       1528           NA\n 2 RecordLabel Agata Recor… NA               NA &lt;NA&gt;  NA      17388           NA\n 3 Song        Ancestral E… TRUE           1991 Drea… FALSE   11793           NA\n 4 Song        Ancestral E… FALSE          2039 Avan… TRUE    17133           NA\n 5 Person      Angela Thom… NA               NA &lt;NA&gt;  NA       1150           NA\n 6 Person      Angela Thom… NA               NA &lt;NA&gt;  NA      13448           NA\n 7 Person      Anthony Dav… NA               NA &lt;NA&gt;  NA       8692           NA\n 8 Person      Anthony Dav… NA               NA &lt;NA&gt;  NA      12452           NA\n 9 Person      Anthony Smi… NA               NA &lt;NA&gt;  NA       5719           NA\n10 Person      Anthony Smi… NA               NA &lt;NA&gt;  NA       7694           NA\n# ℹ 4,943 more rows\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n\n3.3.2 Fixing duplicates in mc1_nodes_raw\nThe section will focus on fixing the duplicates found in mc1_nodes_raw as identified in section 3.3.1.\nThe following code chunk will tag each row with a unique key (group_key) based on its respective column values. This helps to identify unique records.\n\n# Step 1: Mark all node rows with a hash key for grouping\nmc1_nodes_tagged &lt;- mc1_nodes_raw %&gt;%\n  mutate(group_key = paste(`Node Type`, name, single, release_date, genre,\n                           notable, written_date, notoriety_date, is_sailor,\n                           is_oceanus_folk, sep = \"|\"))\n\nmc1_nodes_tagged\n\n# A tibble: 17,412 × 13\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 Song        Breaking Th… TRUE           2017 Ocea… TRUE        0           NA\n 2 Person      Carlos Duffy NA               NA &lt;NA&gt;  NA          1           NA\n 3 Person      Min Qin      NA               NA &lt;NA&gt;  NA          2           NA\n 4 Person      Xiuying Xie  NA               NA &lt;NA&gt;  NA          3           NA\n 5 RecordLabel Nautical Mi… NA               NA &lt;NA&gt;  NA          4           NA\n 6 Song        Unshackled … FALSE          2026 Lo-F… TRUE        5           NA\n 7 Person      Luke Payne   NA               NA &lt;NA&gt;  NA          6           NA\n 8 Person      Xiulan Zeng  NA               NA &lt;NA&gt;  NA          7           NA\n 9 Person      David Frank… NA               NA &lt;NA&gt;  NA          8           NA\n10 RecordLabel Colline-Cas… NA               NA &lt;NA&gt;  NA          9           NA\n# ℹ 17,402 more rows\n# ℹ 5 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;, group_key &lt;chr&gt;\n\n\nThe code below deduplicates the dataset using group_key, reducing the number of duplicated names from 4,953 to 14. The remaining 14 names appear more than once because their corresponding records differ in at least one column used to form group_key, so they are retained as distinct entries.\n\n# Step 2: Deduplicate and keep the preferred (with stage_name if available)\nmc1_nodes_dedup &lt;- mc1_nodes_tagged %&gt;%\n  group_by(group_key) %&gt;%\n  arrange(desc(!is.na(stage_name))) %&gt;%\n  slice(1) %&gt;%\n  ungroup()\n\nduplicated_name &lt;- mc1_nodes_dedup %&gt;%\n  count(name) %&gt;%\n  filter(n &gt; 1)\n\nmc1_nodes_raw %&gt;%\n  filter(name %in% duplicated_name$name) %&gt;%\n  arrange(name)\n\n# A tibble: 14 × 12\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 Song        Ancestral E… TRUE           1991 Drea… FALSE   11793           NA\n 2 Song        Ancestral E… FALSE          2039 Avan… TRUE    17133           NA\n 3 RecordLabel Coastal Ech… NA               NA &lt;NA&gt;  NA       4022           NA\n 4 Album       Coastal Ech… NA             2023 Psyc… TRUE    15065         2019\n 5 Song        Postcards f… TRUE           2023 Indi… TRUE    12852         2023\n 6 Song        Postcards f… FALSE          1984 Acou… FALSE   17214           NA\n 7 Album       Shattered R… NA             2013 Emo/… TRUE     3325         2013\n 8 Song        Shattered R… FALSE          2036 Dark… TRUE    17088           NA\n 9 Song        Unheard Fre… TRUE           2025 Alte… TRUE     7999           NA\n10 RecordLabel Unheard Fre… NA               NA &lt;NA&gt;  NA      10952           NA\n11 Song        Vanishing P… TRUE           2018 Avan… TRUE     9371         2018\n12 Song        Vanishing P… FALSE          2013 Ocea… FALSE   17338           NA\n13 RecordLabel Vertical Ho… NA               NA &lt;NA&gt;  NA       2453           NA\n14 Album       Vertical Ho… NA             2017 Doom… TRUE     9262           NA\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n\n3.3.3 Check for duplicates in mc1_edges_raw\nThe following code checks for duplicates in mc1_edges_raw.\n\n# Step 1: Identify duplicate combinations\nduplicate_summary &lt;- mc1_edges_raw %&gt;%\n  count(source, target, `Edge Type`) %&gt;%\n  filter(n &gt; 1)\n\n# Step 2: Join back to get all original duplicate rows\nmc1_edges_raw %&gt;%\n  inner_join(duplicate_summary, by = c(\"source\", \"target\", \"Edge Type\"))\n\n# A tibble: 6 × 5\n  `Edge Type` source target   key     n\n  &lt;chr&gt;        &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 PerformerOf  17057  17058     0     2\n2 PerformerOf  17057  17058     1     2\n3 PerformerOf  17349  17350     0     2\n4 PerformerOf  17349  17350     2     2\n5 PerformerOf  17355  17356     0     2\n6 PerformerOf  17355  17356     2     2\n\n\nThere are duplicates as seen above, with only differences in key. As key will not be used in subsequent data analysis, the duplicated edges will be removed with the following code.\n\nmc1_edges_raw &lt;- mc1_edges_raw %&gt;%\n  distinct(source, target, `Edge Type`, .keep_all = TRUE) %&gt;%\n  select(!key)\n\nmc1_edges_raw %&gt;%\n  count(source, target, `Edge Type`) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 4\n# ℹ 4 variables: source &lt;int&gt;, target &lt;int&gt;, Edge Type &lt;chr&gt;, n &lt;int&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#further-eda",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#further-eda",
    "title": "Take-home Exercise 2",
    "section": "4 Further EDA",
    "text": "4 Further EDA\n\n4.1 Explore and inspect Nodes\n\nmc1_nodes_raw$release_date %&gt;% unique()\n\n [1] 2017   NA 2026 2020 2027 2022 2007 2010 2003 2023 1997 2013 2000 2025 2029\n[16] 2015 2018 2016 2014 2028 2021 2030 2011 1994 2004 1998 1991 1999 2024 2012\n[31] 2002 2006 2008 2019 1995 1989 2032 2009 2001 1996 1990 1984 2005 1993 1986\n[46] 1985 1981 1992 1987 1988 1983 2031 1975 2035 2033 2037 2036 2039 2038 2034\n[61] 1977 1979 1980 1982 2040\n\nmc1_nodes_raw %&gt;%\n  filter(grepl(\"Sailor Shift\", name)) #Sailor Shift is in name column and not in stage_name column\n\n# A tibble: 1 × 12\n  `Node Type` name         single release_date genre notable    id written_date\n  &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n1 Person      Sailor Shift NA               NA &lt;NA&gt;  NA      17255           NA\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\nThe following code chunk is used to remove ' from name to prevent issues with tooltip in tidygraph.\n\nmc1_nodes_clean &lt;- mc1_nodes_raw %&gt;%\n  mutate(\n    name = gsub(\"'\", \"\", name)) \n  \nkable(head(mc1_nodes_clean))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type\nname\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\nis_sailor\nis_oceanus_folk\n\n\n\n\nSong\nBreaking These Chains\nTRUE\n2017\nOceanus Folk\nTRUE\n0\nNA\nNA\nNA\nFALSE\nTRUE\n\n\nPerson\nCarlos Duffy\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nPerson\nMin Qin\nNA\nNA\nNA\nNA\n2\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nPerson\nXiuying Xie\nNA\nNA\nNA\nNA\n3\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nRecordLabel\nNautical Mile Records\nNA\nNA\nNA\nNA\n4\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nSong\nUnshackled Heart\nFALSE\n2026\nLo-Fi Electronica\nTRUE\n5\nNA\nNA\nNA\nFALSE\nFALSE\n\n\n\n\n\n\n\n4.2 Explore and inspect Edges\nThe following code chunk is used to ensure that id used in mc1_edges_raw matches the range range of id in mc1_nodes_clean.\n\nrange(mc1_nodes_clean$id)\n\n[1]     0 17411\n\nrange(mc1_edges_raw$source)\n\n[1]     0 17411\n\nrange(mc1_edges_raw$target)\n\n[1]     0 17411\n\n\n\n\n4.3 Mapping Node name to Edges id\ntidygraph uses from and to columns to reference nodes. By default, tidygraph matches these edges reference against the first column in the nodes table, or against name column.\nCurrently, source and target columns in mc1_edges_raw contain id values that correspond to the id column in mc1_nodes_clean. To properly integrate with tidygraph’s conventions, the following will be done:\n\nRestructure mc1_nodes_clean\n\nRename the current name column to node_name - this is done to preserve the actual node names\nRename the id column to name so it becomes the primary identifier column that tidygraph will use for matching\n\nRename source and target columns in mc1_edges_raw, as required by tidygraph\nEnsure data type consistency: Convert the name column (formerly id) to character format to match the data type of the edge references\n\n\nmc1_nodes_clean &lt;- mc1_nodes_dedup %&gt;%\n  rename(node_name = name, name = id) %&gt;%\n  mutate(name = as.character(name)) %&gt;%\n  select(`Node Type`, node_name, release_date, genre, notable, name, single, written_date, stage_name, notoriety_date, is_sailor, is_oceanus_folk)\n\nmc1_nodes_clean\n\n# A tibble: 14,077 × 12\n   `Node Type` node_name    release_date genre notable name  single written_date\n   &lt;chr&gt;       &lt;chr&gt;               &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;chr&gt; &lt;lgl&gt;         &lt;int&gt;\n 1 Album       A Lush Dyst…         2031 Psyc… TRUE    17005 NA             2030\n 2 Album       Addicted to…         2004 Sout… TRUE    14658 NA             2000\n 3 Album       Adriatic Em…         2013 Post… TRUE    10412 NA               NA\n 4 Album       Aerial Echo…         2023 Indi… TRUE    7908  NA               NA\n 5 Album       Aftershock …         2028 Drea… TRUE    2030  NA             2021\n 6 Album       Allegretto …         2020 Indi… TRUE    6251  NA               NA\n 7 Album       Alleys and …         2029 Jazz… TRUE    1310  NA               NA\n 8 Album       Alloy Archi…         2017 Indi… TRUE    8428  NA             2017\n 9 Album       Almost (But…         2027 Alte… TRUE    14611 NA             2027\n10 Album       Altar of De…         2020 Ocea… TRUE    5883  NA               NA\n# ℹ 14,067 more rows\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n4.3.1 Creating edge mapping from old id to kept id\nIn section 3.3.2, duplicated nodes were deduplicated and removed, edges referring to the removed nodes will become invalid thus, edges will be remapped to the retained nodes. This ensures that all edges correctly point to existing nodes in the deduplicated graph.\n\n# Step 1: Create mapping of all group_key → kept id\nkey_to_id_map &lt;- mc1_nodes_dedup %&gt;%\n  select(group_key, kept_id = id)\n\n# Step 2: Map all original rows to the retained ID\nid_remap &lt;- mc1_nodes_tagged %&gt;%\n  left_join(key_to_id_map, by = \"group_key\") %&gt;%\n  select(original_id = id, kept_id)\n\nid_remap\n\n# A tibble: 17,412 × 2\n   original_id kept_id\n         &lt;int&gt;   &lt;int&gt;\n 1           0       0\n 2           1       1\n 3           2   14470\n 4           3       3\n 5           4       4\n 6           5       5\n 7           6       6\n 8           7       7\n 9           8       8\n10           9       9\n# ℹ 17,402 more rows\n\n\n\n# Step 3: Replace edges' source and target with mapped kept_id\nmc1_edges_mapped &lt;- mc1_edges_raw %&gt;%\n  left_join(id_remap, by = c(\"source\" = \"original_id\"))\n\nmc1_edges_mapped\n\n# A tibble: 37,854 × 4\n   `Edge Type`      source target kept_id\n   &lt;chr&gt;             &lt;int&gt;  &lt;int&gt;   &lt;int&gt;\n 1 InterpolatesFrom      0   1841       0\n 2 RecordedBy            0      4       0\n 3 PerformerOf           1      0       1\n 4 ComposerOf            1  16180       1\n 5 PerformerOf           2      0   14470\n 6 ProducerOf            2  16180   14470\n 7 PerformerOf           3      0       3\n 8 InterpolatesFrom      5   5088       5\n 9 InStyleOf             5  14332       5\n10 InterpolatesFrom      5  11677       5\n# ℹ 37,844 more rows\n\n\n\nmc1_edges_mapped &lt;- mc1_edges_mapped %&gt;%\n  mutate(source = kept_id) %&gt;%\n  select(-kept_id) %&gt;%\n  left_join(id_remap, by = c(\"target\" = \"original_id\")) %&gt;%\n  mutate(target = kept_id) %&gt;%\n  select(-kept_id) %&gt;%\n  rename(from = source, to = target) %&gt;%\n  mutate(from = as.character(from), to = as.character(to))\n\nmc1_edges_mapped\n\n# A tibble: 37,854 × 3\n   `Edge Type`      from  to   \n   &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;\n 1 InterpolatesFrom 0     1841 \n 2 RecordedBy       0     4    \n 3 PerformerOf      1     0    \n 4 ComposerOf       1     16180\n 5 PerformerOf      14470 0    \n 6 ProducerOf       14470 16180\n 7 PerformerOf      3     0    \n 8 InterpolatesFrom 5     5088 \n 9 InStyleOf        5     14332\n10 InterpolatesFrom 5     11677\n# ℹ 37,844 more rows\n\n\n\n\n\n4.4 Remove unmatched edges\nThe following code chunk removes edges that reference missing node id, ensuring that only valid edges are kept.\n\nmc1_edges_clean &lt;- mc1_edges_mapped %&gt;%\n  filter(!is.na(from), !is.na(to))\n\nThere are no unmatched edges.\n\n\n4.5 Check for missing nodes\nThe following code chunk checks for missing nodes being referenced in mc1_edges_clean that do not exist in mc1_nodes_clean.\n\nsetdiff(\n  unique(c(mc1_edges_clean$from, mc1_edges_clean$to)),\n  mc1_nodes_clean$name\n)\n\ncharacter(0)\n\n\nThere are no missing nodes.\n\n\n4.6 Validate Edges Schema\nThis section aims to ensure that each edge in the graph adheres to the schema specified in the VAST Challenge 2025 MC1 Data Description document. The following code checks whether the node types connect by each edge matches the valid source and target types for that edge’s type.\n\n# Define valid source and destination types for each edge type\nedge_rules &lt;- list(\n  PerformerOf = list(source = c(\"Person\", \"MusicalGroup\"), target = c(\"Song\", \"Album\")),\n  ComposerOf = list(source = c(\"Person\"), target = c(\"Song\", \"Album\")),\n  ProducerOf = list(source = c(\"Person\", \"RecordLabel\"), target = c(\"Song\", \"Album\", \"Person\", \"MusicalGroup\")),\n  LyricistOf = list(source = c(\"Person\"), target = c(\"Song\", \"Album\")),\n  RecordedBy = list(source = c(\"Song\", \"Album\"), target = c(\"RecordLabel\")),\n  DistributedBy = list(source = c(\"Song\", \"Album\"), target = c(\"RecordLabel\")),\n  InStyleOf = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\", \"Person\", \"MusicalGroup\")),\n  InterpolatesFrom = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  CoverOf = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  LyricalReferenceTo = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  DirectlySamples = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  MemberOf = list(source = c(\"Person\"), target = c(\"MusicalGroup\"))\n)\n\nThe following code chunk checks for any erroneous edge and node relationships defined in the code chunk above.\n\n# Create a lookup for node types\nnode_type_lookup &lt;- mc1_nodes_clean %&gt;%\n  select(name, `Node Type`) %&gt;%\n  deframe()\n\n# Add source and target node types to the edge table\nmc1_edges_checked &lt;- mc1_edges_clean %&gt;%\n  mutate(\n    source_type = node_type_lookup[from],\n    target_type = node_type_lookup[to]\n  )\n\nmc1_edges_tagged &lt;- mc1_edges_checked %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    valid = {\n      rule &lt;- edge_rules[[`Edge Type`]]\n      if (is.null(rule)) TRUE\n      else {\n        source_type %in% rule$source && target_type %in% rule$target\n      }\n    }\n  ) %&gt;%\n  ungroup()\n\n# Count and display invalid edge combinations\ninvalid_edge_summary &lt;- mc1_edges_tagged %&gt;%\n  filter(!valid) %&gt;%\n  count(`Edge Type`, source_type, target_type, sort = TRUE)\n\nprint(invalid_edge_summary)\n\n# A tibble: 24 × 4\n   `Edge Type`      source_type  target_type      n\n   &lt;chr&gt;            &lt;chr&gt;        &lt;chr&gt;        &lt;int&gt;\n 1 LyricistOf       MusicalGroup Song           106\n 2 RecordedBy       RecordLabel  Album          102\n 3 ProducerOf       MusicalGroup Song           100\n 4 ComposerOf       MusicalGroup Song            97\n 5 ProducerOf       MusicalGroup Album           31\n 6 LyricistOf       MusicalGroup Album           28\n 7 ComposerOf       MusicalGroup Album           17\n 8 InStyleOf        MusicalGroup MusicalGroup    12\n 9 InStyleOf        Person       MusicalGroup    11\n10 InterpolatesFrom MusicalGroup MusicalGroup    10\n# ℹ 14 more rows\n\n\n\n# Check total invalid edge count\ncat(\"Total invalid edges:\", sum(!mc1_edges_tagged$valid), \"\\n\")\n\nTotal invalid edges: 550 \n\n\nThere are 550 edges that do not adhere to the schema specified in the data description file provided. The following code will remove these edges.\n\n# Keep only valid edges\nmc1_edges_clean &lt;- mc1_edges_tagged %&gt;%\n  filter(valid) %&gt;%\n  select(from, to, `Edge Type`)  # drop helper columns\n\n\n\n4.7 Visualising Edge and Node types\n\nggplot(data = mc1_edges_clean,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = mc1_nodes_clean,\n       aes(y = `Node Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n4.8 Creating knowledge graph\ntbl_graph() is used to create tidygraph’s graph object by using the following code chunk.\n\nmusic = tbl_graph(edges = mc1_edges_clean,\n                             nodes = mc1_nodes_clean,\n                             directed = TRUE)\n\nclass(music)\n\n[1] \"tbl_graph\" \"igraph\"   \n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#vast-challenge-2025-mini-challenge-1",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#vast-challenge-2025-mini-challenge-1",
    "title": "Take-home Exercise 2",
    "section": "5 VAST Challenge 2025 Mini-Challenge 1",
    "text": "5 VAST Challenge 2025 Mini-Challenge 1\nFor Task 1, it is to design and develop visualizations and visual analytic tools that will allow Silas to explore and understand the profile of Sailor Shift’s career. We start off with a network visualisation to provide an overview of Sailor Shift’s works throughout her career, as well as the various roles she played in these works.\n\nNetwork VisualisationRole Summary\n\n\n\n\nCode\n# Step 1: Identify Sailor Shift using the is_sailor column\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor) %&gt;%\n  pull(name) %&gt;%\n  first()\n\n# Step 2: Prepare edges and nodes related to Sailor Shift\nsailor_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name | to == sailor_vertex_name)\n\nsailor_node_names &lt;- unique(c(sailor_edges$from, sailor_edges$to))\n\nsailor_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_node_names) %&gt;%\n  distinct(name, .keep_all = TRUE)\n\n# Step 3: Build tbl_graph object and annotate nodes\ncareer_graph &lt;- tbl_graph(nodes = sailor_nodes, edges = sailor_edges, directed = TRUE) %&gt;%\n  activate(nodes) %&gt;%\n  mutate(\n    node_color = ifelse(is_sailor, \"red\", \"grey30\"),\n    tooltip_text = paste0(\n      \"Name: \", node_name, \"\\n\",\n      \"Type: \", `Node Type`, \"\\n\",\n      ifelse(!is.na(genre), paste0(\"Genre: \", genre, \"\\n\"), \"\"),\n      ifelse(!is.na(release_date), paste0(\"Release: \", release_date, \"\\n\"), \"\")\n    )\n  )\n\n# Step 4: Extract layout coordinates\nlayout_df &lt;- create_layout(career_graph, layout = \"fr\") %&gt;%\n  as_tibble() %&gt;%\n  select(name, x, y)\n\nnodes_plot &lt;- career_graph %&gt;%\n  as_tibble() %&gt;%\n  left_join(layout_df, by = \"name\")\n\nedges_plot &lt;- sailor_edges %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n  rename(x_from = x, y_from = y) %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n  rename(x_to = x, y_to = y)\n\n# Get Sailor Shift node coordinates for annotation\nsailor_coords &lt;- nodes_plot %&gt;%\n  filter(is_sailor) %&gt;%\n  select(x, y)\n\n# Step 5: Plot with ggiraph\np &lt;- ggplot() +\n  # Edge layer with its own color scale\n  geom_segment(\n    data = edges_plot,\n    aes(\n      x = x_from, y = y_from, xend = x_to, yend = y_to,\n      color = `Edge Type`\n    ),\n    alpha = 0.4, arrow = arrow(length = unit(3, 'mm'))\n  ) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Edge Type\") +\n\n  # New color scale for nodes\n  ggnewscale::new_scale_color() +\n\n  geom_point_interactive(\n    data = nodes_plot,\n    aes(\n      x = x, y = y,\n      tooltip = tooltip_text,\n      data_id = name,\n      color = node_color,\n      shape = `Node Type`\n    ),\n    size = 4\n  ) +\n  scale_color_manual(\n    values = c(\"red\" = \"red\", \"grey30\" = \"grey30\")\n  ) +\n  guides(color = \"none\") +  # Remove node color legend\n\n  # Add Sailor Shift label in the middle of the graph\n  geom_text(\n    data = sailor_coords,\n    aes(x = x, y = y, label = \"Sailor Shift\"),\n    size = 6, fontface = \"bold\", color = \"red\", vjust = -1\n  ) +\n\n  theme_void() +\n  labs(title = \"Sailor Shift's Career Profile\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\")\n  )\n\ngirafe(ggobj = p, width_svg = 10, height_svg = 8)\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter edges related to Sailor Shift\nsailor_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name | to == sailor_vertex_name)\n\n# Count edges by Edge Type\nedge_counts &lt;- sailor_edges %&gt;%\n  count(`Edge Type`) %&gt;%\n  arrange(desc(n))\n\n# Display as a simple table\nkable(edge_counts, col.names = c(\"Role (Edge Type)\", \"Count\"), caption = \"Sailor Shift's Career Roles\")\n\n\n\nSailor Shift’s Career Roles\n\n\nRole (Edge Type)\nCount\n\n\n\n\nPerformerOf\n26\n\n\nLyricistOf\n21\n\n\nMemberOf\n1\n\n\nProducerOf\n1\n\n\n\n\n\n\n\n\nBased on the above, Sailor Shift is primarily a performer and lyricist, and a member of Ivy Echos, a musical group. It also shows that Oceanic Records, a Record label, has participated in the production of her works.\n\n5.1 Question 1a - Who has she been most influenced by over time?\nThe network structure below shows how Sailor Shift’s career has been influenced by others. PageRank is used to measure the overall influence of each person, musical group or work within the network. This captures both direct and indirect influences.\n\nNetwork VisualisationInfluence Summary\n\n\n\n\nCode\n# Step 0: Get name of 'Sailor Shift'\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;%\n  first()\n\n# Step 1: Find direct influence relationships from Sailor Shift\n# These are the artists/works that Sailor Shift has been influenced by\ndirect_influence_types &lt;- c(\"InStyleOf\", \"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\")\n\nsailor_direct_influences &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name, \n         `Edge Type` %in% direct_influence_types)\n\n# Step 2: Get immediate neighbors (people/groups Sailor Shift works with)\nsailor_out_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name)\n\nsailor_out_node_names &lt;- sailor_out_edges$to\n\n# Step 3: Split into people/groups vs songs/albums\nsailor_person_group &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_out_node_names, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\nsailor_songs_all &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_out_node_names, `Node Type` %in% c(\"Song\", \"Album\")) %&gt;%\n  pull(name)\n\n# Step 4: For songs/albums, find their direct influences too\nsong_influences &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs_all, \n         `Edge Type` %in% direct_influence_types)\n\n# Step 5: Get all influence targets (who influenced Sailor Shift or their works)\nall_influence_targets &lt;- unique(c(\n  sailor_direct_influences$to,\n  song_influences$to\n))\n\n# Step 6: Get creators of Sailor Shift's works (indirect influence indicators)\ncreator_edge_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\")\n\nsailor_songs &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs_all) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\nsailor_songs_out_nodes &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs) %&gt;%\n  pull(to)\n\ncreator_edges &lt;- mc1_edges_clean %&gt;%\n  filter(to %in% sailor_songs_out_nodes, `Edge Type` %in% creator_edge_types)\n\nsailor_people_group_neighbourhood_nodes &lt;- creator_edges %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 7: Combine all relevant nodes for subgraph\nsailor_all_node_names &lt;- unique(c(\n  sailor_vertex_name,\n  sailor_person_group,\n  sailor_songs,\n  sailor_songs_out_nodes,\n  sailor_people_group_neighbourhood_nodes,\n  all_influence_targets  \n))\n\n# Step 8: Create subgraph\nsub_music &lt;- music %&gt;%\n  filter(name %in% sailor_all_node_names)\n\n# Step 9: Calculate PageRank \nsub_music &lt;- sub_music %&gt;%\n  activate(nodes) %&gt;%\n  mutate(\n    pagerank = centrality_pagerank()\n  )\n\n# Step 10: Set node size based on PageRank for people/groups, fixed for others\nsub_music &lt;- sub_music %&gt;%\n  mutate(\n    is_sailor = name == sailor_vertex_name,\n    node_color = ifelse(is_sailor, \"red\", \"grey30\"),\n    tooltip_text = sprintf(\n      \"Name: %s\\nType: %s\\nPageRank: %.4f\",\n      node_name, `Node Type`, pagerank\n    ),\n    node_size = case_when(\n      `Node Type` %in% c(\"Person\", \"MusicalGroup\") ~ rescale(pagerank, to = c(4, 20)),\n      TRUE ~ 4  \n    )\n  )\n\n# Step 11: Create visualization\ng &lt;- sub_music %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(\n    aes(color = `Edge Type`), \n    alpha = 0.3,\n    arrow = arrow(length = unit(3, 'mm')),\n    end_cap = circle(3, 'mm')\n  ) +\n  geom_point_interactive(\n    aes(\n      x = x, y = y,\n      data_id = name,\n      tooltip = tooltip_text,\n      shape = `Node Type`,\n      colour = node_color,\n      size = node_size\n    )\n  ) +\n  scale_shape_discrete(name = \"Node Type\") +\n  scale_colour_identity() +\n  scale_size_identity() +\n  theme_graph(base_family = \"sans\") +\n  labs(\n    title = \"Network of Influences on Sailor Shift\"\n  )\n\ngirafe(ggobj = g, width_svg = 10, height_svg = 8)\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to people and groups only, exclude Sailor Shift node itself\ntop_influencers &lt;- sub_music %&gt;%\n  as_tibble() %&gt;%\n  filter(\n    `Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n    name != sailor_vertex_name\n  ) %&gt;%\n  arrange(desc(pagerank)) %&gt;%\n  slice_head(n = 5)\n\n# Plot\nggplot(top_influencers, aes(x = reorder(node_name, pagerank), y = pagerank, fill = `Node Type`)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    title = \"Top 5 Influences on Sailor Shift\",\n    x = \"Influencer\",\n    y = \"PageRank Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2 Question 1b - Who has she collaborated with and directly or indirectly influenced?\nThe network visualisation below highlights the people and musical groups who have collaborated with Sailor Shift through her musical works, as well as the broader influence of her group, Ivy Echos. While Sailor Shift herself does not have any documented direct influence connections, the visualisation reveals that Ivy Echos has influenced several other people and group, this illustrates the extended impact of Sailor Shift’s musical network.\n\n\nCode\n# Step 1: Define all relevant edge types per schema\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\ninfluence_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\n# Step 2: Get Sailor Shift's node ID\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;% first()\n\n# Step 3: Find all Sailor Shift's works (songs/albums she performed or was lyricist of)\nsailor_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% c(\"PerformerOf\", \"LyricistOf\"), from == sailor_vertex_name) %&gt;%\n  pull(to)\n\n# Step 4: Find all Person/MusicalGroup collaborated on Sailor Shift's works (excluding herself)\nsailor_collab_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, to %in% sailor_works, from != sailor_vertex_name)\nsailor_collab_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_collab_edges$from, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\n# Step 5: Get Ivy Echos's node ID and works\nivy_echos_name &lt;- mc1_nodes_clean %&gt;%\n  filter(str_detect(node_name, regex(\"Ivy Echos\", ignore_case = TRUE))) %&gt;%\n  pull(name) %&gt;% first()\nivy_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` == \"PerformerOf\", from == ivy_echos_name) %&gt;%\n  pull(to)\nivy_works &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% ivy_works, `Node Type` %in% c(\"Song\", \"Album\")) %&gt;%\n  pull(name)\n\n# Step 6: Find all works influenced by Ivy Echos's works (Ivy Echos's works as destination of influence edges)\nivy_influenced_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_types, to %in% ivy_works)\nivy_influenced_works &lt;- ivy_influenced_edges$from\n\n# Step 7: For each influenced work, get the people/groups involved (collaborators on those works)\nivy_influenced_collab_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, to %in% ivy_influenced_works)\nivy_influenced_collab_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% ivy_influenced_collab_edges$from, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\n# Step 8: Collect all relevant nodes and edges for the network\nall_relevant_nodes &lt;- unique(c(\n  sailor_vertex_name,\n  sailor_collab_nodes,\n  sailor_works,\n  ivy_echos_name,\n  ivy_works,\n  ivy_influenced_works,\n  ivy_influenced_collab_nodes\n))\n\nall_relevant_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% all_relevant_nodes & to %in% all_relevant_nodes)\n\n# Step 9: Annotate node roles for plotting\nsub_nodes_df &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% all_relevant_nodes) %&gt;%\n  mutate(\n    node_role = case_when(\n      name == sailor_vertex_name ~ \"Sailor Shift\",\n      name == ivy_echos_name ~ \"Ivy Echos\",\n      name %in% sailor_collab_nodes ~ \"Sailor Shift Collaborator\",\n      name %in% sailor_works ~ \"Sailor Shift Work\",\n      name %in% ivy_works ~ \"Ivy Echos Work\",\n      name %in% ivy_influenced_works ~ \"Work Influenced by Ivy Echos\",\n      name %in% ivy_influenced_collab_nodes ~ \"Person/Group in Influenced Work\",\n      TRUE ~ \"Other\"\n    ),\n    node_color = case_when(\n      node_role == \"Sailor Shift\" ~ \"red\",\n      node_role == \"Ivy Echos\" ~ \"purple\",\n      node_role == \"Sailor Shift Collaborator\" ~ \"blue\",\n      node_role == \"Sailor Shift Work\" ~ \"grey30\",\n      node_role == \"Ivy Echos Work\" ~ \"green\",\n      node_role == \"Work Influenced by Ivy Echos\" ~ \"orange\",\n      node_role == \"Person/Group in Influenced Work\" ~ \"pink\",\n      TRUE ~ \"steelblue\"\n    ),\n    tooltip_text = paste0(\n      \"Name: \", node_name, \"\\n\",\n      \"Type: \", `Node Type`, \"\\n\",\n      \"Role: \", node_role, \"\\n\",\n      ifelse(!is.na(genre), paste0(\"Genre: \", genre, \"\\n\"), \"\"),\n      ifelse(!is.na(release_date), paste0(\"Release: \", release_date, \"\\n\"), \"\")\n    )\n  )\n\n# Step 10: Create tidygraph object and layout\ncareer_graph &lt;- tbl_graph(nodes = sub_nodes_df, edges = all_relevant_edges, directed = TRUE) %&gt;%\n  activate(nodes)\n\nlayout_df &lt;- create_layout(career_graph, layout = \"fr\") %&gt;%\n  as_tibble() %&gt;%\n  select(name, x, y)\n\nnodes_plot &lt;- as_tibble(career_graph) %&gt;%\n  left_join(layout_df, by = \"name\")\n\nedges_plot &lt;- all_relevant_edges %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n  rename(x_from = x, y_from = y) %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n  rename(x_to = x, y_to = y)\n\n# Step 11: Get coordinates for annotation\nsailor_coords &lt;- nodes_plot %&gt;%\n  filter(name == sailor_vertex_name) %&gt;%\n  select(x, y)\nivy_coords &lt;- nodes_plot %&gt;%\n  filter(name == ivy_echos_name) %&gt;%\n  select(x, y)\n\n# Step 12: Plot with ggplot2 + ggiraph, with annotation and legend\np &lt;- ggplot() +\n  geom_segment(\n    data = edges_plot,\n    aes(\n      x = x_from, y = y_from, xend = x_to, yend = y_to,\n      color = `Edge Type`\n    ),\n    alpha = 0.4, arrow = arrow(length = unit(3, 'mm'))\n  ) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Edge Type\") +\n  ggnewscale::new_scale_color() +\n  geom_point_interactive(\n    data = nodes_plot,\n    aes(\n      x = x, y = y,\n      tooltip = tooltip_text,\n      data_id = name,\n      color = node_role,  # Changed from node_color to node_role for legend\n      shape = `Node Type`\n    ),\n    size = 4\n  ) +\n  scale_color_manual(\n    name = \"Node Role\",\n    values = c(\n      \"Sailor Shift\" = \"red\",\n      \"Ivy Echos\" = \"purple\", \n      \"Sailor Shift Collaborator\" = \"blue\",\n      \"Sailor Shift Work\" = \"grey30\",\n      \"Ivy Echos Work\" = \"green\",\n      \"Work Influenced by Ivy Echos\" = \"orange\",\n      \"Person/Group in Influenced Work\" = \"pink\",\n      \"Other\" = \"steelblue\"\n    ),\n    breaks = c(\n      \"Sailor Shift\",\n      \"Ivy Echos\", \n      \"Sailor Shift Collaborator\",\n      \"Sailor Shift Work\",\n      \"Ivy Echos Work\",\n      \"Work Influenced by Ivy Echos\",\n      \"Person/Group in Influenced Work\"\n    )\n  ) +\n  theme_void() +\n  labs(title = \"Sailor Shift's Collaborators and Influence\") +\n  guides(\n    color = guide_legend(\n      title = \"Node Role\",\n      override.aes = list(size = 4),\n      title.position = \"top\"\n    ),\n    shape = guide_legend(\n      title = \"Node Type\",\n      title.position = \"top\"\n    )\n  ) +\n  theme(\n    legend.position = \"right\",\n    legend.box = \"vertical\",\n    plot.title = element_text(size = 20, face = \"bold\") \n  )\n\ngirafe(ggobj = p, width_svg = 12, height_svg = 8)\n\n\n\n\n\n\n\n\n5.3 Question 1c - How has she influenced collaborators of the broader Oceanus Folk community?\nThe network visualisation aims to analyse how Sailor Shift influenced collaborators of the broader Oceanus Folk community.\nSailor Shift and her group (Ivy Echos) were primary entities of interest, all works associated to them are compiled to form the foundation of Sailor Shift’s musical output. Based on this, several types of influence were analysed:\n\nDirect influence - This includes Oceanus Folk collaborators’ works that were explicity influenced by Sailor Shift or Ivy Echos through relationships such as CoverOf, InterpolatesFrom, LyricalReferenceTo, DirectlySamples, and InStyleOf.\nIndirect (two-step influence) - This occurs when a work by Sailor Shift or Ivy Echos influences an intermediate piece, which then goes on to influence a work by an Oceanus Folk collaborator. These two-step chains shows how Sailor Shift’s influence can propagate through the network.\nCross-collaborator influence - This captures intra-community influence where Oceanus Folk works that were initially influenced by Sailor Shift proceeded to influence other Oceanus Folk creations.\nCollaborated-mediated influence - This is transmitted through shared or bridge collaborators.\n\nShared collaborators are individuals or groups who worked with both Sailor Shift/Ivy Echos and the Oceanus Folk community\nBridge Collaborators are those who first worked with Sailor Shift/Ivy Echos and later collaborated with Ocean Folk Contributors.\n\n\nBased on the influences above, it reveals the full extent of Sailor Shift’s reach within the Oceanus Folk Community.\n\n\nCode\n# Step 1: Define edge types\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\ninfluence_edge_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\n# Step 2: Identify all nodes with genre == \"Oceanus Folk\"\noceanus_folk_works &lt;- mc1_nodes_clean %&gt;%\n  filter(genre == \"Oceanus Folk\") %&gt;%\n  pull(name)\n\n# Step 3: Identify all Person and MusicalGroup who are collaborators on Oceanus Folk works\noceanus_folk_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         to %in% oceanus_folk_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 4: Get Sailor Shift and Ivy Echos\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;% \n  first()\n\nivy_echos_name &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` == \"MemberOf\", from == sailor_vertex_name) %&gt;%\n  pull(to) %&gt;%\n  first()\n\n# Step 5: Find all works that Sailor Shift and Ivy Echos have created/performed\nsailor_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, from == sailor_vertex_name) %&gt;%\n  pull(to)\n\nivy_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, from == ivy_echos_name) %&gt;%\n  pull(to)\n\nsailor_ivy_works &lt;- unique(c(sailor_works, ivy_works))\n\n# Step 6: Find all works that the Oceanus Folk collaborators have worked on\noceanus_collaborator_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         from %in% oceanus_folk_collaborators) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\n# Step 7: Direct influence - Sailor Shift/Ivy Echos works influencing Oceanus collaborator works\ndirect_influence &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works,\n         to %in% oceanus_collaborator_works) %&gt;%\n  mutate(influence_direction = \"Sailor/Ivy → Oceanus\",\n         pathway_type = \"Direct\")\n\n# Step 8: Indirect influence - Multi-step pathways\n\n# 8a: Find intermediate works that could bridge Sailor Shift/Ivy Echos to Oceanus\n# Works influenced BY Sailor/Ivy\nsailor_influenced_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\n# Works that influence Sailor/Ivy  \nsailor_influencing_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         to %in% sailor_ivy_works) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# All intermediate works in potential pathways\nintermediate_works &lt;- unique(c(sailor_influenced_works, sailor_influencing_works))\n\n# 8b: Two-step influence: Sailor/Ivy → Intermediate → Oceanus collaborators\nindirect_influence_step1 &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works,\n         to %in% intermediate_works) %&gt;%\n  select(sailor_work = from, intermediate_work = to, step1_edge_type = `Edge Type`)\n\nindirect_influence_step2 &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% intermediate_works,\n         to %in% oceanus_collaborator_works) %&gt;%\n  select(intermediate_work = from, oceanus_work = to, step2_edge_type = `Edge Type`)\n\n# Join to find complete 2-step pathways\ntwo_step_pathways &lt;- indirect_influence_step1 %&gt;%\n  inner_join(indirect_influence_step2, by = \"intermediate_work\") %&gt;%\n  mutate(pathway_type = \"Indirect (2-step)\",\n         influence_direction = \"Sailor/Ivy → Intermediate → Oceanus\")\n\n# 8c: Cross-collaborator influence within Oceanus community\n# Find Oceanus works that were influenced by Sailor and then influenced other Oceanus works\ndirectly_influenced_oceanus_works &lt;- unique(c(direct_influence$to, two_step_pathways$oceanus_work))\n\ncross_collab_influence &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% directly_influenced_oceanus_works,\n         to %in% oceanus_collaborator_works,\n         from != to) %&gt;%\n  mutate(pathway_type = \"Cross-collaborator\",\n         influence_direction = \"Sailor-influenced Oceanus work → Other Oceanus work\")\n\n# Step 9: Collaboration-mediated influence \n\n# 9a: People who worked with both Sailor/Ivy AND Oceanus Folk collaborators\nsailor_ivy_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         to %in% sailor_ivy_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\nshared_collaborators &lt;- intersect(sailor_ivy_collaborators, oceanus_folk_collaborators)\n\n# 9b. Bridge collaborators - worked with Sailor/Ivy, then later with other Oceanus Folk collaborators\nbridge_collaborators &lt;- setdiff(sailor_ivy_collaborators, oceanus_folk_collaborators)\nbridge_to_oceanus &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         from %in% bridge_collaborators) %&gt;%\n  inner_join(\n    mc1_edges_clean %&gt;%\n      filter(`Edge Type` %in% collab_credit_types,\n             from %in% oceanus_folk_collaborators) %&gt;%\n      select(shared_work = to),\n    by = c(\"to\" = \"shared_work\")\n  ) %&gt;%\n  select(bridge_person = from, shared_work = to) %&gt;%\n  distinct()\n\n# Step 10: Identify influenced Oceanus Folk Collaborators \n\n# Get all works that show influence from Sailor/Ivy\nall_influenced_oceanus_works &lt;- unique(c(\n  direct_influence$to,\n  two_step_pathways$oceanus_work,\n  cross_collab_influence$to\n))\n\n# Find which Oceanus Folk collaborators worked on these influenced works\ndirectly_influenced_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         to %in% all_influenced_oceanus_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n         from %in% oceanus_folk_collaborators) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Add collaborators connected through shared/bridge relationships\ncollaboration_influenced &lt;- unique(c(shared_collaborators, bridge_to_oceanus$bridge_person))\ncollaboration_influenced &lt;- intersect(collaboration_influenced, oceanus_folk_collaborators)\n\ntotal_influenced_collaborators &lt;- unique(c(directly_influenced_collaborators, collaboration_influenced))\n\n# Step 11: ENHANCED NETWORK VISUALIZATION (if there are influences to show)\nif(length(total_influenced_collaborators) &gt; 0) {\n  \n  # Collect all relevant nodes for visualization\n  all_pathway_works &lt;- unique(c(\n    sailor_ivy_works,\n    direct_influence$from, direct_influence$to,\n    two_step_pathways$sailor_work, two_step_pathways$intermediate_work, two_step_pathways$oceanus_work,\n    cross_collab_influence$from, cross_collab_influence$to\n  ))\n  \n  all_relevant_people &lt;- unique(c(\n    sailor_vertex_name,\n    ivy_echos_name,\n    total_influenced_collaborators,\n    shared_collaborators,\n    bridge_to_oceanus$bridge_person\n  ))\n  \n  all_viz_nodes &lt;- unique(c(all_pathway_works, all_relevant_people))\n  \n  # Enhanced node classification\n  viz_nodes &lt;- mc1_nodes_clean %&gt;%\n    filter(name %in% all_viz_nodes) %&gt;%\n    mutate(\n      influence_strength = case_when(\n        name %in% direct_influence$to ~ \"Direct Target\",\n        name %in% two_step_pathways$oceanus_work ~ \"Indirect Target\", \n        name %in% cross_collab_influence$to ~ \"Secondary Target\",\n        name %in% shared_collaborators ~ \"Shared Collaborator\",\n        name %in% bridge_to_oceanus$bridge_person ~ \"Bridge Collaborator\",\n        TRUE ~ \"Network Node\"\n      ),\n      node_role = case_when(\n        name == sailor_vertex_name ~ \"Sailor Shift\",\n        name == ivy_echos_name ~ \"Ivy Echos\",\n        name %in% sailor_ivy_works ~ \"Sailor/Ivy Work\",\n        name %in% oceanus_folk_works ~ \"Oceanus Folk Work\",\n        name %in% total_influenced_collaborators ~ \"Influenced Oceanus Collaborator\",\n        name %in% oceanus_folk_collaborators ~ \"Other Oceanus Collaborator\",\n        name %in% intermediate_works ~ \"Intermediate Work\",\n        TRUE ~ \"Other\"\n      ),\n      node_color = case_when(\n        node_role == \"Sailor Shift\" ~ \"red\",\n        node_role == \"Ivy Echos\" ~ \"purple\", \n        node_role == \"Sailor/Ivy Work\" ~ \"gray30\",\n        influence_strength == \"Direct Target\" ~ \"darkred\",\n        influence_strength == \"Indirect Target\" ~ \"orange\",\n        influence_strength == \"Secondary Target\" ~ \"yellow\",\n        influence_strength == \"Shared Collaborator\" ~ \"blue\",\n        influence_strength == \"Bridge Collaborator\" ~ \"cyan\",\n        node_role == \"Influenced Oceanus Collaborator\" ~ \"darkgreen\",\n        node_role == \"Other Oceanus Collaborator\" ~ \"lightgreen\",\n        node_role == \"Intermediate Work\" ~ \"pink\",\n        TRUE ~ \"lightgray\"\n      ),\n      node_size = case_when(\n        node_role %in% c(\"Sailor Shift\", \"Ivy Echos\") ~ 8,\n        influence_strength %in% c(\"Direct Target\", \"Shared Collaborator\") ~ 6,\n        influence_strength %in% c(\"Indirect Target\", \"Bridge Collaborator\") ~ 5,\n        influence_strength == \"Secondary Target\" ~ 4,\n        TRUE ~ 3\n      ),\n      tooltip_text = paste0(\n        \"Name: \", node_name, \"\\n\",\n        \"Role: \", node_role, \"\\n\", \n        \"Influence: \", influence_strength, \"\\n\",\n        \"Type: \", `Node Type`, \"\\n\",\n        ifelse(!is.na(genre), paste0(\"Genre: \", genre), \"\")\n      )\n    )\n  \n  # Collect all relevant edges preserving original Edge Types\n  all_influence_edges &lt;- bind_rows(\n    direct_influence %&gt;% mutate(pathway_category = \"Direct\"),\n    two_step_pathways %&gt;% \n      select(from = sailor_work, to = intermediate_work, `Edge Type` = step1_edge_type) %&gt;%\n      mutate(pathway_category = \"Indirect Step 1\"),\n    two_step_pathways %&gt;% \n      select(from = intermediate_work, to = oceanus_work, `Edge Type` = step2_edge_type) %&gt;%\n      mutate(pathway_category = \"Indirect Step 2\"),\n    cross_collab_influence %&gt;% \n      select(from, to, `Edge Type`) %&gt;%\n      mutate(pathway_category = \"Cross-Collaborator\")\n  )\n  \n  viz_edges &lt;- mc1_edges_clean %&gt;%\n    filter(from %in% all_viz_nodes, to %in% all_viz_nodes) %&gt;%\n    left_join(\n      all_influence_edges %&gt;% select(from, to, pathway_category),\n      by = c(\"from\", \"to\")\n    ) %&gt;%\n    mutate(\n      # Categorize edges for visual emphasis while keeping original Edge Type\n      edge_category = case_when(\n        !is.na(pathway_category) ~ \"Influence Pathway\",\n        `Edge Type` == \"MemberOf\" & from == sailor_vertex_name ~ \"Key Membership\", \n        `Edge Type` %in% collab_credit_types ~ \"Collaboration\",\n        `Edge Type` %in% influence_edge_types ~ \"Other Influence\",\n        TRUE ~ \"Other\"\n      ),\n      edge_alpha = case_when(\n        edge_category == \"Influence Pathway\" ~ 0.9,\n        edge_category == \"Key Membership\" ~ 0.8,\n        edge_category == \"Collaboration\" ~ 0.4,\n        edge_category == \"Other Influence\" ~ 0.6,\n        TRUE ~ 0.2\n      )\n    )\n  \n  # Create network plot\n  influence_graph &lt;- tbl_graph(nodes = viz_nodes, edges = viz_edges, directed = TRUE)\n\n  layout_df &lt;- create_layout(influence_graph, layout = \"fr\") %&gt;%\n    as_tibble() %&gt;%\n    select(name, x, y)\n  \n  nodes_plot &lt;- as_tibble(influence_graph) %&gt;%\n    left_join(layout_df, by = \"name\")\n  \n  edges_plot &lt;- viz_edges %&gt;%\n    left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n    rename(x_from = x, y_from = y) %&gt;%\n    left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n    rename(x_to = x, y_to = y)\n  \n  # Create legend data frame for node colors\n  legend_data &lt;- data.frame(\n    node_color = c(\"red\", \"purple\", \"gray30\", \"darkred\", \"orange\", \"yellow\", \n                   \"blue\", \"cyan\", \"darkgreen\", \"lightgreen\", \"pink\", \"lightgray\"),\n    node_role = c(\"Sailor Shift\", \"Ivy Echos\", \"Sailor/Ivy Work\", \"Direct Target\", \n                  \"Indirect Target\", \"Secondary Target\", \"Shared Collaborator\", \n                  \"Bridge Collaborator\", \"Influenced Oceanus Collaborator\", \n                  \"Other Oceanus Collaborator\", \"Intermediate Work\", \"Other\"),\n    stringsAsFactors = FALSE\n  )\n  \n  p &lt;- ggplot() +\n    geom_segment(\n      data = edges_plot,\n      aes(x = x_from, y = y_from, xend = x_to, yend = y_to,\n          color = `Edge Type`, alpha = edge_alpha),\n      arrow = arrow(length = unit(1.5, 'mm'))\n    ) +\n    scale_alpha_identity() +\n    scale_color_discrete(name = \"Edge Type\") +\n    ggnewscale::new_scale_color() +\n    geom_point_interactive(\n      data = nodes_plot,\n      aes(x = x, y = y, tooltip = tooltip_text, data_id = name,\n          color = node_color, shape = `Node Type`, size = node_size)\n    ) +\n    scale_size_identity() +  \n    scale_color_manual(\n      name = \"Node Role\",\n      values = c(\"red\" = \"red\", \"purple\" = \"purple\", \"pink\" = \"pink\", \"darkred\" = \"darkred\",\n                 \"orange\" = \"orange\", \"yellow\" = \"yellow\", \"blue\" = \"blue\", \"cyan\" = \"cyan\", \n                 \"darkgreen\" = \"darkgreen\", \"lightgreen\" = \"lightgreen\",\n                 \"gray30\" = \"gray30\", \"lightgray\" = \"lightgray\"),\n      labels = setNames(legend_data$node_role, legend_data$node_color),\n      breaks = legend_data$node_color,\n      guide = guide_legend(override.aes = list(size = 4, shape = 16))\n    ) +\n    geom_text(\n      data = nodes_plot %&gt;% filter(node_role == \"Sailor Shift\"),\n      aes(x = x, y = y, label = \"Sailor Shift\"),\n      size = 4, fontface = \"bold\", color = \"red\", vjust = -2\n    ) +\n    theme_void() +\n    theme(\n      legend.position = \"right\",\n      legend.box = \"vertical\",\n      legend.text = element_text(size = 11),\n      legend.title = element_text(size = 16),\n      plot.title = element_text(size = 20, face = \"bold\"), \n  plot.subtitle = element_text(size = 16, face = \"plain\")    \n    ) +\n    labs(\n      title = \"Sailor Shift's Influence on Oceanus Folk Community\",\n      subtitle = str_to_title(\"Influence pathways: Direct (work-to-work), Indirect (via intermediary), Secondary (cross-collaborator), Shared/Bridge (collaboration networks)\")\n    )\n  \n  # Summary statistics\n  cat(\"\\n=== INFLUENCE ANALYSIS SUMMARY ===\\n\")\n  cat(\"Total Oceanus Folk collaborators:\", length(oceanus_folk_collaborators), \"\\n\")\n  cat(\"Directly influenced collaborators:\", length(directly_influenced_collaborators), \"\\n\")\n  cat(\"Collaboration-mediated influenced:\", length(collaboration_influenced), \"\\n\")\n  cat(\"Total influenced collaborators:\", length(total_influenced_collaborators), \"\\n\")\n  cat(\"Percentage influenced:\", round(100 * length(total_influenced_collaborators) / length(oceanus_folk_collaborators), 1), \"%\\n\")\n  \n  cat(\"\\nInfluence pathway counts:\\n\")\n  cat(\"- Direct influences:\", nrow(direct_influence), \"\\n\")\n  cat(\"- Two-step pathways:\", nrow(two_step_pathways), \"\\n\") \n  cat(\"- Cross-collaborator influences:\", nrow(cross_collab_influence), \"\\n\")\n  cat(\"- Shared collaborators:\", length(shared_collaborators), \"\\n\")\n  cat(\"- Bridge collaborators:\", length(unique(bridge_to_oceanus$bridge_person)), \"\\n\")\n  \n} else {\n  cat(\"No influence pathways detected between Sailor Shift/Ivy Echos and Oceanus Folk collaborators.\\n\")\n}\n\n\n\n=== INFLUENCE ANALYSIS SUMMARY ===\nTotal Oceanus Folk collaborators: 720 \nDirectly influenced collaborators: 39 \nCollaboration-mediated influenced: 42 \nTotal influenced collaborators: 81 \nPercentage influenced: 11.2 %\n\nInfluence pathway counts:\n- Direct influences: 9 \n- Two-step pathways: 11 \n- Cross-collaborator influences: 10 \n- Shared collaborators: 42 \n- Bridge collaborators: 7 \n\n\nCode\ngirafe(ggobj = p, width_svg = 16, height_svg = 12)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#adding-identifying-columns",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#adding-identifying-columns",
    "title": "Take-home Exercise 2",
    "section": "3.1 Adding identifying columns",
    "text": "3.1 Adding identifying columns\nAs a large part of this mini-challenge centers around Sailor Shift and the genre of “Oceanus Folk”, the following code will add columns to help with identification and filtering of Sailor Shift and the work in the genre of “Oceanus Folk”. This will help with analysis in addressing the questions and tasks.\n\nmc1_nodes_raw &lt;- mc1_nodes_raw %&gt;%\n  mutate(\n    is_sailor = (\n      str_detect(name, regex(\"sailor shift\", ignore_case = TRUE))\n    ) %&gt;% replace_na(FALSE),\n    \n    is_oceanus_folk = str_detect(genre, regex(\"oceanus folk\", ignore_case = TRUE)) %&gt;% #na/not oceanus folk = false\n      replace_na(FALSE)\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#converting-date-field",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#converting-date-field",
    "title": "Take-home Exercise 2",
    "section": "3.2 Converting date field",
    "text": "3.2 Converting date field\nDate fields will be converted from chr to int for later analysis. Note that dates only appear for Song and Album.\n\nmc1_nodes_raw &lt;- mc1_nodes_raw %&gt;%\n  mutate(across(c(release_date, notoriety_date, written_date),\n                ~as.integer(if_else(`Node Type` %in% c(\"Song\", \"Album\"), ., NA_character_))))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#check-for-duplicates",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#check-for-duplicates",
    "title": "Take-home Exercise 2",
    "section": "3.3 Check for duplicates",
    "text": "3.3 Check for duplicates\n\n3.3.1 Check for duplicates in mc1_nodes_raw\nThe following code chunk checks for id duplicates in mc1_nodes_raw.\n\nmc1_nodes_raw %&gt;%\n  count(id) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: id &lt;int&gt;, n &lt;int&gt;\n\n\nThere are no duplicated id in mc1_nodes_raw.\nThe following code checks for name duplicates in mc1_nodes_raw.\n\nduplicated_name &lt;- mc1_nodes_raw %&gt;%\n  count(name) %&gt;%\n  filter(n &gt; 1)\n\nduplicated_name\n\n# A tibble: 1,611 × 2\n   name                 n\n   &lt;chr&gt;            &lt;int&gt;\n 1 Agata Records        2\n 2 Ancestral Echoes     2\n 3 Angela Thompson      2\n 4 Anthony Davis        2\n 5 Anthony Smith        2\n 6 Asuka Takahashi      3\n 7 Brandon Wilson       2\n 8 Brian Gonzalez       2\n 9 Bryan Garcia         2\n10 Bryan Smith          3\n# ℹ 1,601 more rows\n\n\nThe following code chunk shows all rows from mc1_nodes_raw that have duplicated names, and sorting them alphabetically by the name column. There are a total of 4,953 records with duplicated names in mc1_nodes_raw.\n\nmc1_nodes_raw %&gt;%\n  filter(name %in% duplicated_name$name) %&gt;%\n  arrange(name)\n\n# A tibble: 4,953 × 12\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 RecordLabel Agata Recor… NA               NA &lt;NA&gt;  NA       1528           NA\n 2 RecordLabel Agata Recor… NA               NA &lt;NA&gt;  NA      17388           NA\n 3 Song        Ancestral E… TRUE           1991 Drea… FALSE   11793           NA\n 4 Song        Ancestral E… FALSE          2039 Avan… TRUE    17133           NA\n 5 Person      Angela Thom… NA               NA &lt;NA&gt;  NA       1150           NA\n 6 Person      Angela Thom… NA               NA &lt;NA&gt;  NA      13448           NA\n 7 Person      Anthony Dav… NA               NA &lt;NA&gt;  NA       8692           NA\n 8 Person      Anthony Dav… NA               NA &lt;NA&gt;  NA      12452           NA\n 9 Person      Anthony Smi… NA               NA &lt;NA&gt;  NA       5719           NA\n10 Person      Anthony Smi… NA               NA &lt;NA&gt;  NA       7694           NA\n# ℹ 4,943 more rows\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n\n3.3.2 Fixing duplicates in mc1_nodes_raw\nThe section will focus on fixing the duplicates found in mc1_nodes_raw as identified in section 3.3.1.\nThe following code chunk will tag each row with a unique key (group_key) based on its respective column values. This helps to identify unique records.\n\n# Step 1: Mark all node rows with a hash key for grouping\nmc1_nodes_tagged &lt;- mc1_nodes_raw %&gt;%\n  mutate(group_key = paste(`Node Type`, name, single, release_date, genre,\n                           notable, written_date, notoriety_date, is_sailor,\n                           is_oceanus_folk, sep = \"|\"))\n\nmc1_nodes_tagged\n\n# A tibble: 17,412 × 13\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 Song        Breaking Th… TRUE           2017 Ocea… TRUE        0           NA\n 2 Person      Carlos Duffy NA               NA &lt;NA&gt;  NA          1           NA\n 3 Person      Min Qin      NA               NA &lt;NA&gt;  NA          2           NA\n 4 Person      Xiuying Xie  NA               NA &lt;NA&gt;  NA          3           NA\n 5 RecordLabel Nautical Mi… NA               NA &lt;NA&gt;  NA          4           NA\n 6 Song        Unshackled … FALSE          2026 Lo-F… TRUE        5           NA\n 7 Person      Luke Payne   NA               NA &lt;NA&gt;  NA          6           NA\n 8 Person      Xiulan Zeng  NA               NA &lt;NA&gt;  NA          7           NA\n 9 Person      David Frank… NA               NA &lt;NA&gt;  NA          8           NA\n10 RecordLabel Colline-Cas… NA               NA &lt;NA&gt;  NA          9           NA\n# ℹ 17,402 more rows\n# ℹ 5 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;, group_key &lt;chr&gt;\n\n\nThe code below deduplicates the dataset using group_key, reducing the number of duplicated names from 4,953 to 14. The remaining 14 names appear more than once because their corresponding records differ in at least one column used to form group_key, so they are retained as distinct entries.\n\n# Step 2: Deduplicate and keep the preferred (with stage_name if available)\nmc1_nodes_dedup &lt;- mc1_nodes_tagged %&gt;%\n  group_by(group_key) %&gt;%\n  arrange(desc(!is.na(stage_name))) %&gt;%\n  slice(1) %&gt;%\n  ungroup()\n\nduplicated_name &lt;- mc1_nodes_dedup %&gt;%\n  count(name) %&gt;%\n  filter(n &gt; 1)\n\nmc1_nodes_raw %&gt;%\n  filter(name %in% duplicated_name$name) %&gt;%\n  arrange(name)\n\n# A tibble: 14 × 12\n   `Node Type` name         single release_date genre notable    id written_date\n   &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n 1 Song        Ancestral E… TRUE           1991 Drea… FALSE   11793           NA\n 2 Song        Ancestral E… FALSE          2039 Avan… TRUE    17133           NA\n 3 RecordLabel Coastal Ech… NA               NA &lt;NA&gt;  NA       4022           NA\n 4 Album       Coastal Ech… NA             2023 Psyc… TRUE    15065         2019\n 5 Song        Postcards f… TRUE           2023 Indi… TRUE    12852         2023\n 6 Song        Postcards f… FALSE          1984 Acou… FALSE   17214           NA\n 7 Album       Shattered R… NA             2013 Emo/… TRUE     3325         2013\n 8 Song        Shattered R… FALSE          2036 Dark… TRUE    17088           NA\n 9 Song        Unheard Fre… TRUE           2025 Alte… TRUE     7999           NA\n10 RecordLabel Unheard Fre… NA               NA &lt;NA&gt;  NA      10952           NA\n11 Song        Vanishing P… TRUE           2018 Avan… TRUE     9371         2018\n12 Song        Vanishing P… FALSE          2013 Ocea… FALSE   17338           NA\n13 RecordLabel Vertical Ho… NA               NA &lt;NA&gt;  NA       2453           NA\n14 Album       Vertical Ho… NA             2017 Doom… TRUE     9262           NA\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n\n3.3.3 Check for duplicates in mc1_edges_raw\nThe following code proceeds to check for duplicates in mc1_edges_raw.\n\n# Step 1: Identify duplicate combinations\nduplicate_summary &lt;- mc1_edges_raw %&gt;%\n  count(source, target, `Edge Type`) %&gt;%\n  filter(n &gt; 1)\n\n# Step 2: Join back to get all original duplicate rows\nmc1_edges_raw %&gt;%\n  inner_join(duplicate_summary, by = c(\"source\", \"target\", \"Edge Type\"))\n\n# A tibble: 6 × 5\n  `Edge Type` source target   key     n\n  &lt;chr&gt;        &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 PerformerOf  17057  17058     0     2\n2 PerformerOf  17057  17058     1     2\n3 PerformerOf  17349  17350     0     2\n4 PerformerOf  17349  17350     2     2\n5 PerformerOf  17355  17356     0     2\n6 PerformerOf  17355  17356     2     2\n\n\nThere are duplicates as seen above, with only differences in key. As key will not be used in subsequent data analysis, the duplicated edges will be removed with the following code.\n\nmc1_edges_raw &lt;- mc1_edges_raw %&gt;%\n  distinct(source, target, `Edge Type`, .keep_all = TRUE) %&gt;%\n  select(!key)\n\nmc1_edges_raw %&gt;%\n  count(source, target, `Edge Type`) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 4\n# ℹ 4 variables: source &lt;int&gt;, target &lt;int&gt;, Edge Type &lt;chr&gt;, n &lt;int&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#explore-and-inspect-nodes",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#explore-and-inspect-nodes",
    "title": "Take-home Exercise 2",
    "section": "4.1 Explore and inspect Nodes",
    "text": "4.1 Explore and inspect Nodes\n\nmc1_nodes_raw$release_date %&gt;% unique()\n\n [1] 2017   NA 2026 2020 2027 2022 2007 2010 2003 2023 1997 2013 2000 2025 2029\n[16] 2015 2018 2016 2014 2028 2021 2030 2011 1994 2004 1998 1991 1999 2024 2012\n[31] 2002 2006 2008 2019 1995 1989 2032 2009 2001 1996 1990 1984 2005 1993 1986\n[46] 1985 1981 1992 1987 1988 1983 2031 1975 2035 2033 2037 2036 2039 2038 2034\n[61] 1977 1979 1980 1982 2040\n\nmc1_nodes_raw %&gt;%\n  filter(grepl(\"Sailor Shift\", name)) #Sailor Shift is in name column and not in stage_name column\n\n# A tibble: 1 × 12\n  `Node Type` name         single release_date genre notable    id written_date\n  &lt;chr&gt;       &lt;chr&gt;        &lt;lgl&gt;         &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;int&gt;        &lt;int&gt;\n1 Person      Sailor Shift NA               NA &lt;NA&gt;  NA      17255           NA\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n' will be removed from name to prevent issues with tooltip in tidygraph.\n\nmc1_nodes_clean &lt;- mc1_nodes_raw %&gt;%\n  mutate(\n    name = gsub(\"'\", \"\", name)) \n  \nkable(head(mc1_nodes_clean))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type\nname\nsingle\nrelease_date\ngenre\nnotable\nid\nwritten_date\nstage_name\nnotoriety_date\nis_sailor\nis_oceanus_folk\n\n\n\n\nSong\nBreaking These Chains\nTRUE\n2017\nOceanus Folk\nTRUE\n0\nNA\nNA\nNA\nFALSE\nTRUE\n\n\nPerson\nCarlos Duffy\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nPerson\nMin Qin\nNA\nNA\nNA\nNA\n2\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nPerson\nXiuying Xie\nNA\nNA\nNA\nNA\n3\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nRecordLabel\nNautical Mile Records\nNA\nNA\nNA\nNA\n4\nNA\nNA\nNA\nFALSE\nFALSE\n\n\nSong\nUnshackled Heart\nFALSE\n2026\nLo-Fi Electronica\nTRUE\n5\nNA\nNA\nNA\nFALSE\nFALSE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#explore-and-inspect-edges",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#explore-and-inspect-edges",
    "title": "Take-home Exercise 2",
    "section": "4.2 Explore and inspect Edges",
    "text": "4.2 Explore and inspect Edges\nThe following code chunk is used to ensure that id used in mc1_edges_raw matches the range range of id in mc1_nodes_clean.\n\nrange(mc1_nodes_clean$id)\n\n[1]     0 17411\n\nrange(mc1_edges_raw$source)\n\n[1]     0 17411\n\nrange(mc1_edges_raw$target)\n\n[1]     0 17411"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#mapping-node-name-to-edges-id",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#mapping-node-name-to-edges-id",
    "title": "Take-home Exercise 2",
    "section": "4.3 Mapping Node name to Edges id",
    "text": "4.3 Mapping Node name to Edges id\ntidygraph uses from and to columns to reference nodes. By default, tidygraph matches these edges reference against the first column in the nodes table, or against name column.\nCurrently, source and target columns in mc1_edges_raw contain id values that correspond to the id column in mc1_nodes_clean. To properly integrate with tidygraph’s conventions, the following will be done:\n\nRestructure mc1_nodes_clean\n\nRename the current name column to node_name - this is done to preserve the actual node names\nRename the id column to name so it becomes the primary identifier column that tidygraph will use for matching\n\nRename source and target columns in mc1_edges_raw, as required by tidygraph\nEnsure data type consistency: Convert the name column (formerly id) to character format to match the data type of the edge references\n\n\nmc1_nodes_clean &lt;- mc1_nodes_dedup %&gt;%\n  rename(node_name = name, name = id) %&gt;%\n  mutate(name = as.character(name)) %&gt;%\n  select(`Node Type`, node_name, release_date, genre, notable, name, single, written_date, stage_name, notoriety_date, is_sailor, is_oceanus_folk)\n\nmc1_nodes_clean\n\n# A tibble: 14,077 × 12\n   `Node Type` node_name    release_date genre notable name  single written_date\n   &lt;chr&gt;       &lt;chr&gt;               &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;   &lt;chr&gt; &lt;lgl&gt;         &lt;int&gt;\n 1 Album       A Lush Dyst…         2031 Psyc… TRUE    17005 NA             2030\n 2 Album       Addicted to…         2004 Sout… TRUE    14658 NA             2000\n 3 Album       Adriatic Em…         2013 Post… TRUE    10412 NA               NA\n 4 Album       Aerial Echo…         2023 Indi… TRUE    7908  NA               NA\n 5 Album       Aftershock …         2028 Drea… TRUE    2030  NA             2021\n 6 Album       Allegretto …         2020 Indi… TRUE    6251  NA               NA\n 7 Album       Alleys and …         2029 Jazz… TRUE    1310  NA               NA\n 8 Album       Alloy Archi…         2017 Indi… TRUE    8428  NA             2017\n 9 Album       Almost (But…         2027 Alte… TRUE    14611 NA             2027\n10 Album       Altar of De…         2020 Ocea… TRUE    5883  NA               NA\n# ℹ 14,067 more rows\n# ℹ 4 more variables: stage_name &lt;chr&gt;, notoriety_date &lt;int&gt;, is_sailor &lt;lgl&gt;,\n#   is_oceanus_folk &lt;lgl&gt;\n\n\n\n4.3.1 Creating edge mapping from old id to kept id\nIn section 3.3.2, duplicated nodes were deduplicated and removed, edges referring to the removed nodes will become invalid thus, edges will be remapped to the retained nodes. This ensures that all edges correctly point to existing nodes in the deduplicated graph.\n\n# Step 1: Create mapping of all group_key → kept id\nkey_to_id_map &lt;- mc1_nodes_dedup %&gt;%\n  select(group_key, kept_id = id)\n\n# Step 2: Map all original rows to the retained ID\nid_remap &lt;- mc1_nodes_tagged %&gt;%\n  left_join(key_to_id_map, by = \"group_key\") %&gt;%\n  select(original_id = id, kept_id)\n\nid_remap\n\n# A tibble: 17,412 × 2\n   original_id kept_id\n         &lt;int&gt;   &lt;int&gt;\n 1           0       0\n 2           1       1\n 3           2   14470\n 4           3       3\n 5           4       4\n 6           5       5\n 7           6       6\n 8           7       7\n 9           8       8\n10           9       9\n# ℹ 17,402 more rows\n\n\n\n# Step 3: Replace edges' source and target with mapped kept_id\nmc1_edges_mapped &lt;- mc1_edges_raw %&gt;%\n  left_join(id_remap, by = c(\"source\" = \"original_id\"))\n\nmc1_edges_mapped\n\n# A tibble: 37,854 × 4\n   `Edge Type`      source target kept_id\n   &lt;chr&gt;             &lt;int&gt;  &lt;int&gt;   &lt;int&gt;\n 1 InterpolatesFrom      0   1841       0\n 2 RecordedBy            0      4       0\n 3 PerformerOf           1      0       1\n 4 ComposerOf            1  16180       1\n 5 PerformerOf           2      0   14470\n 6 ProducerOf            2  16180   14470\n 7 PerformerOf           3      0       3\n 8 InterpolatesFrom      5   5088       5\n 9 InStyleOf             5  14332       5\n10 InterpolatesFrom      5  11677       5\n# ℹ 37,844 more rows\n\n\n\nmc1_edges_mapped &lt;- mc1_edges_mapped %&gt;%\n  mutate(source = kept_id) %&gt;%\n  select(-kept_id) %&gt;%\n  left_join(id_remap, by = c(\"target\" = \"original_id\")) %&gt;%\n  mutate(target = kept_id) %&gt;%\n  select(-kept_id) %&gt;%\n  rename(from = source, to = target) %&gt;%\n  mutate(from = as.character(from), to = as.character(to))\n\nmc1_edges_mapped\n\n# A tibble: 37,854 × 3\n   `Edge Type`      from  to   \n   &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;\n 1 InterpolatesFrom 0     1841 \n 2 RecordedBy       0     4    \n 3 PerformerOf      1     0    \n 4 ComposerOf       1     16180\n 5 PerformerOf      14470 0    \n 6 ProducerOf       14470 16180\n 7 PerformerOf      3     0    \n 8 InterpolatesFrom 5     5088 \n 9 InStyleOf        5     14332\n10 InterpolatesFrom 5     11677\n# ℹ 37,844 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#remove-unmatched-edges",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#remove-unmatched-edges",
    "title": "Take-home Exercise 2",
    "section": "4.4 Remove unmatched edges",
    "text": "4.4 Remove unmatched edges\nThe following code chunk removes edges that reference missing node id, ensuring that only valid edges are kept.\n\nmc1_edges_clean &lt;- mc1_edges_mapped %&gt;%\n  filter(!is.na(from), !is.na(to))\n\nThere are no unmatched edges."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#check-for-missing-nodes",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#check-for-missing-nodes",
    "title": "Take-home Exercise 2",
    "section": "4.5 Check for missing nodes",
    "text": "4.5 Check for missing nodes\nThe following code chunk checks for missing nodes being referenced in mc1_edges_clean that do not exist in mc1_nodes_clean.\n\nsetdiff(\n  unique(c(mc1_edges_clean$from, mc1_edges_clean$to)),\n  mc1_nodes_clean$name\n)\n\ncharacter(0)\n\n\nThere are no missing nodes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#validate-edges-schema",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#validate-edges-schema",
    "title": "Take-home Exercise 2",
    "section": "4.6 Validate Edges Schema",
    "text": "4.6 Validate Edges Schema\nThis section aims to ensure that each edge in the graph adheres to the schema specified in the VAST Challenge 2025 MC1 Data Description document. The following code checks whether the node types connect by each edge matches the valid source and target types for that edge’s type.\n\n# Define valid source and destination types for each edge type\nedge_rules &lt;- list(\n  PerformerOf = list(source = c(\"Person\", \"MusicalGroup\"), target = c(\"Song\", \"Album\")),\n  ComposerOf = list(source = c(\"Person\"), target = c(\"Song\", \"Album\")),\n  ProducerOf = list(source = c(\"Person\", \"RecordLabel\"), target = c(\"Song\", \"Album\", \"Person\", \"MusicalGroup\")),\n  LyricistOf = list(source = c(\"Person\"), target = c(\"Song\", \"Album\")),\n  RecordedBy = list(source = c(\"Song\", \"Album\"), target = c(\"RecordLabel\")),\n  DistributedBy = list(source = c(\"Song\", \"Album\"), target = c(\"RecordLabel\")),\n  InStyleOf = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\", \"Person\", \"MusicalGroup\")),\n  InterpolatesFrom = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  CoverOf = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  LyricalReferenceTo = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  DirectlySamples = list(source = c(\"Song\", \"Album\"), target = c(\"Song\", \"Album\")),\n  MemberOf = list(source = c(\"Person\"), target = c(\"MusicalGroup\"))\n)\n\nThe following code chunk checks for any erroneous edge and node relationships defined in the code chunk above.\n\n# Create a lookup for node types\nnode_type_lookup &lt;- mc1_nodes_clean %&gt;%\n  select(name, `Node Type`) %&gt;%\n  deframe()\n\n# Add source and target node types to the edge table\nmc1_edges_checked &lt;- mc1_edges_clean %&gt;%\n  mutate(\n    source_type = node_type_lookup[from],\n    target_type = node_type_lookup[to]\n  )\n\nmc1_edges_tagged &lt;- mc1_edges_checked %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    valid = {\n      rule &lt;- edge_rules[[`Edge Type`]]\n      if (is.null(rule)) TRUE\n      else {\n        source_type %in% rule$source && target_type %in% rule$target\n      }\n    }\n  ) %&gt;%\n  ungroup()\n\n# Count and display invalid edge combinations\ninvalid_edge_summary &lt;- mc1_edges_tagged %&gt;%\n  filter(!valid) %&gt;%\n  count(`Edge Type`, source_type, target_type, sort = TRUE)\n\nprint(invalid_edge_summary)\n\n# A tibble: 24 × 4\n   `Edge Type`      source_type  target_type      n\n   &lt;chr&gt;            &lt;chr&gt;        &lt;chr&gt;        &lt;int&gt;\n 1 LyricistOf       MusicalGroup Song           106\n 2 RecordedBy       RecordLabel  Album          102\n 3 ProducerOf       MusicalGroup Song           100\n 4 ComposerOf       MusicalGroup Song            97\n 5 ProducerOf       MusicalGroup Album           31\n 6 LyricistOf       MusicalGroup Album           28\n 7 ComposerOf       MusicalGroup Album           17\n 8 InStyleOf        MusicalGroup MusicalGroup    12\n 9 InStyleOf        Person       MusicalGroup    11\n10 InterpolatesFrom MusicalGroup MusicalGroup    10\n# ℹ 14 more rows\n\n\n\n# Check total invalid edge count\ncat(\"Total invalid edges:\", sum(!mc1_edges_tagged$valid), \"\\n\")\n\nTotal invalid edges: 550 \n\n\nThere are 550 edges that do not adhere to the schema specified in the data description file provided. The following code will remove these edges.\n\n# Keep only valid edges\nmc1_edges_clean &lt;- mc1_edges_tagged %&gt;%\n  filter(valid) %&gt;%\n  select(from, to, `Edge Type`)  # drop helper columns"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#visualising-edge-and-node-types",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#visualising-edge-and-node-types",
    "title": "Take-home Exercise 2",
    "section": "4.7 Visualising Edge and Node types",
    "text": "4.7 Visualising Edge and Node types\n\nggplot(data = mc1_edges_clean,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = mc1_nodes_clean,\n       aes(y = `Node Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1a---who-has-she-been-most-influenced-by-over-time",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1a---who-has-she-been-most-influenced-by-over-time",
    "title": "Take-home Exercise 2",
    "section": "5.1 Question 1a - Who has she been most influenced by over time?",
    "text": "5.1 Question 1a - Who has she been most influenced by over time?\nThe network structure below shows how Sailor Shift’s career has been influenced by others. PageRank is used to measure the overall influence of each person, musical group or work within the network. This captures both direct and indirect influences.\n\nNetwork VisualisationInfluence Summary\n\n\n\n\nCode\n# Step 0: Get name of 'Sailor Shift'\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;%\n  first()\n\n# Step 1: Find direct influence relationships from Sailor Shift\n# These are the artists/works that Sailor Shift has been influenced by\ndirect_influence_types &lt;- c(\"InStyleOf\", \"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\")\n\nsailor_direct_influences &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name, \n         `Edge Type` %in% direct_influence_types)\n\n# Step 2: Get immediate neighbors (people/groups Sailor Shift works with)\nsailor_out_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from == sailor_vertex_name)\n\nsailor_out_node_names &lt;- sailor_out_edges$to\n\n# Step 3: Split into people/groups vs songs/albums\nsailor_person_group &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_out_node_names, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\nsailor_songs_all &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_out_node_names, `Node Type` %in% c(\"Song\", \"Album\")) %&gt;%\n  pull(name)\n\n# Step 4: For songs/albums, find their direct influences too\nsong_influences &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs_all, \n         `Edge Type` %in% direct_influence_types)\n\n# Step 5: Get all influence targets (who influenced Sailor Shift or their works)\nall_influence_targets &lt;- unique(c(\n  sailor_direct_influences$to,\n  song_influences$to\n))\n\n# Step 6: Get creators of Sailor Shift's works (indirect influence indicators)\ncreator_edge_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\")\n\nsailor_songs &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs_all) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\nsailor_songs_out_nodes &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% sailor_songs) %&gt;%\n  pull(to)\n\ncreator_edges &lt;- mc1_edges_clean %&gt;%\n  filter(to %in% sailor_songs_out_nodes, `Edge Type` %in% creator_edge_types)\n\nsailor_people_group_neighbourhood_nodes &lt;- creator_edges %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 7: Combine all relevant nodes for subgraph\nsailor_all_node_names &lt;- unique(c(\n  sailor_vertex_name,\n  sailor_person_group,\n  sailor_songs,\n  sailor_songs_out_nodes,\n  sailor_people_group_neighbourhood_nodes,\n  all_influence_targets  \n))\n\n# Step 8: Create subgraph\nsub_music &lt;- music %&gt;%\n  filter(name %in% sailor_all_node_names)\n\n# Step 9: Calculate PageRank \nsub_music &lt;- sub_music %&gt;%\n  activate(nodes) %&gt;%\n  mutate(\n    pagerank = centrality_pagerank()\n  )\n\n# Step 10: Set node size based on PageRank for people/groups, fixed for others\nsub_music &lt;- sub_music %&gt;%\n  mutate(\n    is_sailor = name == sailor_vertex_name,\n    node_color = ifelse(is_sailor, \"red\", \"grey30\"),\n    tooltip_text = sprintf(\n      \"Name: %s\\nType: %s\\nPageRank: %.4f\",\n      node_name, `Node Type`, pagerank\n    ),\n    node_size = case_when(\n      `Node Type` %in% c(\"Person\", \"MusicalGroup\") ~ rescale(pagerank, to = c(4, 20)),\n      TRUE ~ 4  \n    )\n  )\n\n# Step 11: Create visualization\ng &lt;- sub_music %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(\n    aes(color = `Edge Type`), \n    alpha = 0.3,\n    arrow = arrow(length = unit(3, 'mm')),\n    end_cap = circle(3, 'mm')\n  ) +\n  geom_point_interactive(\n    aes(\n      x = x, y = y,\n      data_id = name,\n      tooltip = tooltip_text,\n      shape = `Node Type`,\n      colour = node_color,\n      size = node_size\n    )\n  ) +\n  scale_shape_discrete(name = \"Node Type\") +\n  scale_colour_identity() +\n  scale_size_identity() +\n  theme_graph(base_family = \"sans\") +\n  labs(\n    title = \"Network of Influences on Sailor Shift\"\n  )\n\ngirafe(ggobj = g, width_svg = 10, height_svg = 8)\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter to people and groups only, exclude Sailor Shift node itself\ntop_influencers &lt;- sub_music %&gt;%\n  as_tibble() %&gt;%\n  filter(\n    `Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n    name != sailor_vertex_name\n  ) %&gt;%\n  arrange(desc(pagerank)) %&gt;%\n  slice_head(n = 5)\n\n# Plot\nggplot(top_influencers, aes(x = reorder(node_name, pagerank), y = pagerank, fill = `Node Type`)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    title = \"Top 5 Influences on Sailor Shift\",\n    x = \"Influencer\",\n    y = \"PageRank Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the PageRank score, it is noted that she is most influenced by musical groups as the top 3 most influences are musical groups. Phantom Roots have influenced her the most over time, this is followed by Ursus and the group she was a part of, Ivy Echos."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1b---who-has-she-collaborated-with-and-directly-or-indirectly-influenced",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1b---who-has-she-collaborated-with-and-directly-or-indirectly-influenced",
    "title": "Take-home Exercise 2",
    "section": "5.2 Question 1b - Who has she collaborated with and directly or indirectly influenced?",
    "text": "5.2 Question 1b - Who has she collaborated with and directly or indirectly influenced?\nThe network visualisation below explores Sailor Shift’s collaborations and influence. While the primary question centers on Sailor Shift, the analysis also incorporates Ivy Echos, the musical group that she was a member of. Including Ivy Echos is essential because Sailor Shift’s creative impact can extend beyond her solo work as her contributions as part of Ivy Echos could have influenced others. The visualisation therefore highlights not just individuals and groups who have collaborated with Sailor Shift on her works, but also those influenced by Ivy Echos, providing an extensive picture of her influence.\n\n\nCode\n# Step 1: Define all relevant edge types per schema\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\ninfluence_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\n# Step 2: Get Sailor Shift's node ID\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;% first()\n\n# Step 3: Find all Sailor Shift's works (songs/albums she performed or was lyricist of)\nsailor_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% c(\"PerformerOf\", \"LyricistOf\"), from == sailor_vertex_name) %&gt;%\n  pull(to)\n\n# Step 4: Find all Person/MusicalGroup collaborated on Sailor Shift's works (excluding herself)\nsailor_collab_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, to %in% sailor_works, from != sailor_vertex_name)\nsailor_collab_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% sailor_collab_edges$from, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\n# Step 5: Get Ivy Echos's node ID and works\nivy_echos_name &lt;- mc1_nodes_clean %&gt;%\n  filter(str_detect(node_name, regex(\"Ivy Echos\", ignore_case = TRUE))) %&gt;%\n  pull(name) %&gt;% first()\nivy_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` == \"PerformerOf\", from == ivy_echos_name) %&gt;%\n  pull(to)\nivy_works &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% ivy_works, `Node Type` %in% c(\"Song\", \"Album\")) %&gt;%\n  pull(name)\n\n# Step 6: Find all works influenced by Ivy Echos's works (Ivy Echos's works as destination of influence edges)\nivy_influenced_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_types, to %in% ivy_works)\nivy_influenced_works &lt;- ivy_influenced_edges$from\n\n# Step 7: For each influenced work, get the people/groups involved (collaborators on those works)\nivy_influenced_collab_edges &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, to %in% ivy_influenced_works)\nivy_influenced_collab_nodes &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% ivy_influenced_collab_edges$from, `Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(name)\n\n# Step 8: Collect all relevant nodes and edges for the network\nall_relevant_nodes &lt;- unique(c(\n  sailor_vertex_name,\n  sailor_collab_nodes,\n  sailor_works,\n  ivy_echos_name,\n  ivy_works,\n  ivy_influenced_works,\n  ivy_influenced_collab_nodes\n))\n\nall_relevant_edges &lt;- mc1_edges_clean %&gt;%\n  filter(from %in% all_relevant_nodes & to %in% all_relevant_nodes)\n\n# Step 9: Annotate node roles for plotting\nsub_nodes_df &lt;- mc1_nodes_clean %&gt;%\n  filter(name %in% all_relevant_nodes) %&gt;%\n  mutate(\n    node_role = case_when(\n      name == sailor_vertex_name ~ \"Sailor Shift\",\n      name == ivy_echos_name ~ \"Ivy Echos\",\n      name %in% sailor_collab_nodes ~ \"Sailor Shift Collaborator\",\n      name %in% sailor_works ~ \"Sailor Shift Work\",\n      name %in% ivy_works ~ \"Ivy Echos Work\",\n      name %in% ivy_influenced_works ~ \"Work Influenced by Ivy Echos\",\n      name %in% ivy_influenced_collab_nodes ~ \"Person/Group in Influenced Work\",\n      TRUE ~ \"Other\"\n    ),\n    node_color = case_when(\n      node_role == \"Sailor Shift\" ~ \"red\",\n      node_role == \"Ivy Echos\" ~ \"purple\",\n      node_role == \"Sailor Shift Collaborator\" ~ \"blue\",\n      node_role == \"Sailor Shift Work\" ~ \"grey30\",\n      node_role == \"Ivy Echos Work\" ~ \"green\",\n      node_role == \"Work Influenced by Ivy Echos\" ~ \"orange\",\n      node_role == \"Person/Group in Influenced Work\" ~ \"pink\",\n      TRUE ~ \"steelblue\"\n    ),\n    tooltip_text = paste0(\n      \"Name: \", node_name, \"\\n\",\n      \"Type: \", `Node Type`, \"\\n\",\n      \"Role: \", node_role, \"\\n\",\n      ifelse(!is.na(genre), paste0(\"Genre: \", genre, \"\\n\"), \"\"),\n      ifelse(!is.na(release_date), paste0(\"Release: \", release_date, \"\\n\"), \"\")\n    )\n  )\n\n# Step 10: Create tidygraph object and layout\ncareer_graph &lt;- tbl_graph(nodes = sub_nodes_df, edges = all_relevant_edges, directed = TRUE) %&gt;%\n  activate(nodes)\n\nlayout_df &lt;- create_layout(career_graph, layout = \"fr\") %&gt;%\n  as_tibble() %&gt;%\n  select(name, x, y)\n\nnodes_plot &lt;- as_tibble(career_graph) %&gt;%\n  left_join(layout_df, by = \"name\")\n\nedges_plot &lt;- all_relevant_edges %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n  rename(x_from = x, y_from = y) %&gt;%\n  left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n  rename(x_to = x, y_to = y)\n\n# Step 11: Get coordinates for annotation\nsailor_coords &lt;- nodes_plot %&gt;%\n  filter(name == sailor_vertex_name) %&gt;%\n  select(x, y)\nivy_coords &lt;- nodes_plot %&gt;%\n  filter(name == ivy_echos_name) %&gt;%\n  select(x, y)\n\n# Step 12: Plot with ggplot2 + ggiraph, with annotation and legend\np &lt;- ggplot() +\n  geom_segment(\n    data = edges_plot,\n    aes(\n      x = x_from, y = y_from, xend = x_to, yend = y_to,\n      color = `Edge Type`\n    ),\n    alpha = 0.4, arrow = arrow(length = unit(3, 'mm'))\n  ) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Edge Type\") +\n  ggnewscale::new_scale_color() +\n  geom_point_interactive(\n    data = nodes_plot,\n    aes(\n      x = x, y = y,\n      tooltip = tooltip_text,\n      data_id = name,\n      color = node_role,  # Changed from node_color to node_role for legend\n      shape = `Node Type`\n    ),\n    size = 4\n  ) +\n  scale_color_manual(\n    name = \"Node Role\",\n    values = c(\n      \"Sailor Shift\" = \"red\",\n      \"Ivy Echos\" = \"purple\", \n      \"Sailor Shift Collaborator\" = \"blue\",\n      \"Sailor Shift Work\" = \"grey30\",\n      \"Ivy Echos Work\" = \"green\",\n      \"Work Influenced by Ivy Echos\" = \"orange\",\n      \"Person/Group in Influenced Work\" = \"pink\",\n      \"Other\" = \"steelblue\"\n    ),\n    breaks = c(\n      \"Sailor Shift\",\n      \"Ivy Echos\", \n      \"Sailor Shift Collaborator\",\n      \"Sailor Shift Work\",\n      \"Ivy Echos Work\",\n      \"Work Influenced by Ivy Echos\",\n      \"Person/Group in Influenced Work\"\n    )\n  ) +\n  theme_void() +\n  labs(title = \"Sailor Shift's Collaborators and Influence\") +\n  guides(\n    color = guide_legend(\n      title = \"Node Role\",\n      override.aes = list(size = 4),\n      title.position = \"top\"\n    ),\n    shape = guide_legend(\n      title = \"Node Type\",\n      title.position = \"top\"\n    )\n  ) +\n  theme(\n    legend.position = \"right\",\n    legend.box = \"vertical\",\n    plot.title = element_text(size = 20, face = \"bold\") \n  )\n\ngirafe(ggobj = p, width_svg = 12, height_svg = 8)\n\n\n\n\n\n\nThe visualisation shows a wide array of individuals and musical groups who have collaborated with Sailor Shift on various works, this reflects her active engagement within the industry. While there are no instances of Sailor Shift directly influencing other artists, the visualisation reveals that her group, Ivy Echos, has influenced a group and four individuals through a song (Deepsea Fireflies, released in 2025). This demonstrates that Sailor Shift’s reach extends beyond her personal collaborations, contributing to a broader legacy through her involvement with Ivy Echos."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1c---how-has-she-influenced-collaborators-of-the-broader-oceanus-folk-community",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#question-1c---how-has-she-influenced-collaborators-of-the-broader-oceanus-folk-community",
    "title": "Take-home Exercise 2",
    "section": "5.3 Question 1c - How has she influenced collaborators of the broader Oceanus Folk community?",
    "text": "5.3 Question 1c - How has she influenced collaborators of the broader Oceanus Folk community?\nThe network visualisation aims to analyse how Sailor Shift influenced collaborators of the broader Oceanus Folk community.\nSailor Shift and her group (Ivy Echos) were primary entities of interest, all works associated to them are compiled to form the foundation of Sailor Shift’s musical output. Based on this, several types of influence were analysed:\n\nDirect influence - This includes Oceanus Folk collaborators’ works that were explicity influenced by Sailor Shift or Ivy Echos through relationships such as CoverOf, InterpolatesFrom, LyricalReferenceTo, DirectlySamples, and InStyleOf.\nIndirect (two-step influence) - This occurs when a work by Sailor Shift or Ivy Echos influences an intermediate piece, which then goes on to influence a work by an Oceanus Folk collaborator. These two-step chains shows how Sailor Shift’s influence can propagate through the network.\nCross-collaborator influence - This captures intra-community influence where Oceanus Folk works that were initially influenced by Sailor Shift/Ivy Echos proceeded to influence other Oceanus Folk creations.\nCollaborated-mediated influence - This is transmitted through shared or bridge collaborators.\n\nShared collaborators are individuals or groups who worked with both Sailor Shift/Ivy Echos and the Oceanus Folk community\nBridge Collaborators are those who first worked with Sailor Shift/Ivy Echos and later collaborated with Ocean Folk Contributors.\n\n\nBased on the influences above, it reveals the full extent of Sailor Shift’s reach within the Oceanus Folk Community.\n\n\nCode\n# Step 1: Define edge types\ncollab_credit_types &lt;- c(\"PerformerOf\", \"ComposerOf\", \"ProducerOf\", \"LyricistOf\", \"MemberOf\")\ninfluence_edge_types &lt;- c(\"CoverOf\", \"InterpolatesFrom\", \"LyricalReferenceTo\", \"DirectlySamples\", \"InStyleOf\")\n\n# Step 2: Identify all nodes with genre == \"Oceanus Folk\"\noceanus_folk_works &lt;- mc1_nodes_clean %&gt;%\n  filter(genre == \"Oceanus Folk\") %&gt;%\n  pull(name)\n\n# Step 3: Identify all Person and MusicalGroup who are collaborators on Oceanus Folk works\noceanus_folk_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         to %in% oceanus_folk_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Step 4: Get Sailor Shift and Ivy Echos\nsailor_vertex_name &lt;- mc1_nodes_clean %&gt;%\n  filter(is_sailor == TRUE) %&gt;%\n  pull(name) %&gt;% \n  first()\n\nivy_echos_name &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` == \"MemberOf\", from == sailor_vertex_name) %&gt;%\n  pull(to) %&gt;%\n  first()\n\n# Step 5: Find all works that Sailor Shift and Ivy Echos have created/performed\nsailor_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, from == sailor_vertex_name) %&gt;%\n  pull(to)\n\nivy_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, from == ivy_echos_name) %&gt;%\n  pull(to)\n\nsailor_ivy_works &lt;- unique(c(sailor_works, ivy_works))\n\n# Step 6: Find all works that the Oceanus Folk collaborators have worked on\noceanus_collaborator_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         from %in% oceanus_folk_collaborators) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\n# Step 7: Direct influence - Sailor Shift/Ivy Echos works influencing Oceanus collaborator works\ndirect_influence &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works,\n         to %in% oceanus_collaborator_works) %&gt;%\n  mutate(influence_direction = \"Sailor/Ivy → Oceanus\",\n         pathway_type = \"Direct\")\n\n# Step 8: Indirect influence - Multi-step pathways\n\n# 8a: Find intermediate works that could bridge Sailor Shift/Ivy Echos to Oceanus\n# Works influenced BY Sailor/Ivy\nsailor_influenced_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works) %&gt;%\n  pull(to) %&gt;%\n  unique()\n\n# Works that influence Sailor/Ivy  \nsailor_influencing_works &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         to %in% sailor_ivy_works) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# All intermediate works in potential pathways\nintermediate_works &lt;- unique(c(sailor_influenced_works, sailor_influencing_works))\n\n# 8b: Two-step influence: Sailor/Ivy → Intermediate → Oceanus collaborators\nindirect_influence_step1 &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% sailor_ivy_works,\n         to %in% intermediate_works) %&gt;%\n  select(sailor_work = from, intermediate_work = to, step1_edge_type = `Edge Type`)\n\nindirect_influence_step2 &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% intermediate_works,\n         to %in% oceanus_collaborator_works) %&gt;%\n  select(intermediate_work = from, oceanus_work = to, step2_edge_type = `Edge Type`)\n\n# Join to find complete 2-step pathways\ntwo_step_pathways &lt;- indirect_influence_step1 %&gt;%\n  inner_join(indirect_influence_step2, by = \"intermediate_work\") %&gt;%\n  mutate(pathway_type = \"Indirect (2-step)\",\n         influence_direction = \"Sailor/Ivy → Intermediate → Oceanus\")\n\n# 8c: Cross-collaborator influence within Oceanus community\n# Find Oceanus works that were influenced by Sailor and then influenced other Oceanus works\ndirectly_influenced_oceanus_works &lt;- unique(c(direct_influence$to, two_step_pathways$oceanus_work))\n\ncross_collab_influence &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% influence_edge_types,\n         from %in% directly_influenced_oceanus_works,\n         to %in% oceanus_collaborator_works,\n         from != to) %&gt;%\n  mutate(pathway_type = \"Cross-collaborator\",\n         influence_direction = \"Sailor-influenced Oceanus work → Other Oceanus work\")\n\n# Step 9: Collaboration-mediated influence \n\n# 9a: People who worked with both Sailor/Ivy AND Oceanus Folk collaborators\nsailor_ivy_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         to %in% sailor_ivy_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\")) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\nshared_collaborators &lt;- intersect(sailor_ivy_collaborators, oceanus_folk_collaborators)\n\n# 9b. Bridge collaborators - worked with Sailor/Ivy, then later with other Oceanus Folk collaborators\nbridge_collaborators &lt;- setdiff(sailor_ivy_collaborators, oceanus_folk_collaborators)\nbridge_to_oceanus &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types,\n         from %in% bridge_collaborators) %&gt;%\n  inner_join(\n    mc1_edges_clean %&gt;%\n      filter(`Edge Type` %in% collab_credit_types,\n             from %in% oceanus_folk_collaborators) %&gt;%\n      select(shared_work = to),\n    by = c(\"to\" = \"shared_work\")\n  ) %&gt;%\n  select(bridge_person = from, shared_work = to) %&gt;%\n  distinct()\n\n# Step 10: Identify influenced Oceanus Folk Collaborators \n\n# Get all works that show influence from Sailor/Ivy\nall_influenced_oceanus_works &lt;- unique(c(\n  direct_influence$to,\n  two_step_pathways$oceanus_work,\n  cross_collab_influence$to\n))\n\n# Find which Oceanus Folk collaborators worked on these influenced works\ndirectly_influenced_collaborators &lt;- mc1_edges_clean %&gt;%\n  filter(`Edge Type` %in% collab_credit_types, \n         to %in% all_influenced_oceanus_works) %&gt;%\n  inner_join(mc1_nodes_clean %&gt;% select(name, `Node Type`), by = c(\"from\" = \"name\")) %&gt;%\n  filter(`Node Type` %in% c(\"Person\", \"MusicalGroup\"),\n         from %in% oceanus_folk_collaborators) %&gt;%\n  pull(from) %&gt;%\n  unique()\n\n# Add collaborators connected through shared/bridge relationships\ncollaboration_influenced &lt;- unique(c(shared_collaborators, bridge_to_oceanus$bridge_person))\ncollaboration_influenced &lt;- intersect(collaboration_influenced, oceanus_folk_collaborators)\n\ntotal_influenced_collaborators &lt;- unique(c(directly_influenced_collaborators, collaboration_influenced))\n\n# Prepare variables for tabset (initialize as NULL)\np &lt;- NULL\nsummary_stats &lt;- NULL\n\n# Step 11: Enhanced network visualisation and summary statistics \nif(length(total_influenced_collaborators) &gt; 0) {\n  \n  # Collect all relevant nodes for visualization\n  all_pathway_works &lt;- unique(c(\n    sailor_ivy_works,\n    direct_influence$from, direct_influence$to,\n    two_step_pathways$sailor_work, two_step_pathways$intermediate_work, two_step_pathways$oceanus_work,\n    cross_collab_influence$from, cross_collab_influence$to\n  ))\n  \n  all_relevant_people &lt;- unique(c(\n    sailor_vertex_name,\n    ivy_echos_name,\n    total_influenced_collaborators,\n    shared_collaborators,\n    bridge_to_oceanus$bridge_person\n  ))\n  \n  all_viz_nodes &lt;- unique(c(all_pathway_works, all_relevant_people))\n  \n  # Enhanced node classification\n  viz_nodes &lt;- mc1_nodes_clean %&gt;%\n    filter(name %in% all_viz_nodes) %&gt;%\n    mutate(\n      influence_strength = case_when(\n        name %in% direct_influence$to ~ \"Direct Target\",\n        name %in% two_step_pathways$oceanus_work ~ \"Indirect Target\", \n        name %in% cross_collab_influence$to ~ \"Secondary Target\",\n        name %in% shared_collaborators ~ \"Shared Collaborator\",\n        name %in% bridge_to_oceanus$bridge_person ~ \"Bridge Collaborator\",\n        TRUE ~ \"Network Node\"\n      ),\n      node_role = case_when(\n        name == sailor_vertex_name ~ \"Sailor Shift\",\n        name == ivy_echos_name ~ \"Ivy Echos\",\n        name %in% sailor_ivy_works ~ \"Sailor/Ivy Work\",\n        name %in% oceanus_folk_works ~ \"Oceanus Folk Work\",\n        name %in% total_influenced_collaborators ~ \"Influenced Oceanus Collaborator\",\n        name %in% oceanus_folk_collaborators ~ \"Other Oceanus Collaborator\",\n        name %in% intermediate_works ~ \"Intermediate Work\",\n        TRUE ~ \"Other\"\n      ),\n      node_color = case_when(\n        node_role == \"Sailor Shift\" ~ \"red\",\n        node_role == \"Ivy Echos\" ~ \"purple\", \n        node_role == \"Sailor/Ivy Work\" ~ \"gray30\",\n        influence_strength == \"Direct Target\" ~ \"darkred\",\n        influence_strength == \"Indirect Target\" ~ \"orange\",\n        influence_strength == \"Secondary Target\" ~ \"yellow\",\n        influence_strength == \"Shared Collaborator\" ~ \"blue\",\n        influence_strength == \"Bridge Collaborator\" ~ \"cyan\",\n        node_role == \"Influenced Oceanus Collaborator\" ~ \"darkgreen\",\n        node_role == \"Other Oceanus Collaborator\" ~ \"lightgreen\",\n        node_role == \"Intermediate Work\" ~ \"pink\",\n        TRUE ~ \"lightgray\"\n      ),\n      node_size = case_when(\n        node_role %in% c(\"Sailor Shift\", \"Ivy Echos\") ~ 8,\n        influence_strength %in% c(\"Direct Target\", \"Shared Collaborator\") ~ 6,\n        influence_strength %in% c(\"Indirect Target\", \"Bridge Collaborator\") ~ 5,\n        influence_strength == \"Secondary Target\" ~ 4,\n        TRUE ~ 3\n      ),\n      tooltip_text = paste0(\n        \"Name: \", node_name, \"\\n\",\n        \"Role: \", node_role, \"\\n\", \n        \"Influence: \", influence_strength, \"\\n\",\n        \"Type: \", `Node Type`, \"\\n\",\n        ifelse(!is.na(genre), paste0(\"Genre: \", genre), \"\")\n      )\n    )\n  \n  # Collect all relevant edges preserving original Edge Types\n  all_influence_edges &lt;- bind_rows(\n    direct_influence %&gt;% mutate(pathway_category = \"Direct\"),\n    two_step_pathways %&gt;% \n      select(from = sailor_work, to = intermediate_work, `Edge Type` = step1_edge_type) %&gt;%\n      mutate(pathway_category = \"Indirect Step 1\"),\n    two_step_pathways %&gt;% \n      select(from = intermediate_work, to = oceanus_work, `Edge Type` = step2_edge_type) %&gt;%\n      mutate(pathway_category = \"Indirect Step 2\"),\n    cross_collab_influence %&gt;% \n      select(from, to, `Edge Type`) %&gt;%\n      mutate(pathway_category = \"Cross-Collaborator\")\n  )\n  \n  viz_edges &lt;- mc1_edges_clean %&gt;%\n    filter(from %in% all_viz_nodes, to %in% all_viz_nodes) %&gt;%\n    left_join(\n      all_influence_edges %&gt;% select(from, to, pathway_category),\n      by = c(\"from\", \"to\")\n    ) %&gt;%\n    mutate(\n      # Categorize edges for visual emphasis while keeping original Edge Type\n      edge_category = case_when(\n        !is.na(pathway_category) ~ \"Influence Pathway\",\n        `Edge Type` == \"MemberOf\" & from == sailor_vertex_name ~ \"Key Membership\", \n        `Edge Type` %in% collab_credit_types ~ \"Collaboration\",\n        `Edge Type` %in% influence_edge_types ~ \"Other Influence\",\n        TRUE ~ \"Other\"\n      ),\n      edge_alpha = case_when(\n        edge_category == \"Influence Pathway\" ~ 0.9,\n        edge_category == \"Key Membership\" ~ 0.8,\n        edge_category == \"Collaboration\" ~ 0.4,\n        edge_category == \"Other Influence\" ~ 0.6,\n        TRUE ~ 0.2\n      )\n    )\n  \n  # Create network plot\n  influence_graph &lt;- tbl_graph(nodes = viz_nodes, edges = viz_edges, directed = TRUE)\n\n  layout_df &lt;- create_layout(influence_graph, layout = \"fr\") %&gt;%\n    as_tibble() %&gt;%\n    select(name, x, y)\n  \n  nodes_plot &lt;- as_tibble(influence_graph) %&gt;%\n    left_join(layout_df, by = \"name\")\n  \n  edges_plot &lt;- viz_edges %&gt;%\n    left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"from\" = \"name\")) %&gt;%\n    rename(x_from = x, y_from = y) %&gt;%\n    left_join(nodes_plot %&gt;% select(name, x, y), by = c(\"to\" = \"name\")) %&gt;%\n    rename(x_to = x, y_to = y)\n  \n  # Create legend data frame for node colors\n  legend_data &lt;- data.frame(\n    node_color = c(\"red\", \"purple\", \"gray30\", \"darkred\", \"orange\", \"yellow\", \n                   \"blue\", \"cyan\", \"darkgreen\", \"lightgreen\", \"pink\", \"lightgray\"),\n    node_role = c(\"Sailor Shift\", \"Ivy Echos\", \"Sailor/Ivy Work\", \"Direct Target\", \n                  \"Indirect Target\", \"Secondary Target\", \"Shared Collaborator\", \n                  \"Bridge Collaborator\", \"Influenced Oceanus Collaborator\", \n                  \"Other Oceanus Collaborator\", \"Intermediate Work\", \"Other\"),\n    stringsAsFactors = FALSE\n  )\n  \n  p &lt;- ggplot() +\n    geom_segment(\n      data = edges_plot,\n      aes(x = x_from, y = y_from, xend = x_to, yend = y_to,\n          color = `Edge Type`, alpha = edge_alpha),\n      arrow = arrow(length = unit(1.5, 'mm'))\n    ) +\n    scale_alpha_identity() +\n    scale_color_discrete(name = \"Edge Type\") +\n    ggnewscale::new_scale_color() +\n    geom_point_interactive(\n      data = nodes_plot,\n      aes(x = x, y = y, tooltip = tooltip_text, data_id = name,\n          color = node_color, shape = `Node Type`, size = node_size)\n    ) +\n    scale_size_identity() +  \n    scale_color_manual(\n      name = \"Node Role\",\n      values = c(\"red\" = \"red\", \"purple\" = \"purple\", \"pink\" = \"pink\", \"darkred\" = \"darkred\",\n                 \"orange\" = \"orange\", \"yellow\" = \"yellow\", \"blue\" = \"blue\", \"cyan\" = \"cyan\", \n                 \"darkgreen\" = \"darkgreen\", \"lightgreen\" = \"lightgreen\",\n                 \"gray30\" = \"gray30\", \"lightgray\" = \"lightgray\"),\n      labels = setNames(legend_data$node_role, legend_data$node_color),\n      breaks = legend_data$node_color,\n      guide = guide_legend(override.aes = list(size = 4, shape = 16))\n    ) +\n    geom_text(\n      data = nodes_plot %&gt;% filter(node_role == \"Sailor Shift\"),\n      aes(x = x, y = y, label = \"Sailor Shift\"),\n      size = 4, fontface = \"bold\", color = \"red\", vjust = -2\n    ) +\n    theme_void() +\n    theme(\n      legend.position = \"right\",\n      legend.box = \"vertical\",\n      legend.text = element_text(size = 11),\n      legend.title = element_text(size = 16),\n      plot.title = element_text(size = 20, face = \"bold\"), \n      plot.subtitle = element_text(size = 16, face = \"plain\")    \n    ) +\n    labs(\n      title = \"Sailor Shift's Influence on Oceanus Folk Community\",\n      subtitle = str_to_title(\"Influence pathways: Direct (work-to-work), Indirect (via intermediary), Secondary (cross-collaborator), Shared/Bridge (collaboration networks)\")\n    )\n  \n  # Create summary statistics data frame\nsummary_stats &lt;- data.frame(\n  Metric = c(\n    \"Total Oceanus Folk collaborators\",\n    \"Total influenced collaborators\",\n    \"Percentage influenced (%)\",\n    \"\",\n    \"Direct influences\",\n    \"Two-step pathways\", \n    \"Cross-collaborator influences\",\n    \"Shared collaborators\",\n    \"Bridge collaborators\"\n  ),\n  Value = c(\n    length(oceanus_folk_collaborators),\n    length(total_influenced_collaborators),\n    round(100 * length(total_influenced_collaborators) / length(oceanus_folk_collaborators), 1),\n    \"\",\n    nrow(direct_influence),\n    nrow(two_step_pathways),\n    nrow(cross_collab_influence),\n    length(shared_collaborators),\n    length(unique(bridge_to_oceanus$bridge_person))\n  ),\n  stringsAsFactors = FALSE\n)\n}\n\n\n\nNetwork VisualisationSummary Statistics\n\n\n\n\nCode\ngirafe(ggobj = p, width_svg = 16, height_svg = 12)\n\n\n\n\n\n\n\n\n\n\nCode\nknitr::kable(\n  summary_stats,\n  col.names = c(\"Metric\", \"Count\"),\n  caption = \"Sailor Shift's Influence Analysis Summary\"\n)\n\n\n\nSailor Shift’s Influence Analysis Summary\n\n\nMetric\nCount\n\n\n\n\nTotal Oceanus Folk collaborators\n720\n\n\nTotal influenced collaborators\n81\n\n\nPercentage influenced (%)\n11.2\n\n\n\n\n\n\nDirect influences\n9\n\n\nTwo-step pathways\n11\n\n\nCross-collaborator influences\n10\n\n\nShared collaborators\n42\n\n\nBridge collaborators\n7\n\n\n\n\n\n\n\n\nThe above visualisation focus on the network of influence that Sailor Shift had in the Oceanus Folk community. Out of 720 Oceanus Folk collaborators, she has interacted with 81 collaborators, which is a notable influence as it is more than 10% of the community.\nWhile only 9 collaborators have been directly influenced by working closely with her/Ivy Echos, the majority of her impact is indirect. More than half of the influenced collaborators have been shaped indirectly through shared and bridged collaborators. These network-mediated pathways, including two-step and cross-collaborator connections, illustrates how her influence extends beyond those that she worked directly with.\nOverall, this showcases how Sailor Shift’s influence diffuses dynamically throughout the community where her impact in the community is not only driven by direct collaborations, but also by the broader web of relationships and interactions that connect the Oceanus Folk community."
  }
]